{"attributes":{"kind":"struct","backlinks":[{"tag":"document","title":"How to augment vision data","docid":"documents/docs/howto/augmentvision.md"},{"tag":"document","title":"Blocks and encodings","docid":"documents/docs/background/blocksencodings.md"},{"tag":"document","title":"Saving and loading models for inference","docid":"documents/notebooks/serialization.ipynb"},{"tag":"sourcefile","title":"FastAI/src/Vision/tasks/segmentation.jl","docid":"sourcefiles/FastAI/src/Vision/tasks/segmentation.jl"},{"tag":"sourcefile","title":"FastAI/src/Vision/encodings/projective.jl","docid":"sourcefiles/FastAI/src/Vision/encodings/projective.jl"},{"tag":"sourcefile","title":"FastAI/src/Vision/Vision.jl","docid":"sourcefiles/FastAI/src/Vision/Vision.jl"},{"tag":"document","title":"Keypoint regression","docid":"documents/notebooks/keypointregression.ipynb"},{"tag":"documentation","title":"ImageClassificationSingle","docid":"references/FastAI.Vision.ImageClassificationSingle"},{"tag":"documentation","title":"Bounded","docid":"references/FastAI.Vision.Bounded"},{"tag":"sourcefile","title":"FastAI/src/Vision/tests.jl","docid":"sourcefiles/FastAI/src/Vision/tests.jl"},{"tag":"sourcefile","title":"FastAI/src/Vision/tasks/classification.jl","docid":"sourcefiles/FastAI/src/Vision/tasks/classification.jl"},{"tag":"sourcefile","title":"FastAI/src/Vision/tasks/keypointregression.jl","docid":"sourcefiles/FastAI/src/Vision/tasks/keypointregression.jl"},{"tag":"document","title":"Introduction","docid":"documents/docs/introduction.md"},{"tag":"documentation","title":"ImageSegmentation","docid":"references/FastAI.Vision.ImageSegmentation"},{"tag":"document","title":"Image segmentation","docid":"documents/notebooks/imagesegmentation.ipynb"},{"tag":"document","title":"Siamese image similarity","docid":"documents/notebooks/siamese.ipynb"},{"tag":"document","title":"fastai API comparison","docid":"documents/docs/fastai_api_comparison.md"},{"tag":"documentation","title":"ImageClassificationMulti","docid":"references/FastAI.Vision.ImageClassificationMulti"}],"methods":[{"line":47,"file":"/home/runner/.julia/packages/FastAI/8BNUf/src/Vision/encodings/projective.jl","method_id":"FastAI.Vision.ProjectiveTransforms_1","symbol_id":"FastAI.Vision.ProjectiveTransforms","signature":"ProjectiveTransforms(sz::Tuple{Vararg{Int64, N}}, buffered::Bool, augmentations, tfms::T, sharestate::Bool)"},{"line":56,"file":"/home/runner/.julia/packages/FastAI/8BNUf/src/Vision/encodings/projective.jl","method_id":"FastAI.Vision.ProjectiveTransforms_2","symbol_id":"FastAI.Vision.ProjectiveTransforms","signature":"ProjectiveTransforms(sz; augmentations, inferencefactor, buffered, sharestate)"}],"name":"ProjectiveTransforms","title":"ProjectiveTransforms","symbol_id":"FastAI.Vision.ProjectiveTransforms","public":true,"module_id":"FastAI.Vision"},"tag":"documentation","children":[{"attributes":{},"tag":"md","children":[{"attributes":{"lang":""},"tag":"codeblock","children":["ProjectiveTransforms(sz; [augmentations, buffered]) <: Encoding\n"],"type":"node"},{"attributes":{},"tag":"p","children":["Encoding for spatial data that resizes blocks to a common size ",{"attributes":{},"tag":"code","children":["sz"],"type":"node"}," and applies",{"attributes":{},"tag":"br","children":[],"type":"node"},"projective augmentations."],"type":"node"},{"attributes":{},"tag":"p","children":["Encodes all spatial blocks, preserving the block type:"],"type":"node"},{"attributes":{},"tag":"ul","children":[{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["Image{N}"],"type":"node"}," -> ",{"attributes":{},"tag":"code","children":["Image{N}"],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["Mask{N}"],"type":"node"}," -> ",{"attributes":{},"tag":"code","children":["Mask{N}"],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["Keypoints{N}"],"type":"node"}," -> ",{"attributes":{},"tag":"code","children":["Keypoints{N}"],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"p","children":["The behavior differs based on the ",{"attributes":{},"tag":"code","children":["context"],"type":"node"}," of encoding:"],"type":"node"},{"attributes":{},"tag":"ul","children":[{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{"reftype":"symbol","document_id":"references/FastAI.Training"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["Training"],"type":"node"}],"type":"node"},":"],"type":"node"},{"attributes":{},"tag":"ol","children":[{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":["Resizes the data so the smallest side equals",{"attributes":{},"tag":"br","children":[],"type":"node"},"a side length in ",{"attributes":{},"tag":"code","children":["sz"],"type":"node"}," while keeping the aspect ratio."],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":["Applies ",{"attributes":{},"tag":"code","children":["augmentations"],"type":"node"},"."],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":["Crops a random ",{"attributes":{},"tag":"code","children":["sz"],"type":"node"},"-sized portion of the data"],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{"reftype":"symbol","document_id":"references/FastAI.Validation"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["Validation"],"type":"node"}],"type":"node"},":"],"type":"node"},{"attributes":{},"tag":"ol","children":[{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":["Resizes the data so the smallest side equals",{"attributes":{},"tag":"br","children":[],"type":"node"},"a side length in ",{"attributes":{},"tag":"code","children":["sz"],"type":"node"}," while keeping the aspect ratio."],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":["Crops a ",{"attributes":{},"tag":"code","children":["sz"],"type":"node"},"-sized portion from the center."],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{"reftype":"symbol","document_id":"references/FastAI.Inference"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["Inference"],"type":"node"}],"type":"node"},":"],"type":"node"},{"attributes":{},"tag":"ol","children":[{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":["Resizes the data so the smallest side equals",{"attributes":{},"tag":"br","children":[],"type":"node"},"a side length in ",{"attributes":{},"tag":"code","children":["sz"],"type":"node"}," while keeping the aspect ratio.",{"attributes":{},"tag":"br","children":[],"type":"node"},"Note that in this context, the data does not have",{"attributes":{},"tag":"br","children":[],"type":"node"},"size ",{"attributes":{},"tag":"code","children":["sz"],"type":"node"},", since no cropping happens and aspect ratio",{"attributes":{},"tag":"br","children":[],"type":"node"},"is preserved."],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["ProjectiveTransforms"],"type":"node"}," is not limited to 2D data, and works on 3D data as well.",{"attributes":{},"tag":"br","children":[],"type":"node"},"Note, however, that some transformations in ",{"attributes":{},"tag":"code","children":["augs_projection"],"type":"node"}," (rotation, warping, flipping)",{"attributes":{},"tag":"br","children":[],"type":"node"},"are 2D only so ",{"attributes":{},"tag":"code","children":["augs_projection"],"type":"node"}," cannot be used for 3D data."],"type":"node"},{"attributes":{},"tag":"h2","children":["Keyword arguments"],"type":"node"},{"attributes":{},"tag":"ul","children":[{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["augmentations::"],"type":"node"},{"attributes":{"reftype":"symbol","document_id":"references/DataAugmentation.Transform"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["DataAugmentation.Transform"],"type":"node"}],"type":"node"},{"attributes":{},"tag":"code","children":[" = Identity()"],"type":"node"},": Projective",{"attributes":{},"tag":"br","children":[],"type":"node"},"augmentation to apply during training. See ",{"attributes":{"reftype":"symbol","document_id":"references/FastAI.Vision.augs_projection"},"tag":"reference","children":[{"attributes":{},"tag":"code","children":["augs_projection"],"type":"node"}],"type":"node"},"."],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["buffered = true"],"type":"node"},": Whether to use inplace transformations. Reduces memory usage."],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["sharestate = true"],"type":"node"},": Whether to use the same random state and bounds for all blocks",{"attributes":{},"tag":"br","children":[],"type":"node"},"in a sample"],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"}