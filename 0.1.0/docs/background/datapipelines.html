<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
    <meta charset="utf-8" />
    <meta name="generator" content="Publish.jl" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="keywords" content="" />
    <title>FastAI.jl</title>
    <link rel="stylesheet" href="..&#x2F;..&#x2F;normalize.css" />
    <link rel="stylesheet" href="https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;npm&#x2F;katex@0.12.0&#x2F;dist&#x2F;katex.min.css" />
    <link rel="stylesheet" href="..&#x2F;..&#x2F;tabulator_simple.min.css" />
    <link rel="stylesheet" href="..&#x2F;..&#x2F;publish.css" />
    <link rel="stylesheet" href="..&#x2F;..&#x2F;default.min.css" />
    <link rel="stylesheet" href="..&#x2F;..&#x2F;custom.css" />
    <script src="https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;npm&#x2F;katex@0.12.0&#x2F;dist&#x2F;katex.min.js"></script>
    <script src="https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;npm&#x2F;katex@0.12.0&#x2F;dist&#x2F;contrib&#x2F;auto-render.min.js"></script>
    <script src="..&#x2F;..&#x2F;versions.js"></script>
    <script src="..&#x2F;..&#x2F;lunr.js"></script>
    <script src="..&#x2F;..&#x2F;highlight.min.js"></script>
    <script src="..&#x2F;..&#x2F;tabulator.min.js"></script>
    <script src="..&#x2F;..&#x2F;julia.min.js"></script>
    <script src="..&#x2F;..&#x2F;julia-repl.min.js"></script>
    <script src="..&#x2F;..&#x2F;publish.js"></script>
    
</head>
<body>
    <main id="page">
        <div class="menu">
            <div id="projectname">FastAI.jl</div>
            <input id="search-input" placeholder="Search">
            <select id="version-selector"></select>
            <svg id="menu-toggler" title="Contents" onclick="toggleIndexPage();" width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M2 6C2 5.44772 2.44772 5 3 5H21C21.5523 5 22 5.44772 22 6C22 6.55228 21.5523 7 21 7H3C2.44772 7 2 6.55228 2 6Z" fill="currentColor" /><path d="M2 12.0322C2 11.4799 2.44772 11.0322 3 11.0322H21C21.5523 11.0322 22 11.4799 22 12.0322C22 12.5845 21.5523 13.0322 21 13.0322H3C2.44772 13.0322 2 12.5845 2 12.0322Z" fill="currentColor" /><path d="M3 17.0645C2.44772 17.0645 2 17.5122 2 18.0645C2 18.6167 2.44772 19.0645 3 19.0645H21C21.5523 19.0645 22 18.6167 22 18.0645C22 17.5122 21.5523 17.0645 21 17.0645H3Z" fill="currentColor" /></svg>
        </div>
        <div id="toc"><ul>
<li><a href="../../README.html">README</a></li>
<li><a href="../../docs/setup.html">Setup</a></li>
<li><a href="../../docs/quickstart.html">Quickstart</a></li>
</ul>
<h1 id="tutorials"><a href="../../#tutorials" class="anchor"></a>Tutorials</h1>
<ul>
<li><a href="../../docs/introduction.html">Introduction</a></li>
<li><a href="../../docs/data_containers.html">Data containers</a></li>
<li><a href="../../docs/learning_methods.html">Learning methods</a></li>
</ul>
<h1 id="learning-tasks"><a href="../../#learning-tasks" class="anchor"></a>Learning tasks</h1>
<ul>
<li><a href="../../docs/methods/imageclassification.html">Image classification</a></li>
<li><a href="../../docs/methods/imagesegmentation.html">Image segmentation</a></li>
</ul>
<h1 id="how-to"><a href="../../#how-to" class="anchor"></a>How To</h1>
<ul>
<li><a href="../../docs/notebooks/fitonecycle.html">Train a model from scratch</a></li>
<li><a href="../../docs/notebooks/finetune.html">Finetune a pretrained model</a></li>
<li><a href="../../docs/notebooks/lrfind.html">Find a good learning rate</a></li>
</ul>
<h1 id="reference"><a href="../../#reference" class="anchor"></a>Reference</h1>
<ul>
<li><a href="../../docstrings.html">Docstrings</a></li>
<li><a href="../../docs/interfaces.html">Interfaces</a></li>
<li><a href="../../docs/glossary.html">Glossary</a></li>
</ul>
<h1 id="background"><a href="../../#background" class="anchor"></a>Background</h1>
<ul>
<li><a href="../../docs/background/datapipelines.html">Performant data pipelines</a></li>
</ul>
</div>
        <article id="content"><h1 id="performant-data-pipelines"><a href="#performant-data-pipelines" class="anchor"></a>Performant data pipelines</h1>
<p><em>Explainer on how data pipelines in FastAI.jl are made fast and how to make yours fast.</em></p>
<p>When training large deep learning models on a GPU we clearly want wait as short as possible for the training to complete. The hardware bottleneck is usually the GPU power you have available to you. This means that data pipelines need to be fast enough to keep the GPU at 100% utilization, that is, keep it from “starving”. Reducing the time the GPU has to wait for the next batch of data directly lowers the training time until the GPU is fully utilized. There are other ways to reduce training time like using hyperparameter schedules and different optimizers for faster convergence, but we’ll only talk about improving GPU utilization here.</p>
<h2 id="reasons-for-low-gpu-utilization"><a href="#reasons-for-low-gpu-utilization" class="anchor"></a>Reasons for low GPU utilization</h2>
<p>The main cause of low GPU utilization is that the next batch of data is not available after a training step and the GPU has to wait. This means that in order to get full GPU utilization,</p>
<ol>
<li>loading a batch must not take longer than a training step; and</li>
<li>the data must be loaded in the background, so that it is ready the moment the GPU needs it.</li>
</ol>
<p>These issues can be addressed by</p>
<ol>
<li>using worker threads to load multiple batches in parallel</li>
<li>keeping the primary thread free; and</li>
<li>reducing the time it takes to load a single batch</li>
</ol>
<p>FastAI.jl by default uses <code>DataLoader</code> from the <a href="">DataLoaders.jl</a> package which addresses points 1. and 2. For those familiar with PyTorch, it closely resembles <code>torch.utils.data.DataLoader</code>. It also efficiently collates the data by reusing a buffer where supported.</p>
<p>We can measure the large performance difference by comparing a naive sequential data iterator with <code>eachobsparallel</code>, the data iterator that <code>DataLoader</code> uses.</p>
<pre><code class="language-julia">using DataLoaders: batchviewcollated
using FastAI
using FastAI.Datasets

data = loadtaskdata(datasetpath(&quot;imagenette2-320&quot;), ImageClassificationTask)
method = ImageClassification(Datasets.getclassesclassification(&quot;imagenette2-320&quot;), (224, 224))

# maps data processing over `data`
methoddata = methoddataset(data, method, Training())

# creates a data container of collated batches
batchdata = batchviewcollated(methoddata, 16)

NBATCHES = 200

# sequential data iterator
@time for (i, batch) in enumerate(getobs(batchdata, i) for i in 1:nobs(batchdata))
    i != NBATCHES || break
end

# parallel data iterator
@time for (i, batch) in enumerate(eachobsparallel(batchdata))
    i != NBATCHES || break
end
</code></pre>
<p>Running each timer twice to forego compilation time, the sequential iterator takes 20 seconds while the parallel iterator using 11 background threads only takes 2.5 seconds. This certainly isn’t a proper benchmark, but it shows the performance can be improved by an order of magnitude with no effort.</p>
<p>Beside increasing the amount of compute available with worker threads as above, the data loading performance can also be improved by reducing the time it takes to load a single batch. Since a batch is made up of some number of observations, this usually boils down to reducing the loading time of a single observation. If you’re using the <code>LearningMethod</code> API, this can be further broken down into the loading and encoding part.</p>
<h2 id="measuring-performance"><a href="#measuring-performance" class="anchor"></a>Measuring performance</h2>
<p>So how do you know if your GPU is underutilized? If it isn’t, then improving data pipeline performance won’t help you at all! One way to check this is to start training and run <code>&gt; watch -n 0.1 nvidia-smi</code> in a terminal which displays and refreshs GPU stats every 1/10th of a second. If <code>GPU-Util</code> stays between 90% and 99%, you’re good!</p>
<p>If that’s not the case, you might see it frantically jumping up and down. We can get a better estimate of how much training time can be sped up by running the following experiment:</p>
<ol>
<li>Load one batch and run <code>n</code> optimization steps on this batch. The time this takes corresponds to the training time when the GPU does not have to wait for data to be available.</li>
<li>Next take your data iterator and time iterating over the first <code>n</code> batches <em>without</em> an optimization step.</li>
</ol>
<p>The speed of the complete training loop (data loading and optimization) will be around the maximum of either measurement. Roughly speaking, if 1. takes 100 seconds and 2. takes 200 seconds, you know that you can speed up training by about a factor of 2 if you reduce data loading time by half, after which the GPU will become the bottleneck.</p>
<pre><code class="language-julia">using FastAI
using FastAI.Datasets
using FluxTraining: fitbatchphase!

data = loadtaskdata(datasetpath(&quot;imagenette2-320&quot;), ImageClassificationTask)
method = ImageClassification(Datasets.getclassesclassification(&quot;imagenette2-320&quot;), (224, 224))

learner = methodlearner(method, data, xresnet18())

NBATCHES = 100

# Measure GPU time
batch = gpu(first(learner.data.training))
learner.model = gpu(model)
@time for i in 1:NBATCHES
    fitbatchphase!(learner, batch, TrainingPhase())
end

# Measure data loading time
@time for (i, batch) in zip(learner.data.training, 1:NBATCHES)
end
</code></pre>
<p>Again, make sure to run each measurement twice so you don’t include the compilation time.</p>
<hr />
<p>To find performance bottlenecks in the loading of each observation, you’ll want to compare the time it takes to load an observation of the task data container and the time it takes to encode that observation.</p>
<pre><code class="language-julia">using BenchmarkTools
using FastAI
using FastAI.Datasets

# Since loading times can vary per observation, we'll average the measurements over multiple observations
N = 10
data = datasubset(shuffleobs(loadtaskdata(datasetpath(&quot;imagenette2&quot;), ImageClassificationTask), 1:N))
method = ImageClassification(Datasets.getclassesclassification(&quot;imagenette2-320&quot;), (224, 224))

# Time it takes to load an `(image, class)` observation
@btime for i in 1:N
    getobs(data, i)
end


# Time it takes to encode an `(image, class)` observation into `(x, y)`
obss = [getobs(data, i) for i in 1:N]
@btime for i in 1:N
    encode(method, Training(), obss[i])
end
</code></pre>
<p>This will give you a pretty good idea of where the performance bottleneck is. Note that the encoding performance is often dependent of the method configuration. If we used <code>ImageClassification</code> with input size <code>(64, 64)</code> it would be much faster.</p>
<h2 id="improving-performance"><a href="#improving-performance" class="anchor"></a>Improving performance</h2>
<p>So, you’ve identified the data pipeline as a performance bottleneck. What now? Before anything else, make sure you’re doing the following:</p>
<ul>
<li>Use <code>DataLoaders.DataLoader</code> as a data iterator. If you’re using <a href="../../docstrings/DLPipelines.methoddataloaders.html"><code>methoddataloaders</code></a> or <a href="../../docstrings/FastAI.methodlearner.html"><code>methodlearner</code></a>, this is already the case.</li>
<li>Start Julia with multiple threads by specifying the <code>-t n</code>/<code>-t auto</code> flag when starting Julia. If it is successful, <code>Threads.nthreads()</code> should be larger than <code>1</code>.</li>
</ul>
<p>If the data loading is still slowing down training, you’ll probably have to speed up the loading of each observation. As mentioned above, this can be broken down into observation loading and encoding. The exact strategy will depend on your use case, but here are some examples.</p>
<ul>
<li>
<p>Reduce loading time of image datasets by presizing</p>
<p>For many computer vision tasks, you will resize and crop images to a specific size during training for GPU performance reasons. If the images themselves are large, loading them from disk itself can take some time. If your dataset consists of 1920x1080 resolution images but you’re resizing them to 256x256 during training, you’re wasting a lot of time loading the large images. <em>Presizing</em> means saving resized versions of each image to disk once, and then loading these smaller versions during training. We can see the performance difference using ImageNette since it comes in 3 sizes: original, 360px and 180px.</p>
<pre><code class="language-julia">data_orig = loadtaskdata(datasetpath(&quot;imagenette2&quot;), ImageClassificationTask)
@time eachobsparallel(data_orig, buffered = false)

data_320px = loadtaskdata(datasetpath(&quot;imagenette2-320&quot;), ImageClassificationTask)
@time eachobsparallel(data_320px, buffered = false)

data_160px = loadtaskdata(datasetpath(&quot;imagenette2-160&quot;), ImageClassificationTask)
@time eachobsparallel(data_160px, buffered = false)
</code></pre>
</li>
<li>
<p>Reducing allocations with inplace operations</p>
<p>When implementing the <code>LearningMethod</code> interface, you have the option to implement <code>encode!(buf, method, context, sample)</code>, an inplace version of <code>encode</code> that reuses a buffer to avoid allocations. Reducing allocations often speeds up the encoding step and can also reduce the frequency of garbage collector pauses during training which can reduce GPU utilization.</p>
</li>
<li>
<p>Using efficient data augmentation</p>
<p>Many kinds of augmentation can be composed efficiently. A prime example of this are image transformations like resizing, scaling and cropping which are powered by <a href="https://github.com/lorenzoh/DataAugmentation.jl">DataAugmentation.jl</a>. See <a href="https://lorenzoh.github.io/DataAugmentation.jl/dev/docs/literate/intro.html">its documentation</a> to find out how to implement efficient, composable data transformations.</p>
</li>
</ul>
</article>
        <div id="page-navigation">
            <a id="previous-page" title="Previous" href="..&#x2F;glossary.html"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M16.2426 6.34317L14.8284 4.92896L7.75739 12L14.8285 19.0711L16.2427 17.6569L10.5858 12L16.2426 6.34317Z" fill="currentColor" /></svg></a>
            <a id="next-page" title="Next" href="..&#x2F;..&#x2F;docstrings&#x2F;FastAI.Datasets.datasetpath.html"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M10.5858 6.34317L12 4.92896L19.0711 12L12 19.0711L10.5858 17.6569L16.2427 12L10.5858 6.34317Z" fill="currentColor" /></svg></a>
        </div>
        <footer>
            Built with <a target="_blank" href="https://github.com/MichaelHatherly/Publish.jl">Publish.jl</a> and the <a target="_blank" href="https://julialang.org">Julia Language</a>.
        </footer>
    </main>
    <script>hljs.initHighlightingOnLoad();</script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            renderMathInElement(document.body, {
                delimiters: [
                    {left: "$$", right: "$$", display: true},
                    {left: "$", right: "$", display: false},
                    {left: "\\(", right: "\\)", display: false},
                    {left: "\\[", right: "\\]", display: true}
                ]
            });
        });
    </script>
</body>
</html>
