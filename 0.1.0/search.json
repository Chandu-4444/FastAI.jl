[{"body":"Datasets Before we get started, let ’ s load up a  data container  that we can test our code on as we go .  It ’ s always a good idea to interactively test your code !  Since we ’ ll be implementing a method for image classification, the observations in our data container will of course have to be pairs of images and classes .  We ’ ll use one of the many image classification datasets available from the fastai dataset repository .  I ’ ll use ImageNette, but you can use any of the datasets listed in  FastAI.Datasets.DATASETS_IMAGECLASSIFICATION .  The way the interface is built allows you to easily swap out the dataset you ’ re using . We ’ ll also collect the unique class names:","id":"docs/learning_methods.html#datasets"},{"body":"Data container interface","id":"docs/interfaces.html#data-container-interface"},{"body":"public   methodlearner   —   function Create a  Learner  to train a model for learning method  method  using data .  See also  Learner .","id":"docstrings/FastAI.methodlearner.html"},{"body":"public   joinobs   —   function Concatenate data containers  datas .","id":"docstrings/FastAI.Datasets.joinobs.html"},{"body":"Low - level LearningMethod LearningTask encode encodeinput decodey","id":"docs/api.html#low-level"},{"body":"private   setschedules!   —   function Set  schedules  on  learner ’ s  Scheduler  callback so that training resumes from there . If  learner  does not have a  Scheduler  callback yet, adds it .","id":"docstrings/FastAI.setschedules!.html"},{"body":"private   plotxy   —   function","id":"docstrings/FastAI.plotxy.html"},{"body":"Exercises Using  mapobs  and  loadfile , create a data container where every observation is only an image .","id":"docs/data_containers.html#exercises-1"},{"body":"Data loaders Next we turn the data container into training and validation data loaders .  These take care of efficiently loading batches of data (by default in parallel) .  The observations are already preprocessed using the information in  method  and then batched together .  Let ’ s look at a single batch: xs  is a batch of cropped and normalized images with dimensions  (height, width, color channels, batch size)  and  ys  a batch of one - hot encoded classes with dimensions  (classes, batch size) .","id":"docs/introduction.html#data-loaders"},{"body":"Model sizes Array sizes that compatible models must conform to . Full model:  (method.sz..., 3, batch) -> (length(method.classes), batch) Backbone model:  (method.sz..., 3, batch) -> ((method.sz ./ f)..., ch, batch)  where  f is a downscaling factor  f = 2^k It is recommended  not  to use  Flux.softmax  as the final layer for custom models; instead use  Flux.logitcrossentropy  as the loss function for increased numerical stability .  This is done automatically if using with  methodmodel  and  methodlossfn .","id":"docstrings/FastAI.ImageClassification.html#model-sizes"},{"body":"private   makeitem   —   function Tries to assign a  DataAugmentation.Item  from  data  based on its type . args  are passed to the chosen   Item  constructor . AbstractMatrix{<:Colorant}   - >  Image Vector{<:Union{Nothing, SVector}}   - >  Keypoints","id":"docstrings/FastAI.makeitem.html"},{"body":"public   ProjectiveTransforms   —   struct Pipeline step that resizes images and keypoints to  size . In context  Training , applies  augmentations .","id":"docstrings/FastAI.ProjectiveTransforms.html"},{"body":"public   ImageClassification   —   struct A learning method for single - label image classification: given an image and a set of  classes , determine which class the image falls into .  For example, decide if an image contains a dog or a cat . Images are resized and cropped to  sz  (see  ProjectiveTransforms ) and preprocessed using  ImagePreprocessing .   classes  is a vector of the class labels .","id":"docstrings/FastAI.ImageClassification.html"},{"body":"private   invert   —   function Applies the inverse of the operation  step  to  data","id":"docstrings/FastAI.invert.html"},{"body":"Callback interface See the  FluxTraining . jl tutorial .","id":"docs/interfaces.html#callback-interface"},{"body":"Core interface Enables training and prediction .  Prerequisite for other, optional learning method interfaces . Required methods: encode  or both  encodeinput  and  encodetarget . decodeŷ Optional methods: shouldbatch encode!  or both  encodeinput!  and  encodetarget! . Enables use of: methoddataset methoddataloaders predict predictbatch","id":"docs/interfaces.html#core-interface"},{"body":"public   groupobs   —   function Split data container data  data  into different data containers, grouping observations by  f(obs) .","id":"docstrings/FastAI.Datasets.groupobs.html"},{"body":"Interfaces FastAI . jl provides many interfaces that allow extending its functionality .","id":"docs/interfaces.html#interfaces"},{"body":"private   PixelShuffle   —   struct Pixel shuffle layer that upscales height and width of  x  by  scale .  Has reduced checkerboard artifacts compared to  ConvTranspose Introduced in  Real - Time Single Image and Video Super - Resolution Using an EfficientSub - Pixel Convolutional Neural Network .","id":"docstrings/FastAI.Models.PixelShuffle.html"},{"body":"Definitions","id":"docs/glossary.html#definitions"},{"body":"FastAI . jl interfaces","id":"docs/api.html#fastaijl-interfaces"},{"body":"Low - level Full control over data containers . getobs nobs","id":"docs/api.html#low-level-1"},{"body":"Learning task An abstract subtype of  DLPipelines.LearningTask  that represents the problem of learning a mapping from some input type  I  to a target type  T .  For example,  ImageClassificationTask  represents the task of learning to map an image to a class .  See  learning method","id":"docs/glossary.html#learning-task"},{"body":"public   loadtaskdata   —   function Load a task data container for  LearningTask   Task  stored in  dir in a canonical format . Load a data container for  ImageClassificationTask  with observations (input = image, target = class) . If  split  is  true , returns a tuple of the data containers split by the name of the grandparent folder . dir  should contain the data in the following canonical format: dir split (e . g .   “ train ” ,  “ valid ” … ) class (e . g .   “ cat ” ,  “ dog ” … ) image32434 . { jpg/png/ … } … … … Load a data container for  ImageSegmentationTask  with observations (input = image, target = mask) . If  split  is  true , returns a tuple of the data containers split by the name of the grandparent folder .","id":"docstrings/FastAI.Datasets.loadtaskdata.html"},{"body":"public   Datasets   —   module Commonly used datasets and utilities for creating data containers . ToDos: add localization/segmentation datasets add labels for classification datasets","id":"docstrings/FastAI.Datasets.html"},{"body":"public   plotsamples   —   function Plot samples for a  LearningTask / LearningMethod  in a grid .","id":"docstrings/FastAI.plotsamples.html"},{"body":"Training interface Convenience for creating  Learner s . Required methods: methodlossfn methodmodel Enables use of: methodlearner","id":"docs/interfaces.html#training-interface"},{"body":"Learner Finally we bring the model and data loaders together with an optimizer and loss function in a  Learner .  The  Learner  stores all state for training the model .  It also features a powerful, extensible  callback system  enabling checkpointing, hyperparameter scheduling, TensorBoard logging, and many other features .  Here we use the  ToGPU()  callback so that model and batch data will be transferred to an available GPU and  Metrics(accuracy)  to track the classification accuracy during training . With that setup, training  learner  is dead simple:","id":"docs/introduction.html#learner"},{"body":"Measuring performance So how do you know if your GPU is underutilized? If it isn ’ t, then improving data pipeline performance won ’ t help you at all !  One way to check this is to start training and run  > watch -n 0.1 nvidia-smi  in a terminal which displays and refreshs GPU stats every 1/10th of a second .  If  GPU-Util  stays between 90% and 99%, you ’ re good ! If that ’ s not the case, you might see it frantically jumping up and down .  We can get a better estimate of how much training time can be sped up by running the following experiment: Load one batch and run  n  optimization steps on this batch .  The time this takes corresponds to the training time when the GPU does not have to wait for data to be available . Next take your data iterator and time iterating over the first  n  batches  without  an optimization step . The speed of the complete training loop (data loading and optimization) will be around the maximum of either measurement .  Roughly speaking, if 1 .  takes 100 seconds and 2 .  takes 200 seconds, you know that you can speed up training by about a factor of 2 if you reduce data loading time by half, after which the GPU will become the bottleneck . Again, make sure to run each measurement twice so you don ’ t include the compilation time . To find performance bottlenecks in the loading of each observation, you ’ ll want to compare the time it takes to load an observation of the task data container and the time it takes to encode that observation . This will give you a pretty good idea of where the performance bottleneck is .  Note that the encoding performance is often dependent of the method configuration .  If we used  ImageClassification  with input size  (64, 64)  it would be much faster .","id":"docs/background/datapipelines.html#measuring-performance"},{"body":"How to train a model from scratch When training a model from scratch, using a one - cycle learning rate schedule is a good starting point . We ’ ll set up a  Learner  in the usual way .  Note that  Models.xresnet18() , the backbone we ’ re using, doesn ’ t have pretrained weights . And then simply call  fitonecycle! :","id":"docs/notebooks/fitonecycle.html#how-to-train-a-model-from-scratch-"},{"body":"private   invert!   —   function Applies the inverse of the operation  step  to  buf  inplace .   buf  is mutated,","id":"docstrings/FastAI.invert!.html"},{"body":"Learning method interfaces Learning methods form the core of FastAI . jl ’ s high - level API .  See  this tutorial  for a motivation and introduction . Functions for the learning method interfaces always dispatch on a  LearningMethod {T}  where  T  is an abstract subtype of  LearningTask .   LearningTask  only constrains what input and target data look like, while  LearningMethod  defines everything that needs to happen to turn an input into a target and much more .   LearningMethod  should be a  struct  containing configuration .","id":"docs/interfaces.html#learning-method-interfaces"},{"body":"public   fitonecycle!   —   function Fit  learner  for  nepochs  using a one - cycle learning rate schedule .","id":"docstrings/FastAI.fitonecycle!.html"},{"body":"Image classification When doing image classification, we want to train a model to classify a given image into one or more classes .","id":"docs/methods/imageclassification.html#image-classification"},{"body":"private   plotsample   —   function Plot a  sample  of a  method  or  Task  type . See also  plotsample!","id":"docstrings/FastAI.plotsample.html"},{"body":"Inputs We implement  encodeinput  using  DataAugmenation . jl .  Feel free to look at  its documentation , we won ’ t focus on it here . If we test this out on our image, it should give us a 3D array of size  (128, 128, 3) , and indeed it does:","id":"docs/learning_methods.html#inputs"},{"body":"public   ImagePreprocessing   —   struct Converts an image to a color  C , then to a 3D - array of type  T  and finally normalizes the values using  means  and  stds . If no  means  or  stds  are given, uses ImageNet statistics .","id":"docstrings/FastAI.ImagePreprocessing.html"},{"body":"private   freeze   —   function Freeze all parameters in  model , except those in  model[indices] .","id":"docstrings/FastAI.freeze.html"},{"body":"Testing interface Automatically test interfaces . Required methods: mockmodel mocksample  or both  mockinput  and  mocktarget Enables use of: checkmethod_core","id":"docs/interfaces.html#testing-interface"},{"body":"private   run!   —   function Applies the operation  step  inplace to  buf .   buf  is mutated .","id":"docstrings/FastAI.run!.html"},{"body":"How to find a good learning rate Finding a good learning rate is very important when training models .  If it ’ s too large, the training will diverge, and if it ’ s too low, training will be unnecessarily slow . We can use a heuristic called the learning rate finder to find a good learning rate .  It works by training with a very low learning rate and exponentially increasing it very quickly until the loss diverges .  By plotting learning rates against losses we can find a good a value .  We ’ ll set up a  Learner  as usual: Then we use the  LRFinderPhase  which handles the exponential learning rate scheduling and early termination .  It will also reset the model when it is done . To visualize the results, you will need to import a plotting backend . A good rule of thumb is to look at where the loss diverges and divide the learning rate at that point by 10 .  In this case this gives us a learning rate of about  0.1 .  Let ’ s use that to train our model:","id":"docs/notebooks/lrfind.html#how-to-find-a-good-learning-rate"},{"body":"Datasets","id":"docs/api.html#datasets"},{"body":"Mid - level Load and transform data containers . Datasets.datasetpath Datasets.FileDataset Datasets.TableDataset mapobs groupobs joinobs groupobs","id":"docs/api.html#mid-level-1"},{"body":"Encoding and decoding There are only 3 methods we need to define before we can use our learning method to train models and make predictions: DLPipelines.encodeinput  will encode an image so it can be input to a model; DLPipelines.encodetarget  encodes a class so we can compare it with a model output; and DLPipelines.decodeŷ  (write  \\hat<TAB>  for    ̂ ) decodes a model output into a class label Note: These functions always operate on  single  images and classes, even if we want to pass batches to the model later on . While it ’ s not the focus of this tutorial, let ’ s give a quick recap of how the data is encoded and decoded for image classification . Images are cropped to a common size so they can be batched, converted to a 3D array with dimensions (height, width, color channels) and normalized Classes are encoded as one - hot vectors, teaching the model to predict a confidence distribution over all classes .  To decode a predicted one - hot vector, we can simply find the index with the highest value and look up the class label . Each of the methods also takes a  context:: DLPipelines.Context  argument which allows it to behave differently during training, validation and inference .  We ’ ll make use of that to choose a different image crop for each situation .  During training we ’ ll use a random crop for augmentation, while during validation a center crop will ensure that any metrics we track are the same every epoch .  During inference, we won ’ t crop the image so we don ’ t lose any information .","id":"docs/learning_methods.html#encoding-and-decoding"},{"body":"public   filterobs   —   function Return a subset of data container  data  including all indices  i  for which  f(getobs(data, i)) === true .","id":"docstrings/FastAI.Datasets.filterobs.html"},{"body":"Training","id":"docs/api.html#training"},{"body":"Quickstart FastAI . jl makes it easy to train models for common tasks .  For example, we can train an image classification model in just 6 lines .","id":"docs/quickstart.html#quickstart"},{"body":"private   withfields   —   function Replace fields on  x  with given keyword arguments, run  f  and then restore the fields . Every keyword argument is a mapping  (field, value)  or  (field, (setfn!, value)) . setfn!(x, val)  will be used to set the field; if as in the first case none is given  setfield!  is used .","id":"docstrings/FastAI.withfields.html"},{"body":"public   finetune!   —   function Behaves as  fastai.Learner.fine_tune","id":"docstrings/FastAI.finetune!.html"},{"body":"Data containers This tutorial explains what data containers are, how they are used in FastAI . jl and how to create your own .  You are encouraged to follow along in a REPL or a Jupyter notebook and explore the code .  You will find small exercises at the end of some sections to deepen your understanding .","id":"docs/data_containers.html#data-containers"},{"body":"Model Now we create a Flux . jl model .   methodmodel  is a part of the learning method interface that knows how to smartly construct an image classification model from different backbone architectures .  Here a classificiation head with the appropriate number of classes is stacked on a slightly modified version of the ResNet architecture .","id":"docs/introduction.html#model"},{"body":"Type abbreviations In many docstrings, generic types are abbreviated with the following symbols .  Many of these refer to a learning method; the context should make clear which method is meant . DC{T} : A  data container  of type T, meaning a type that implements the data container interface  getobs  and  nobs  where  getobs : (DC{T}, Int) -> Int , that is, each observation is of type  T . I : Type of the unprocessed input in the context of a method . T : Type of the target variable . X : Type of the processed input .  This is fed into a  model , though it may be batched beforehand .   Xs  represents a batch of processed inputs . Y : Type of the model output .   Ys  represents a batch of model outputs . model / M : A learnable mapping  M : (X,) -> Y  or  M : (Xs,) -> Ys .  It predicts an encoded target from an encoded input .  The learnable part of a learning method . Some examples of these in use: LearningTask  represents the task of learning to predict  T  from  I . LearningMethod  is a concrete approach to learning to predict  T  from  I  by using the encoded representations  X  and  Y . encodeinput : (method, context, I) -> X  encodes an input so that a prediction can be made by a model . A task dataset is a  DC{(I, T)} , i . e .  a data container where each observation is a 2 - tuple of an input and a target .","id":"docs/glossary.html#type-abbreviations"},{"body":"Interface DC  is a data container with observations of type D (i . e .   typeof(getobs(::DC<D>, i)::D) ) Transformations: mapobs(f::(D -> E), ::DC<D>)::DC<E> Map a function (or a tuple of functions) over a data container . Tuple(DC<D1>, ..., DC<DN>)::DC<(D1,...,DN)> Combine multiple data containers into a single data container that returns tuples of the each ’ s observations . filterobs(f, DC<D>)::DC<D> Keep only observations for which  f(obs) === true . groupobs(f, DC<D>)::(DC1<D>, ..., DCN<D>)  with  N  the unique return values of  f(::D) joinobs(f, DC<D1>, ..., DC<DN>)::DC<D> Combines N datasets into a single one,  “ concatenating ”  them . Primitive datasets: FileDataset(dir; filterfn) Each file in  dir  is one observation .  Currently implemented in DLDatasets . jl with FileTrees . jl and observation type  FileTrees.File . TableDataset(table) Every row in the table is an observation .  Could use Tables . jl interface to be compatible with tons of packages .","id":"docstrings/FastAI.Datasets.html#interface"},{"body":"Training And that ’ s all we need to start training models !  There are some optional interfaces that make that even easier, but let ’ s use what we have for now . With our  LearningMethod  defined, we can use  methoddataloaders  to turn a dataset into a set of training and validation data loaders that can be thrown into a training loop . Now, with a makeshift model, an optimizer and a loss function we can create a  Learner . From here, you ’ re free to start training using   fit!  or  fitonecycle! .","id":"docs/learning_methods.html#training"},{"body":"Setup FastAI . jl is not registered yet since it depends on some unregistered packages (Flux . jl v0 . 12 . 0 and a Metalhead . jl PR), but you can try it out by installing these manually .  You should be able to install FastAI . jl using the REPL as follows: FastAI . jl also defines  Makie . jl  plotting recipes to visualize data .  If you want to use them, you ’ ll have to install and one of the Makie . jl backends  CairoMakie . jl ,  GLMakie . jl  or  WGLMakie . jl .  For example:","id":"docs/setup.html#setup"},{"body":"Data container A data structure that is used to load a number of data observations separately and lazily .  It defines how many observations it holds with  nobs  and how to load a single observation with  getobs .","id":"docs/glossary.html#data-container"},{"body":"Learning methods This tutorial explains what learning tasks and methods are and how to create your own . In the  quickstart  section, you ’ ve already seen a learning method in action:  ImageClassification .  The learning method abstraction powers FastAI . jl ’ s high - level interface allowing you to make training models for a task simple .  In this tutorial we ’ ll implement our own version of the image classification learning method .  You ’ re encouraged to follow along in a REPL or notebook .  This tutorial can also serve as a template for implementing a custom learning method for your own project . A learning method describes how we need to process data so we can train a model for some task .  In our case, the task we want to solve is to classify an image .  The task defines what kind of data we need, here pairs of images and class labels .  That alone, however, isn ’ t enough to train a model since we can ’ t just throw an image in any format into a model and get a class out .  Almost always the input data needs to be processed in some way before it is input to a model (we call this  encoding ) and the same goes for the model outputs (we call this  decoding ) . So let ’ s say we have an image and a trained model .  How do we make a prediction? First we encode the image, run it through the model, and then decode the output .  Similarly, how we can use a pair of image and class to train a model? We encode both, run the encoded input through the model and then compare the output with the encoded class using a  loss function .  The result tells us how we ’ ll need to update the weights of the model to improve its performance . In essence, the learning method interface allows us to implement these steps and derive useful functionality from it, like training and evaluating models .  Later we ’ ll also cover some optional interfaces that allow us to define other parts of a deep learning project .","id":"docs/learning_methods.html#learning-methods"},{"body":"Outputs encodetarget  is much simpler: The decoding step as well:","id":"docs/learning_methods.html#outputs"},{"body":"private   plotxy!   —   function","id":"docstrings/FastAI.plotxy!.html"},{"body":"public   mapobs   —   function Lazily map  f  over the observations in a data container  data . Lazily map each function in tuple  fs  over the observations in data container  data . Returns a tuple of transformed data containers . Map a  NamedTuple  of functions over  data , turning it into a data container of  NamedTuple s .  Field syntax can be used to select a column of the resulting data container .","id":"docstrings/FastAI.Datasets.mapobs.html"},{"body":"Single - label classification In the simple case, every image will have one class from a list associated with it .  For example, the Cats & Dogs dataset contains pictures of cats and dogs (duh) .   .  The learning method  ImageClassification  handles single - label image classification .  Let ’ s load some samples and visualize them: With a method and a data container, we can easily construct a  Learner : If we have a look at a training batch, we can see that the images are resized and cropped to the same size:","id":"docs/methods/imageclassification.html#single-label-classification"},{"body":"Setup Next to FastAI . jl, you ’ ll need to install","id":"docs/learning_methods.html#setup"},{"body":"private   run   —   function Applies the operation  step  to  data","id":"docstrings/FastAI.run.html"},{"body":"Introduction This tutorial explains the qickstart examples and some core abstractions FastAI . jl is built on . On the  quickstart page , we showed how to train models on common tasks in a few lines of code: Let ’ s unpack each line .","id":"docs/introduction.html#introduction"},{"body":"Finetuning a pretrained model Let ’ s load the image classification dataset ImageNette .  You ’ re free to replace this by any of the other classification datasets in  FastAI.DATASETS . Now we load a pretrained model backbone: We pass it to  methodlearner  which will call  methodmodel  to stack a classification head on top of the backbone: The fine - tuning itself is done with  finetune! .  It follows the same protocol as the  fastai implementation .","id":"docs/notebooks/finetune.html#finetuning-a-pretrained-model"},{"body":"Performant data pipelines Explainer on how data pipelines in FastAI . jl are made fast and how to make yours fast . When training large deep learning models on a GPU we clearly want wait as short as possible for the training to complete .  The hardware bottleneck is usually the GPU power you have available to you .  This means that data pipelines need to be fast enough to keep the GPU at 100% utilization, that is, keep it from  “ starving ” .  Reducing the time the GPU has to wait for the next batch of data directly lowers the training time until the GPU is fully utilized .  There are other ways to reduce training time like using hyperparameter schedules and different optimizers for faster convergence, but we ’ ll only talk about improving GPU utilization here .","id":"docs/background/datapipelines.html#performant-data-pipelines"},{"body":"FastAI Documentation FastAI . jl is inspired by  fastai , and is a repository of best practices for deep learning in Julia .  Its goal is to easily enable creating state - of - the - art models .  FastAI enables the design, training, and delivery of deep learning models that compete with the best in class, using few lines of code . As an example, training an image classification model from scratch is as simple as Please read  the documentation  for more information and see the  setup instructions .","id":"README.html#fastai"},{"body":"Exercises Have a look at the other image classification datasets in  Datasets.DATASETS_IMAGECLASSIFICATION  and change the above code to load a different dataset .","id":"docs/data_containers.html#exercises"},{"body":"Creating data containers from files loadtaskdata  makes it easy to get started when your dataset already comes in the correct format, but alas, datasets come in all different shapes and sizes .  Let ’ s create the same data container, but now using more general functions FastAI . jl provides to get a look behind the scenes .  If each observation in your dataset is a file in a folder,  FileDataset  conveniently creates a data container given a path .  We ’ ll use the path of the downloaded dataset: filedata  is a data container where each observation is a path to a file .  We ’ ll confirm that using  getobs : Next we need to load an image and the corresponding class from the path .  If you have a look at the folder structure of  dir  you can see that the parent folder of each file gives the name of class .  So we can use the following function to load the  (image, class)  pair from a path: Finally, we use  mapobs  to lazily transform each observation and have a data container ready to be used for training an image classifier .","id":"docs/data_containers.html#creating-data-containers-from-files"},{"body":"Task data container / dataset DC{(I, T)} .  A data container containing pairs of inputs and targets .  Used in  methoddataset ,  methoddataloaders  and  evaluate .","id":"docs/glossary.html#task-data-container--dataset"},{"body":"private   withcallbacks   —   function Run  f  with  callbacks  on  learner .  Existing callbacks on  learner  of the same type as in  callbacks  are swapped during the execution of  f .","id":"docstrings/FastAI.withcallbacks.html"},{"body":"High - level Quickly get started training and finetuning models using already implemented learning methods and callbacks . methodlearner fit! fitonecycle! finetune! evaluate learning methods ImageClassification ImageSegmentation callbacks","id":"docs/api.html#high-level"},{"body":"Glossary Terms commonly used in  FastAI . jl .","id":"docs/glossary.html#glossary"},{"body":"Improving performance So, you ’ ve identified the data pipeline as a performance bottleneck .  What now? Before anything else, make sure you ’ re doing the following: Use  DataLoaders.DataLoader  as a data iterator .  If you ’ re using  methoddataloaders  or  methodlearner , this is already the case . Start Julia with multiple threads by specifying the  -t n / -t auto  flag when starting Julia .  If it is successful,  Threads.nthreads()  should be larger than  1 . If the data loading is still slowing down training, you ’ ll probably have to speed up the loading of each observation .  As mentioned above, this can be broken down into observation loading and encoding .  The exact strategy will depend on your use case, but here are some examples . Reduce loading time of image datasets by presizing For many computer vision tasks, you will resize and crop images to a specific size during training for GPU performance reasons .  If the images themselves are large, loading them from disk itself can take some time .  If your dataset consists of 1920x1080 resolution images but you ’ re resizing them to 256x256 during training, you ’ re wasting a lot of time loading the large images .   Presizing  means saving resized versions of each image to disk once, and then loading these smaller versions during training .  We can see the performance difference using ImageNette since it comes in 3 sizes: original, 360px and 180px . Reducing allocations with inplace operations When implementing the  LearningMethod  interface, you have the option to implement  encode!(buf, method, context, sample) , an inplace version of  encode  that reuses a buffer to avoid allocations .  Reducing allocations often speeds up the encoding step and can also reduce the frequency of garbage collector pauses during training which can reduce GPU utilization . Using efficient data augmentation Many kinds of augmentation can be composed efficiently .  A prime example of this are image transformations like resizing, scaling and cropping which are powered by  DataAugmentation . jl .  See  its documentation  to find out how to implement efficient, composable data transformations .","id":"docs/background/datapipelines.html#improving-performance"},{"body":"private   getclassessegmentation   —   function Get the list of classes for classification dataset  name .","id":"docstrings/FastAI.Datasets.getclassessegmentation.html"},{"body":"Introduction In the  quickstart  section, you have already come in contact with data containers .  The following code was used to load a data container for image classification: A data container is any type that holds observations of data and allows us to load them with  getobs  and query the number of observations with  nobs : In this case, each observation is a tuple of an image and the corresponding class; after all, we want to use it for image classification . As you saw above, the  Datasets  submodule provides functions for loading and creating data containers .  We used  Datasets.datasetpath  to download a dataset if it wasn ’ t yet and get the folder it was downloaded to .  Then,  Datasets.loadtaskdata  took the folder and loaded a data container suitable for image classification .  FastAI . jl makes it easy to download the datasets from fastai ’ s collection on AWS Open Datasets .  For the full list, see  Datasets.DATASETS","id":"docs/data_containers.html#introduction"},{"body":"Implementation","id":"docs/learning_methods.html#implementation"},{"body":"Data containers These two lines download and load the  ImageNette  image classification dataset, a small subset of ImageNet with 10 different classes .   dataset  is a  data container  that can be used to load individual observations, here of images and the corresponding labels .  We can use  getobs(dataset, i)  to load the  i - th observation and  nobs  to find out how many observations there are . To train on a different dataset, you could replace  dataset  with other data containers made up of pairs of images and classes .","id":"docs/introduction.html#data-containers"},{"body":"Plotting interface For visualizing observations and predictions using  Makie . jl . Required methods: plotsample! plotxy! Enables use of: plotsamples plotbatch MethodVisualizationCallback","id":"docs/interfaces.html#plotting-interface"},{"body":"Examples","id":"docstrings/FastAI.plotsample.html#examples"},{"body":"Examples Loading and splitting an image classification dataset stored in the same file structure as ImageNette, i . e . : train class1 obs1 … obs2 class1 obs1 … obs2 valid … Turning a container of (input, target) into a container of (x, y) and then an iterator of batches (xs, ys) .  This is pretty much all  methoddataset  and  methoddataloaders  do . Loading an image dataset without labels for inference .","id":"docstrings/FastAI.Datasets.html#examples"},{"body":"Learning method An instance of  DLPipelines.LearningMethod .  A concrete approach to solving a learning task .  Encapsulates the logic and configuration for processing data to train a model and make predictions . See the DLPipelines . jl documentation for more information .","id":"docs/glossary.html#learning-method"},{"body":"public   loadfile   —   function Load a file from disk into the appropriate format .","id":"docstrings/FastAI.Datasets.loadfile.html"},{"body":"Method Here we define an instance of the learning method  ImageClassification  which defines how data is processed before being fed to the model and how model outputs are turned into predictions .   classes  is a vector of strings naming each class, and  (224, 224)  the size of the images that are input to the model . ImageClassification  is a  LearningMethod , an abstraction that encapsulates the logic and configuration for training models on a specific learning task .  See  learning methods  to find out more about how they can be used and how to create custom learning methods .","id":"docs/introduction.html#method"},{"body":"Types sample :  Tuple / NamedTuple  of input ::AbstractArray{2, T} : A 2 - dimensional array with dimensions (height, width) and elements of a color or number type .   Matrix{RGB{Float32}}  is a 2D RGB image, while  Array{Float32, 3}  would be a 3D grayscale image .  If element type is a number it should fall between  0  and  1 .  It is recommended to use the  Gray  color type to represent grayscale images . target : A class .  Has to be an element in  method.classes . x ::AbstractArray{Float32, 3} : a normalized array with dimensions (height, width, color channels) .  See  ImagePreprocessing  for additional information . y ::AbstractVector{Float32} : a one - hot encoded vector of length  length(method.classes)  with true class index   1.  and all other entries  0 . y ::AbstractVector{Float32} : vector of predicted class scores .","id":"docstrings/FastAI.ImageClassification.html#types"},{"body":"High - level Quickly download and load task data containers from the fastai dataset library . Datasets.loadtaskdata Datasets.DATASETS","id":"docs/api.html#high-level-1"},{"body":"Reference This learning method implements the following interfaces: Core interface Plotting interface Training interface Testing interface","id":"docstrings/FastAI.ImageClassification.html#reference"},{"body":"public   plotbatch   —   function Plot an encoded batch of data in a grid .","id":"docstrings/FastAI.plotbatch.html"},{"body":"Mid - level Learner methodmodel adaptmodel methodlossfn Callback","id":"docs/api.html#mid-level"},{"body":"Reasons for low GPU utilization The main cause of low GPU utilization is that the next batch of data is not available after a training step and the GPU has to wait .  This means that in order to get full GPU utilization, loading a batch must not take longer than a training step; and the data must be loaded in the background, so that it is ready the moment the GPU needs it . These issues can be addressed by using worker threads to load multiple batches in parallel keeping the primary thread free; and reducing the time it takes to load a single batch FastAI . jl by default uses  DataLoader  from the  DataLoaders . jl  package which addresses points 1 .  and 2 .  For those familiar with PyTorch, it closely resembles  torch.utils.data.DataLoader .  It also efficiently collates the data by reusing a buffer where supported . We can measure the large performance difference by comparing a naive sequential data iterator with  eachobsparallel , the data iterator that  DataLoader  uses . Running each timer twice to forego compilation time, the sequential iterator takes 20 seconds while the parallel iterator using 11 background threads only takes 2 . 5 seconds .  This certainly isn ’ t a proper benchmark, but it shows the performance can be improved by an order of magnitude with no effort . Beside increasing the amount of compute available with worker threads as above, the data loading performance can also be improved by reducing the time it takes to load a single batch .  Since a batch is made up of some number of observations, this usually boils down to reducing the loading time of a single observation .  If you ’ re using the  LearningMethod  API, this can be further broken down into the loading and encoding part .","id":"docs/background/datapipelines.html#reasons-for-low-gpu-utilization"},{"body":"Learning method struct Now let ’ s get to it !  The first thing we need to do is to create a  DLPipelines.LearningTask  and a  DLPipelines.LearningMethod  struct .  The  task  represents learning a mapping from an image to a class, while the  method  is a concrete way to solve the task .  The distinction is made since in practice there can be multiple methods to solve a task .  After this part, we ’ ll only deal with  LearningMethod . The  LearningMethod   struct  should contain all the configuration needed for encoding and decoding the data .  We ’ ll keep it simple here and include a list of the classes and the image dimensions input to the model .  The reference implementation  FastAI.ImageClassification  of course has many more parameters that can be configured . Now we can create an instance of it, though of course it can ’ t do anything (yet ! ) .","id":"docs/learning_methods.html#learning-method-struct"},{"body":"public   datasetpath   —   function Return the folder that dataset  name  is stored . If it hasn ’ t been downloaded yet, you will be asked if you want to download it .  See  Datasets.DATASETS  for a list of available datasets .","id":"docstrings/FastAI.Datasets.datasetpath.html"},{"body":"private   plotsample!   —   function Plot a  sample  of a  method  or  Task  type on figure or axis  f . See also  plotsample","id":"docstrings/FastAI.plotsample!.html"},{"body":"Splitting a data container into subsets Until now, we ’ ve only created a single data container containing all observations in a dataset .  In practice, though, you ’ ll want to have at least a training and validation split .  The easiest way to get these is to randomly split your data container into two parts .  Here we split  data  into 80% training and 20% validation data .  Note the use of  shuffleobs  to make sure each split has approximately the same class distribution . This is great for experimenting, but where possible you will want to use the official training/validation split for a dataset .  Consider the image classification dataset folder structure: As you can see, the grandparent folder of each image indicates which split it is a part of .   groupobs  allows us to partition a data container using a function .  Let ’ s use it to split  filedata  based on the name of the grandparent directory .  (We can ’ t reuse  data  for this since it no longer carries the file information . ) Using this official split, it will be easier to compare the performance of your results with those of others ’ .","id":"docs/data_containers.html#splitting-a-data-container-into-subsets"},{"body":"private   getclassesclassification   —   function Get the list of classes for classification dataset  name .","id":"docstrings/FastAI.Datasets.getclassesclassification.html"},{"body":"Image classification Train an image classifier from scratch: Or finetune a pretrained model:","id":"docs/quickstart.html#image-classification"}]