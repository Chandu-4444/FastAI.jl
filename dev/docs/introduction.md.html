<HTML><head><title>Introduction</title><link href=../template/hugobook.css rel=stylesheet ></link><meta content=Type=text/html; charset=utf-8 http-equiv=Content-Type ></meta></head><body><input onclick=toggleMenu() id=menu-control class=hidden toggle type=checkbox ></input><input id=toc-control type=checkbox class=hidden toggle ></input><main class=container flex ><aside id=menu-container class=book-menu ><nav class=book-menu-content ><h2 id=title >FastAI.jl</h2><div id=sidebar ><div class=doctree ><body><ul><li><p><a href=../README.md.html title= >README</a></p></li><li><p><a href=setup.md.html title= >Setup</a></p></li><li><p><a href=quickstart.md.html title= >Quickstart</a></p></li><li><p>Tutorials</p><ul><li><p><a href=introduction.md.html title= >Introduction</a></p></li><li><p><a href=data_containers.md.html title= >Data containers</a></p></li><li><p><a href=learning_methods.md.html title= >Learning methods</a></p></li><li><p><a href=notebooks/serialization.ipynb.html title= >Saving and loading models</a></p></li><li><p><a href=tutorials/presizing.ipynb.html title= >Presizing vision datasets</a></p></li></ul></li><li><p>Learning tasks</p><ul><li><p><a href=methods/imageclassification.md.html title= >Image classification</a></p></li><li><p><a href=notebooks/imagesegmentation.ipynb.html title= >Image segmentation</a></p></li><li><p><a href=notebooks/keypointregression.ipynb.html title= >Keypoint regression</a></p></li></ul></li><li><p>How To</p><ul><li><p><a href=notebooks/fitonecycle.ipynb.html title= >Train a model from scratch</a></p></li><li><p><a href=notebooks/finetune.ipynb.html title= >Finetune a pretrained model</a></p></li><li><p><a href=notebooks/lrfind.ipynb.html title= >Find a good learning rate</a></p></li><li><p><a href=howto/augmentvision.md.html title= >Augment vision data</a></p></li><li><p><a href=notebooks/how_to_visualize.ipynb.html title= >Visualize data</a></p></li><li><p><a href=howto/logtensorboard.md.html title= >Log to TensorBoard</a></p></li></ul></li><li><p>Reference</p><ul><li><p><a href=../REFERENCE.html title= >Docstrings</a></p></li><li><p><a href=interfaces.md.html title= >Interfaces</a></p></li><li><p><a href=api.md.html title= >API</a></p></li><li><p><a href=glossary.md.html title= >Glossary</a></p></li></ul></li><li><p>Background</p><ul><li><p><a href=background/datapipelines.md.html title= >Performant data pipelines</a></p></li></ul></li></ul></body></div></div></nav></aside><div class=book-page ><header class=book-header ></header><article><h1 id=introduction >Introduction</h1><p><em>This tutorial explains the qickstart examples and some core abstractions FastAI.jl is built on.</em></p><div class=cellcontainer ><pre result=false cell=main lang=julia style=display:none; ><code>using FastAI
</code></pre></div><p>On the <a href=./quickstart.ipynb.html title= >quickstart page</a>, we showed how to train models on common tasks in a few lines of code:</p><pre lang=julia ><code>using FastAI

path = datasetpath(&quot;imagenette2-160&quot;)
dataset = loadtaskdata(path, ImageClasssification)
method = ImageClassification(Datasets.getclassesclassification(&quot;imagenette2-160&quot;), (160, 160))
dls = methoddataloaders(dataset, method, 16)
model = methodmodel(method, Models.xresnet18())
learner = Learner(model, dls, ADAM(), methodlossfn(method), ToGPU(), Metrics(accuracy))
fitonecycle!(learner, 5)
</code></pre><p>Let’s unpack each line.</p><h2 id=data-containers >Data containers</h2><div class=cellcontainer ><pre cell=main lang=julia ><code>path = datasetpath(&quot;imagenette2-160&quot;)
dataset = loadtaskdata(path, ImageClasssification)
</code></pre><pre class=coderesult ><code>LoadError("string", 2, UndefVarError(:ImageClasssification))</code></pre></div><p>These two lines download and load the <a href=https://github.com/fastai/imagenette title= >ImageNette</a> image classification dataset, a small subset of ImageNet with 10 different classes. <code>dataset</code> is a <a href=./data_containers.md.html title= >data container</a> that can be used to load individual observations, here of images and the corresponding labels. We can use <code>getobs(dataset, i)</code> to load the <code>i</code>-th observation and <code>nobs</code> to find out how many observations there are.</p><div class=cellcontainer ><pre cell=main lang=julia ><code>image, class = getobs(dataset, 1000)
@show class
image
</code></pre><pre class=coderesult ><code>LoadError("string", 1, UndefVarError(:dataset))</code></pre></div><div class=cellcontainer ><pre cell=main lang=julia ><code>nobs(dataset)
</code></pre><pre class=coderesult ><code>LoadError("string", 1, UndefVarError(:dataset))</code></pre></div><p>To train on a different dataset, you could replace <code>dataset</code> with other data containers made up of pairs of images and classes.</p><h2 id=method >Method</h2><div class=cellcontainer ><pre cell=main lang=julia ><code>classes = Datasets.getclassesclassification(&quot;imagenette2-160&quot;)
method = ImageClassification(classes, (160, 160))
</code></pre><pre class=coderesult ><code>ImageClassification{2}(
    classes = ["n01440764", "n02102040", "n02979186", "n03000684", "n03028079", "n03394916", "…], 
    projections = ProjectiveTransforms{2}(
    sz = (160, 160), 
    buffered = true, 
    augmentations = Identity()
), 
    imageprepocessing = ImagePreprocessing(
    C = ColorTypes.RGB{FixedPointNumbers.N0f8}, 
    T = Float32, 
    buffered = true, 
    augmentations = Identity()
)
)</code></pre></div><p>Here we define an instance of the learning method <a href=../REFERENCE/FastAI.ImageClassification.html ><code>ImageClassification</code></a> which defines how data is processed before being fed to the model and how model outputs are turned into predictions. <code>classes</code> is a vector of strings naming each class, and <code>(224, 224)</code> the size of the images that are input to the model.</p><p><code>ImageClassification</code> is a <code>LearningMethod</code>, an abstraction that encapsulates the logic and configuration for training models on a specific learning task. See <a href=./learning_methods.md.html title= >learning methods</a> to find out more about how they can be used and how to create custom learning methods.</p><h2 id=data-loaders >Data loaders</h2><div class=cellcontainer ><pre cell=main lang=julia ><code>dls = methoddataloaders(dataset, method, 16)
</code></pre><pre class=coderesult ><code>LoadError("string", 1, UndefVarError(:dataset))</code></pre></div><p>Next we turn the data container into training and validation data loaders. These take care of efficiently loading batches of data (by default in parallel). The observations are already preprocessed using the information in <code>method</code> and then batched together. Let’s look at a single batch:</p><div class=cellcontainer ><pre cell=main lang=julia ><code>traindl, valdl = dls
(xs, ys), _ = iterate(traindl)
summary.((xs, ys))
</code></pre><pre class=coderesult ><code>LoadError("string", 1, UndefVarError(:dls))</code></pre></div><p><code>xs</code> is a batch of cropped and normalized images with dimensions <code>(height, width, color channels, batch size)</code> and <code>ys</code> a batch of one-hot encoded classes with dimensions <code>(classes, batch size)</code>.</p><h2 id=model >Model</h2><div class=cellcontainer ><pre cell=main lang=julia ><code>model = methodmodel(method, Models.xresnet18())
</code></pre><pre class=coderesult ><code>Chain(Chain(Chain(Conv((3, 3), 3=>32), BatchNorm(32, relu)), Chain(Conv((3, 3), 32=>64), BatchNorm(64, relu)), Chain(Conv((3, 3), 64=>64), BatchNorm(64, relu)), MaxPool((3, 3), pad=1, stride=2), Chain(FastAI.Models.ResBlock(Chain(Chain(Conv((3, 3), 64=>64), BatchNorm(64, relu)), Chain(Conv((3, 3), 64=>64), BatchNorm(64))), identity, identity), FastAI.Models.ResBlock(Chain(Chain(Conv((3, 3), 64=>64), BatchNorm(64, relu)), Chain(Conv((3, 3), 64=>64), BatchNorm(64))), identity, identity)), Chain(FastAI.Models.ResBlock(Chain(Chain(Conv((3, 3), 64=>128), BatchNorm(128, relu)), Chain(Conv((3, 3), 128=>128), BatchNorm(128))), Chain(Conv((1, 1), 64=>128), BatchNorm(128, relu)), MeanPool((2, 2))), FastAI.Models.ResBlock(Chain(Chain(Conv((3, 3), 128=>128), BatchNorm(128, relu)), Chain(Conv((3, 3), 128=>128), BatchNorm(128))), identity, identity)), Chain(FastAI.Models.ResBlock(Chain(Chain(Conv((3, 3), 128=>256), BatchNorm(256, relu)), Chain(Conv((3, 3), 256=>256), BatchNorm(256))), Chain(Conv((1, 1), 128=>256), BatchNorm(256, relu)), MeanPool((2, 2))), FastAI.Models.ResBlock(Chain(Chain(Conv((3, 3), 256=>256), BatchNorm(256, relu)), Chain(Conv((3, 3), 256=>256), BatchNorm(256))), identity, identity)), Chain(FastAI.Models.ResBlock(Chain(Chain(Conv((3, 3), 256=>512), BatchNorm(512, relu)), Chain(Conv((3, 3), 512=>512), BatchNorm(512))), Chain(Conv((1, 1), 256=>512), BatchNorm(512, relu)), MeanPool((2, 2))), FastAI.Models.ResBlock(Chain(Chain(Conv((3, 3), 512=>512), BatchNorm(512, relu)), Chain(Conv((3, 3), 512=>512), BatchNorm(512))), identity, identity))), Chain(Parallel(vcat, AdaptiveMeanPool((1, 1)), AdaptiveMaxPool((1, 1))), flatten, Chain(BatchNorm(1024), identity, Dense(1024, 512, relu; bias=false)), Chain(BatchNorm(512), identity, Dense(512, 10; bias=false))))</code></pre></div><p>Now we create a Flux.jl model. <a href=../REFERENCE/DLPipelines.methodmodel.html ><code>DLPipelines.methodmodel</code></a> is a part of the learning method interface that knows how to smartly construct an image classification model from different backbone architectures. Here a classificiation head with the appropriate number of classes is stacked on a slightly modified version of the ResNet architecture.</p><h2 id=learner >Learner</h2><div class=cellcontainer ><pre cell=main lang=julia ><code>learner = Learner(model, dls, ADAM(), methodlossfn(method), ToGPU(), Metrics(accuracy))
</code></pre><pre class=coderesult ><code>LoadError("string", 1, UndefVarError(:dls))</code></pre></div><p>Finally we bring the model and data loaders together with an optimizer and loss function in a <code>Learner</code>. The <code>Learner</code> stores all state for training the model. It also features a powerful, extensible <a href=https://lorenzoh.github.io/FluxTraining.jl/dev/docs/callbacks/reference.html title= >callback system</a> enabling checkpointing, hyperparameter scheduling, TensorBoard logging, and many other features. Here we use the <code>ToGPU()</code> callback so that model and batch data will be transferred to an available GPU and <code>Metrics(accuracy)</code> to track the classification accuracy during training.</p><p>With that setup, training <code>learner</code> is dead simple:</p><pre lang=julia ><code>fitonecycle!(learner, 5)
</code></pre></article><footer class=book-footer ></footer></div><aside class=book-toc ><nav id=toc class=book-toc-content ><ul><li><a href=#introduction >Introduction</a><ul><li><a href=#data-containers >Data containers</a><ul></ul></li><li><a href=#method >Method</a><ul></ul></li><li><a href=#data-loaders >Data loaders</a><ul></ul></li><li><a href=#model >Model</a><ul></ul></li><li><a href=#learner >Learner</a><ul></ul></li></ul></li></ul></nav></aside></main></body></HTML>