<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8" />
    <!--     <link rel="icon" href="/favicon.png" /> -->
    <meta name="viewport" content="width=device-width, initial-scale=1" /> <meta http-equiv="content-security-policy" content=""><title>FastAI.jl</title>
	<link rel="stylesheet" href="/FastAI.jl/internal/assets/pages/__layout.svelte-5b348943.css">
	<link rel="stylesheet" href="/FastAI.jl/internal/assets/documentloader-c3b38c78.css">
	<link rel="modulepreload" href="/FastAI.jl/internal/start-01fb7bee.js">
	<link rel="modulepreload" href="/FastAI.jl/internal/chunks/vendor-82c3ebfd.js">
	<link rel="modulepreload" href="/FastAI.jl/internal/chunks/paths-4b3c6e7e.js">
	<link rel="modulepreload" href="/FastAI.jl/internal/pages/__layout.svelte-4bac7188.js">
	<link rel="modulepreload" href="/FastAI.jl/internal/pages/_version_/_...documentId_.svelte-7aaa8049.js">
	<link rel="modulepreload" href="/FastAI.jl/internal/chunks/documentloader-1ca571c2.js">
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Fira+Mono:wght@400;500&display=swap');
        @import url('https://fonts.googleapis.com/css2?family=IBM+Plex+Sans:wght@400;600&display=swap');
    </style>
</head>

<body>
    <div id="svelte">




<div class="flex lg:flex-row flex-col lg:sticky lg:h-full"><div class="gutter">



<div class="header border-gray-200 flex flex-col w-full border-b-[1px] lg:sticky lg:top-0 lg:w-72 lg:[min-width:18rem;] lg:max-h-screen lg:min-h-screen lg:h-screen lg:border-b-0 lg:border-r-[1px]"><div class="title flex flex-row items-center p-3"><span class="name content-center text-xl flex-grow font-bold"><a href="/FastAI.jl/dev/documents/README.md">FastAI.jl</a></span>
		<span class="openmenu cursor-pointer flex lg:hidden">
<svg data-carbon-icon="Menu24" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" width="24" height="24" preserveAspectRatio="xMidYMid meet" aria-hidden focusable="false"><path d="M3 18H21V19.5H3zM3 13.5H21V15H3zM3 9H21V10.5H3zM3 4.5H21V6H3z"></path>
    
  </svg></span></div>

	<div class="menu p-3 flex-col hidden [box-shadow:inset_0_0_8px_rgba(0,0,0,.1)] border-t-[1px] lg:flex lg:[box-shadow:none] lg:border-t-0 "><div class="group svelte-1spyzn"><div class="grouptitle svelte-1spyzn">Search</div>
			<div class="searchwidget svelte-1lm1fh6" style="width: 100%; flex-grow: 3">
	<div class="searchfield svelte-1lm1fh6">
<svg data-carbon-icon="Search20" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32" fill="currentColor" width="20" height="20" preserveAspectRatio="xMidYMid meet" style="fill:gray; display:inline" aria-hidden focusable="false"><path d="M29,27.5859l-7.5521-7.5521a11.0177,11.0177,0,1,0-1.4141,1.4141L27.5859,29ZM4,13a9,9,0,1,1,9,9A9.01,9.01,0,0,1,4,13Z"></path>
    
  </svg>
		<input type="text" placeholder="Search for text or code" style="margin-left: 4px; flex-grow: 2; outline:none; background: inherit;" class="svelte-1lm1fh6" value="">

			
			</div>
	
</div></div>

		<div class="group svelte-1spyzn"><div class="grouptitle svelte-1spyzn">Pages</div>
			<div class="ml-1 mr-1"><div class=""><a class="link svelte-1uqp1tf" href="/FastAI.jl/dev/documents/README.md">Overview</a></div><div class=""><a class="link svelte-1uqp1tf" href="/FastAI.jl/dev/documents/docs/setup.md">Setup</a></div><div class=""><a class="link svelte-1uqp1tf" href="/FastAI.jl/dev/documents/notebooks/quickstart.ipynb">Quickstart</a></div><div class="groupcontainer svelte-1uqp1tf"><div class="groupname svelte-1uqp1tf">
<svg data-carbon-icon="CaretDownGlyph" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 8 4" fill="currentColor" width="8" height="4" preserveAspectRatio="xMidYMid meet" style="display:inline; width: 8px" aria-hidden focusable="false"><path d="M8 0L4 4 0 0z"></path>
    
  </svg>
					<span class="pl-1">Core</span></div>
				<div class="group svelte-1uqp1tf"><div class="groupcontainer svelte-1uqp1tf"><div class="groupname svelte-1uqp1tf">
<svg data-carbon-icon="CaretRightGlyph" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 5 8" fill="currentColor" width="5" height="8" preserveAspectRatio="xMidYMid meet" style="display:inline; width: 8px" aria-hidden focusable="false"><path d="M0 0L5 4 0 8z"></path>
    
  </svg>
					<span class="pl-1">Tutorials</span></div>
				
			</div><div class="groupcontainer svelte-1uqp1tf"><div class="groupname svelte-1uqp1tf">
<svg data-carbon-icon="CaretRightGlyph" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 5 8" fill="currentColor" width="5" height="8" preserveAspectRatio="xMidYMid meet" style="display:inline; width: 8px" aria-hidden focusable="false"><path d="M0 0L5 4 0 8z"></path>
    
  </svg>
					<span class="pl-1">How-to</span></div>
				
			</div><div class="groupcontainer svelte-1uqp1tf"><div class="groupname svelte-1uqp1tf">
<svg data-carbon-icon="CaretRightGlyph" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 5 8" fill="currentColor" width="5" height="8" preserveAspectRatio="xMidYMid meet" style="display:inline; width: 8px" aria-hidden focusable="false"><path d="M0 0L5 4 0 8z"></path>
    
  </svg>
					<span class="pl-1">Background</span></div>
				
			</div>
					</div>
			</div><div class="groupcontainer svelte-1uqp1tf"><div class="groupname svelte-1uqp1tf">
<svg data-carbon-icon="CaretDownGlyph" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 8 4" fill="currentColor" width="8" height="4" preserveAspectRatio="xMidYMid meet" style="display:inline; width: 8px" aria-hidden focusable="false"><path d="M8 0L4 4 0 0z"></path>
    
  </svg>
					<span class="pl-1">Computer vision</span></div>
				<div class="group svelte-1uqp1tf"><div class="groupcontainer svelte-1uqp1tf"><div class="groupname svelte-1uqp1tf">
<svg data-carbon-icon="CaretRightGlyph" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 5 8" fill="currentColor" width="5" height="8" preserveAspectRatio="xMidYMid meet" style="display:inline; width: 8px" aria-hidden focusable="false"><path d="M0 0L5 4 0 8z"></path>
    
  </svg>
					<span class="pl-1">Tasks</span></div>
				
			</div><div class="groupcontainer svelte-1uqp1tf"><div class="groupname svelte-1uqp1tf">
<svg data-carbon-icon="CaretRightGlyph" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 5 8" fill="currentColor" width="5" height="8" preserveAspectRatio="xMidYMid meet" style="display:inline; width: 8px" aria-hidden focusable="false"><path d="M0 0L5 4 0 8z"></path>
    
  </svg>
					<span class="pl-1">How-To</span></div>
				
			</div>
					</div>
			</div><div class="groupcontainer svelte-1uqp1tf"><div class="groupname svelte-1uqp1tf">
<svg data-carbon-icon="CaretDownGlyph" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 8 4" fill="currentColor" width="8" height="4" preserveAspectRatio="xMidYMid meet" style="display:inline; width: 8px" aria-hidden focusable="false"><path d="M8 0L4 4 0 0z"></path>
    
  </svg>
					<span class="pl-1">Tabular data</span></div>
				<div class="group svelte-1uqp1tf"><div class="groupcontainer svelte-1uqp1tf"><div class="groupname svelte-1uqp1tf">
<svg data-carbon-icon="CaretRightGlyph" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 5 8" fill="currentColor" width="5" height="8" preserveAspectRatio="xMidYMid meet" style="display:inline; width: 8px" aria-hidden focusable="false"><path d="M0 0L5 4 0 8z"></path>
    
  </svg>
					<span class="pl-1">Tasks</span></div>
				
			</div>
					</div>
			</div></div></div>

		
		

		
		<div class="flex-col hidden md:flex group svelte-1spyzn"><div class="grouptitle svelte-1spyzn">This page</div>
				<a class="linktointeractive svelte-1spyzn" href="/FastAI.jl/dev/i?id=documents/docs/fastai_api_comparison.md">Open in interactive viewer</a></div>
		<div class="group svelte-1spyzn"><div class="grouptitle svelte-1spyzn">Links</div>
			<a href="https://github.com/FluxML/FastAI.jl" class="text-gray-600 hover:text-gray-900">
<svg data-carbon-icon="LogoGithub24" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32" fill="currentColor" width="24" height="24" preserveAspectRatio="xMidYMid meet" aria-hidden focusable="false"><path fill-rule="evenodd" d="M16,2a14,14,0,0,0-4.43,27.28c.7.13,1-.3,1-.67s0-1.21,0-2.38c-3.89.84-4.71-1.88-4.71-1.88A3.71,3.71,0,0,0,6.24,22.3c-1.27-.86.1-.85.1-.85A2.94,2.94,0,0,1,8.48,22.9a3,3,0,0,0,4.08,1.16,2.93,2.93,0,0,1,.88-1.87c-3.1-.36-6.37-1.56-6.37-6.92a5.4,5.4,0,0,1,1.44-3.76,5,5,0,0,1,.14-3.7s1.17-.38,3.85,1.43a13.3,13.3,0,0,1,7,0c2.67-1.81,3.84-1.43,3.84-1.43a5,5,0,0,1,.14,3.7,5.4,5.4,0,0,1,1.44,3.76c0,5.38-3.27,6.56-6.39,6.91a3.33,3.33,0,0,1,.95,2.59c0,1.87,0,3.38,0,3.84s.25.81,1,.67A14,14,0,0,0,16,2Z"></path>
    
  </svg></a></div></div>
</div></div>
		<div class="content h-max p-4 sm:w-full md:max-w-2xl"><div class="document document"><div class="markdown">
			<div class="md ">
			<h1 class="">
			fastai API comparison</h1>
			<p class="">
			FastAI.jl is in many ways similar to the original Python 
			



			fastai
	
			, but also has its differences. This reference goes through all the sections in the 
			<span class="linkexternal"><a href="https://arxiv.org/abs/2002.04688" class="svelte-1jfpqr">
			fastai: A Layered API for Deep Learning
		
<svg data-carbon-icon="Link16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32" fill="currentColor" width="16" height="16" preserveAspectRatio="xMidYMid meet" style="display:inline; transform: translate(-1px,-2px)" aria-hidden focusable="false"><path d="M29.25,6.76a6,6,0,0,0-8.5,0l1.42,1.42a4,4,0,1,1,5.67,5.67l-8,8a4,4,0,1,1-5.67-5.66l1.41-1.42-1.41-1.42-1.42,1.42a6,6,0,0,0,0,8.5A6,6,0,0,0,17,25a6,6,0,0,0,4.27-1.76l8-8A6,6,0,0,0,29.25,6.76Z"></path><path d="M4.19,24.82a4,4,0,0,1,0-5.67l8-8a4,4,0,0,1,5.67,0A3.94,3.94,0,0,1,19,14a4,4,0,0,1-1.17,2.85L15.71,19l1.42,1.42,2.12-2.12a6,6,0,0,0-8.51-8.51l-8,8a6,6,0,0,0,0,8.51A6,6,0,0,0,7,28a6.07,6.07,0,0,0,4.28-1.76L9.86,24.82A4,4,0,0,1,4.19,24.82Z"></path>
    
  </svg></a>
</span>
			 paper and comments what the interfaces for the same functionality in FastAI.jl are, and where they differ or functionality is still missing.</p>
			<h2 class="">
			Applications</h2>
			<p class="">
			FastAI.jl’s own data block API makes it possible to derive every part of a high-level interface with a unified API across tasks. Instead it suffices to create a learning task and based on the blocks and encodings specified the proper model builder, loss function, and visualizations are implemented (see below). For a high-level API, a complete 
			<span class="code"><code class="codeinline ">
			Learner</code></span>
			 can be constructed using 
			


<a href="/FastAI.jl/dev/references/FastAI.tasklearner" class="reference symbol ">
			<span class="code"><code class="codeinline ">
			tasklearner</code></span></a>
	
			 without much boilerplate. There are some helper functions for  creating these learning tasks, for example 
			


<a href="/FastAI.jl/dev/references/FastAI.Vision.ImageClassificationSingle" class="reference symbol ">
			<span class="code"><code class="codeinline ">
			ImageClassificationSingle</code></span></a>
	
			 and 
			


<a href="/FastAI.jl/dev/references/FastAI.Vision.ImageSegmentation" class="reference symbol ">
			<span class="code"><code class="codeinline ">
			ImageSegmentation</code></span></a>
	
			.</p>
			<p class="">
			FastAI.jl additionally has a unified API for registering and discovering functionality across applications also based on the data block abstraction.  
			<span class="code"><code class="codeinline ">
			finddatasets</code></span>
			 and 
			<span class="code"><code class="codeinline ">
			loaddataset</code></span>
			 let you quickly load common datasets matching some data modality and 
			<span class="code"><code class="codeinline ">
			findlearningtask</code></span>
			 lets you find learning task helpers for common tasks. See 
			


<a href="/FastAI.jl/dev/documents/docs/discovery.md" class="reference document ">
			the discovery tutorial</a>
	
			 for more info.</p>
			<h3 class="">
			Vision</h3>
			<p class="">
			Computer vision is the most developed part of FastAI.jl with good support for different tasks and optimized data pipelines with N-dimensional images, masks and keypoints. See the tutorial section for many examples.</p>
			<h3 class="">
			Tabular</h3>
			<p class="">
			Support for tabular data is merged into master but is lacking documentation which will come with the next release (0.2.0).</p>
			<h3 class="">
			Deployment</h3>
			<p class="">
			Through FastAI.jl’s 
			



			<span class="code"><code class="codeinline ">
			LearningTask</code></span>
			 interface
	
			, the data processing logic is decoupled from the dataset creation and training and can be easily serialized and loaded to make predictions. See the tutorial on 
			


<a href="/FastAI.jl/dev/documents/notebooks/serialization.ipynb" class="reference document ">
			saving and loading models</a>
	
			.</p>
			<span class="hr "></span>
			<p class="">
			There is no integration (yet!) for text and collaborative filtering applications.</p>
			<h2 class="">
			High
			-
			level API</h2>
			<h3 class="">
			High
			-
			level API foundations</h3>
			<p class="">
			FastAI.jl also has a data block API but it differs from fastai’s in a number of ways. In the Julia package it only handles the data encoding and decoding part, and doesn’t concern itself with creating datasets. For dataset loading, see the 
			


<a href="/FastAI.jl/dev/documents/docs/data_containers.md" class="reference document ">
			data container API</a>
	
			. As mentioned above, the high-level application-specific logic is also derived from the data block API. To use it you need to specify a tuple of input and target blocks as well as a tuple of encodings that are applied to the data. The encodings  are invertible data-specific data processing steps which correspond to 
			<span class="code"><code class="codeinline ">
			fastai.Transform</code></span>
			s. As in fastai, dispatch is used to transform applicable data and pass other data through unchanged. Unlike in fastai, there are no default steps associated with a block, allowing greater flexibility.</p>
			<p class="">
			We can create a 
			<span class="code"><code class="codeinline ">
			BlockTask</code></span>
			 (similar to 
			<span class="code"><code class="codeinline ">
			fastai.DataBlock</code></span>
			) and get information about the representations the data goes through.</p>
			<div class="codecell ">
			<div class="codeinput ">
			<pre class="codeblock codeblock svelte-vj8ryq"><code class="svelte-vj8ryq">
			<span class="julia ">
			<span class="USING ">
			<span class="USING ">
			using</span>
			<span class="DOT ">
			<span class="WHITESPACE ">
			 </span>
			


<a href="/FastAI.jl/dev/references/FastAI" class="reference symbol ">
			FastAI</a>
	</span></span>
			<span class="NEWLINE_WS ">
			
</span>
			<span class="IMPORT ">
			<span class="COLON ">
			<span class="IMPORT ">
			import</span>
			<span class="DOT ">
			<span class="WHITESPACE ">
			 </span>
			


<a href="/FastAI.jl/dev/references/FastAI" class="reference symbol ">
			FastAI</a>
	</span>
			<span class="COLON ">
			:</span>
			<span class="DOT ">
			<span class="WHITESPACE ">
			 </span>
			


<a href="/FastAI.jl/dev/references/DataAugmentation.Image" class="reference symbol ">
			Image</a>
	</span></span></span>
			<span class="NEWLINE_WS ">
			
</span>
			<span class="NEWLINE_WS ">
			
</span>
			<span class="EQ ">
			<span class="IDENTIFIER ">
			task</span>
			<span class="WHITESPACE ">
			 </span>
			<span class="EQ ">
			=</span>
			<span class="WHITESPACE ">
			 </span>
			<span class="CALL ">
			


<a href="/FastAI.jl/dev/references/FastAI.BlockTask" class="reference symbol ">
			BlockTask</a>
	
			<span class="LPAREN ">
			(</span>
			<span class="NEWLINE_WS ">
			
    </span>
			<span class="TUPLE ">
			<span class="LPAREN ">
			(</span>
			<span class="CALL ">
			<span class="CURLY ">
			


<a href="/FastAI.jl/dev/references/DataAugmentation.Image" class="reference symbol ">
			Image</a>
	
			<span class="LBRACE ">
			{</span>
			<span class="INTEGER ">
			2</span>
			<span class="RBRACE ">
			}</span></span>
			<span class="LPAREN ">
			(</span>
			<span class="RPAREN ">
			)</span></span>
			<span class="COMMA ">
			,</span>
			<span class="WHITESPACE ">
			 </span>
			<span class="CALL ">
			<span class="CURLY ">
			


<a href="/FastAI.jl/dev/references/FastAI.Vision.Mask" class="reference symbol ">
			Mask</a>
	
			<span class="LBRACE ">
			{</span>
			<span class="INTEGER ">
			2</span>
			<span class="RBRACE ">
			}</span></span>
			<span class="LPAREN ">
			(</span>
			<span class="VECT ">
			<span class="LSQUARE ">
			[</span>
			<span class="DQUOTE ">
			&quot;</span>
			<span class="STRING ">
			foreground</span>
			<span class="DQUOTE ">
			&quot;</span>
			<span class="COMMA ">
			,</span>
			<span class="WHITESPACE ">
			 </span>
			<span class="DQUOTE ">
			&quot;</span>
			<span class="STRING ">
			background</span>
			<span class="DQUOTE ">
			&quot;</span>
			<span class="RSQUARE ">
			]</span></span>
			<span class="RPAREN ">
			)</span></span>
			<span class="RPAREN ">
			)</span></span>
			<span class="COMMA ">
			,</span>
			<span class="NEWLINE_WS ">
			
    </span>
			<span class="TUPLE ">
			<span class="LPAREN ">
			(</span>
			<span class="NEWLINE_WS ">
			
        </span>
			<span class="CALL ">
			


<a href="/FastAI.jl/dev/references/FastAI.Vision.ProjectiveTransforms" class="reference symbol ">
			ProjectiveTransforms</a>
	
			<span class="LPAREN ">
			(</span>
			<span class="TUPLE ">
			<span class="LPAREN ">
			(</span>
			<span class="INTEGER ">
			128</span>
			<span class="COMMA ">
			,</span>
			<span class="WHITESPACE ">
			 </span>
			<span class="INTEGER ">
			128</span>
			<span class="RPAREN ">
			)</span></span>
			<span class="RPAREN ">
			)</span></span>
			<span class="COMMA ">
			,</span>
			<span class="NEWLINE_WS ">
			
        </span>
			<span class="CALL ">
			


<a href="/FastAI.jl/dev/references/FastAI.Vision.ImagePreprocessing" class="reference symbol ">
			ImagePreprocessing</a>
	
			<span class="LPAREN ">
			(</span>
			<span class="RPAREN ">
			)</span></span>
			<span class="COMMA ">
			,</span>
			<span class="NEWLINE_WS ">
			
        </span>
			<span class="CALL ">
			


<a href="/FastAI.jl/dev/references/DataAugmentation.OneHot" class="reference symbol ">
			OneHot</a>
	
			<span class="LPAREN ">
			(</span>
			<span class="RPAREN ">
			)</span></span>
			<span class="COMMA ">
			,</span>
			<span class="NEWLINE_WS ">
			
    </span>
			<span class="RPAREN ">
			)</span></span>
			<span class="NEWLINE_WS ">
			
</span>
			<span class="RPAREN ">
			)</span></span></span>
			<span class="NEWLINE_WS ">
			
</span>
			<span class="CALL ">
			


<a href="/FastAI.jl/dev/references/FastAI.describetask" class="reference symbol ">
			describetask</a>
	
			<span class="LPAREN ">
			(</span>
			<span class="IDENTIFIER ">
			task</span>
			<span class="RPAREN ">
			)</span></span></span></code></pre></div>
			<div class="coderesult ">
			<!-- HTML_TAG_START --><div class="markdown"><p><strong><code>SupervisedTask</code> summary</strong></p>
<p>Learning task for the supervised task with input <code>Image&#123;2&#125;</code> and target <code>Mask&#123;2, String&#125;</code>. Compatible with <code>model</code>s that take in <code>Bounded&#123;2, FastAI.Vision.ImageTensor&#123;2&#125;&#125;</code> and output <code>Bounded&#123;2, FastAI.OneHotTensor&#123;2, String&#125;&#125;</code>.</p>
<p>Encoding a sample &#40;<code>encodesample&#40;task, context, sample&#41;</code>&#41; is done through the following encodings:</p>
<table><tr><th align="right">Encoding</th><th align="right">Name</th><th align="right"><code>blocks.input</code></th><th align="right"><code>blocks.target</code></th></tr><tr><td align="right"></td><td align="right"><code>&#40;input, target&#41;</code></td><td align="right"><code>Image&#123;2&#125;</code></td><td align="right"><code>Mask&#123;2, String&#125;</code></td></tr><tr><td align="right"><code>ProjectiveTransforms</code></td><td align="right"></td><td align="right"><strong><code>Bounded&#123;2, Image&#123;2&#125;&#125;</code></strong></td><td align="right"><strong><code>Bounded&#123;2, Mask&#123;2, String&#125;&#125;</code></strong></td></tr><tr><td align="right"><code>ImagePreprocessing</code></td><td align="right"></td><td align="right"><strong><code>Bounded&#123;2, FastAI.Vision.ImageTensor&#123;2&#125;&#125;</code></strong></td><td align="right"></td></tr><tr><td align="right"><code>OneHot</code></td><td align="right"><code>&#40;x, y&#41;</code></td><td align="right"></td><td align="right"><strong><code>Bounded&#123;2, FastAI.OneHotTensor&#123;2, String&#125;&#125;</code></strong></td></tr></table>
</div><!-- HTML_TAG_END --></div></div>
			<p class="">
			From this short definition, many things can be derived:</p>
			<ul class="">
			<li class="">
			<p class="">
			data encoding</p></li>
			<li class="">
			<p class="">
			model output decoding</p></li>
			<li class="">
			<p class="">
			how to create a model from a backbone</p></li>
			<li class="">
			<p class="">
			the loss function to use</p></li>
			<li class="">
			<p class="">
			how to visualize samples and predictions</p></li></ul>
			<p class="">
			Together with a 
			



			data container
	
			 
			<span class="code"><code class="codeinline ">
			data</code></span>
			, we can quickly create a 
			<span class="code"><code class="codeinline ">
			Learner</code></span>
			 using 
			


<a href="/FastAI.jl/dev/references/FastAI.tasklearner" class="reference symbol ">
			<span class="code"><code class="codeinline ">
			tasklearner</code></span></a>
	
			 which, like in fastai, handles the training for us. There are no application-specific 
			<span class="code"><code class="codeinline ">
			Learner</code></span>
			 constructors like 
			<span class="code"><code class="codeinline ">
			cnn_learner</code></span>
			 or 
			<span class="code"><code class="codeinline ">
			unet_learner</code></span>
			 in FastAI.jl.</p>
			<pre class="codeblock codeblock svelte-vj8ryq"><code class="svelte-vj8ryq">
			<span class="julia ">
			<span class="EQ ">
			<span class="IDENTIFIER ">
			learner</span>
			<span class="WHITESPACE ">
			 </span>
			<span class="EQ ">
			=</span>
			<span class="WHITESPACE ">
			 </span>
			<span class="CALL ">
			


<a href="/FastAI.jl/dev/references/FastAI.tasklearner" class="reference symbol ">
			tasklearner</a>
	
			<span class="LPAREN ">
			(</span>
			<span class="IDENTIFIER ">
			task</span>
			<span class="COMMA ">
			,</span>
			<span class="WHITESPACE ">
			 </span>
			<span class="IDENTIFIER ">
			data</span>
			<span class="RPAREN ">
			)</span></span></span></span></code></pre>
			<p class="">
			High-level training protocols like the 
			



			one
			-
			cycle learning rate schedule
	
			, 
			



			fine
			-
			tuning
	
			 and the 
			



			learning rate finder
	
			 are then available to us:</p>
			<pre class="codeblock codeblock svelte-vj8ryq"><code class="svelte-vj8ryq">
			<span class="julia ">
			<span class="CALL ">
			


<a href="/FastAI.jl/dev/references/FluxTraining.fit!" class="reference symbol ">
			fit!</a>
	
			<span class="LPAREN ">
			(</span>
			<span class="IDENTIFIER ">
			learner</span>
			<span class="COMMA ">
			,</span>
			<span class="WHITESPACE ">
			 </span>
			<span class="INTEGER ">
			10</span>
			<span class="RPAREN ">
			)</span></span>
			<span class="WHITESPACE ">
			                  </span>
			<span class="COMMENT ">
			# Basic training for 10 epochs</span>
			<span class="NEWLINE_WS ">
			
</span>
			<span class="CALL ">
			


<a href="/FastAI.jl/dev/references/FastAI.finetune!" class="reference symbol ">
			finetune!</a>
	
			<span class="LPAREN ">
			(</span>
			<span class="IDENTIFIER ">
			learner</span>
			<span class="COMMA ">
			,</span>
			<span class="WHITESPACE ">
			 </span>
			<span class="INTEGER ">
			5</span>
			<span class="COMMA ">
			,</span>
			<span class="WHITESPACE ">
			 </span>
			<span class="FLOAT ">
			1e-3</span>
			<span class="RPAREN ">
			)</span></span>
			<span class="WHITESPACE ">
			        </span>
			<span class="COMMENT ">
			# Finetuning regimen for 1+5 epochs with lr=1e-3</span>
			<span class="NEWLINE_WS ">
			
</span>
			<span class="CALL ">
			


<a href="/FastAI.jl/dev/references/FastAI.fitonecycle!" class="reference symbol ">
			fitonecycle!</a>
	
			<span class="LPAREN ">
			(</span>
			<span class="IDENTIFIER ">
			learner</span>
			<span class="COMMA ">
			,</span>
			<span class="WHITESPACE ">
			 </span>
			<span class="INTEGER ">
			10</span>
			<span class="RPAREN ">
			)</span></span>
			<span class="TOPLEVEL ">
			<span class="WHITESPACE ">
			          </span>
			<span class="COMMENT ">
			# One-cycle learning rate regimen</span>
			<span class="NEWLINE_WS ">
			
</span>
			<span class="EQ ">
			<span class="IDENTIFIER ">
			res</span>
			<span class="WHITESPACE ">
			 </span>
			<span class="EQ ">
			=</span>
			<span class="WHITESPACE ">
			 </span>
			<span class="CALL ">
			


<a href="/FastAI.jl/dev/references/FastAI.lrfind" class="reference symbol ">
			lrfind</a>
	
			<span class="LPAREN ">
			(</span>
			<span class="IDENTIFIER ">
			learner</span>
			<span class="RPAREN ">
			)</span></span></span>
			<span class="SEMICOLON ">
			;</span>
			<span class="WHITESPACE ">
			 </span>
			<span class="CALL ">
			<span class="IDENTIFIER ">
			plot</span>
			<span class="LPAREN ">
			(</span>
			<span class="IDENTIFIER ">
			res</span>
			<span class="RPAREN ">
			)</span></span></span>
			<span class="WHITESPACE ">
			   </span>
			<span class="COMMENT ">
			# Run learning rate finder and plot suggestions</span></span></code></pre>
			<h3 class="">
			Incrementally adapting PyTorch code</h3>
			<p class="">
			Since it is a Julia package, FastAI.jl is not written on top of PyTorch, but a Julia library for deep learning: 
			<span class="linkexternal"><a href="http://www.fluxml.ai" class="svelte-1jfpqr">
			Flux
			.
			jl
		
<svg data-carbon-icon="Link16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32" fill="currentColor" width="16" height="16" preserveAspectRatio="xMidYMid meet" style="display:inline; transform: translate(-1px,-2px)" aria-hidden focusable="false"><path d="M29.25,6.76a6,6,0,0,0-8.5,0l1.42,1.42a4,4,0,1,1,5.67,5.67l-8,8a4,4,0,1,1-5.67-5.66l1.41-1.42-1.41-1.42-1.42,1.42a6,6,0,0,0,0,8.5A6,6,0,0,0,17,25a6,6,0,0,0,4.27-1.76l8-8A6,6,0,0,0,29.25,6.76Z"></path><path d="M4.19,24.82a4,4,0,0,1,0-5.67l8-8a4,4,0,0,1,5.67,0A3.94,3.94,0,0,1,19,14a4,4,0,0,1-1.17,2.85L15.71,19l1.42,1.42,2.12-2.12a6,6,0,0,0-8.51-8.51l-8,8a6,6,0,0,0,0,8.51A6,6,0,0,0,7,28a6.07,6.07,0,0,0,4.28-1.76L9.86,24.82A4,4,0,0,1,4.19,24.82Z"></path>
    
  </svg></a>
</span>
			. In any case, the point of this section is to note that the abstractions in fastai are decoupled and existing projects can easily be reused. This is also the case for FastAI.jl as it is built on top of several decoupled libraries. Many of these were built specifically for FastAI.jl, but they are unaware of each other and useful in their own right:</p>
			<ul class="">
			<li class="">
			<p class="">
			<span class="linkexternal"><a href="https://github.com/FluxML/Flux.jl" class="svelte-1jfpqr">
			Flux
			.
			jl
		
<svg data-carbon-icon="Link16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32" fill="currentColor" width="16" height="16" preserveAspectRatio="xMidYMid meet" style="display:inline; transform: translate(-1px,-2px)" aria-hidden focusable="false"><path d="M29.25,6.76a6,6,0,0,0-8.5,0l1.42,1.42a4,4,0,1,1,5.67,5.67l-8,8a4,4,0,1,1-5.67-5.66l1.41-1.42-1.41-1.42-1.42,1.42a6,6,0,0,0,0,8.5A6,6,0,0,0,17,25a6,6,0,0,0,4.27-1.76l8-8A6,6,0,0,0,29.25,6.76Z"></path><path d="M4.19,24.82a4,4,0,0,1,0-5.67l8-8a4,4,0,0,1,5.67,0A3.94,3.94,0,0,1,19,14a4,4,0,0,1-1.17,2.85L15.71,19l1.42,1.42,2.12-2.12a6,6,0,0,0-8.51-8.51l-8,8a6,6,0,0,0,0,8.51A6,6,0,0,0,7,28a6.07,6.07,0,0,0,4.28-1.76L9.86,24.82A4,4,0,0,1,4.19,24.82Z"></path>
    
  </svg></a>
</span>
			 provides models, optimizers, and loss functions, fulfilling a similar role to PyTorch</p></li>
			<li class="">
			<p class="">
			<span class="linkexternal"><a href="https://github.com/JuliaML/MLDataPattern.jl" class="svelte-1jfpqr">
			MLDataPattern
			.
			jl
		
<svg data-carbon-icon="Link16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32" fill="currentColor" width="16" height="16" preserveAspectRatio="xMidYMid meet" style="display:inline; transform: translate(-1px,-2px)" aria-hidden focusable="false"><path d="M29.25,6.76a6,6,0,0,0-8.5,0l1.42,1.42a4,4,0,1,1,5.67,5.67l-8,8a4,4,0,1,1-5.67-5.66l1.41-1.42-1.41-1.42-1.42,1.42a6,6,0,0,0,0,8.5A6,6,0,0,0,17,25a6,6,0,0,0,4.27-1.76l8-8A6,6,0,0,0,29.25,6.76Z"></path><path d="M4.19,24.82a4,4,0,0,1,0-5.67l8-8a4,4,0,0,1,5.67,0A3.94,3.94,0,0,1,19,14a4,4,0,0,1-1.17,2.85L15.71,19l1.42,1.42,2.12-2.12a6,6,0,0,0-8.51-8.51l-8,8a6,6,0,0,0,0,8.51A6,6,0,0,0,7,28a6.07,6.07,0,0,0,4.28-1.76L9.86,24.82A4,4,0,0,1,4.19,24.82Z"></path>
    
  </svg></a>
</span>
			 gives you tools for building and transforming data containers</p></li>
			<li class="">
			<p class="">
			<span class="linkexternal"><a href="https://github.com/lorenzoh/DataLoaders.jl" class="svelte-1jfpqr">
			DataLoaders
			.
			jl
		
<svg data-carbon-icon="Link16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32" fill="currentColor" width="16" height="16" preserveAspectRatio="xMidYMid meet" style="display:inline; transform: translate(-1px,-2px)" aria-hidden focusable="false"><path d="M29.25,6.76a6,6,0,0,0-8.5,0l1.42,1.42a4,4,0,1,1,5.67,5.67l-8,8a4,4,0,1,1-5.67-5.66l1.41-1.42-1.41-1.42-1.42,1.42a6,6,0,0,0,0,8.5A6,6,0,0,0,17,25a6,6,0,0,0,4.27-1.76l8-8A6,6,0,0,0,29.25,6.76Z"></path><path d="M4.19,24.82a4,4,0,0,1,0-5.67l8-8a4,4,0,0,1,5.67,0A3.94,3.94,0,0,1,19,14a4,4,0,0,1-1.17,2.85L15.71,19l1.42,1.42,2.12-2.12a6,6,0,0,0-8.51-8.51l-8,8a6,6,0,0,0,0,8.51A6,6,0,0,0,7,28a6.07,6.07,0,0,0,4.28-1.76L9.86,24.82A4,4,0,0,1,4.19,24.82Z"></path>
    
  </svg></a>
</span>
			 takes care of efficient, parallelized iteration of data containers</p></li>
			<li class="">
			<p class="">
			<span class="linkexternal"><a href="https://github.com/lorenzoh/DataAugmentation.jl" class="svelte-1jfpqr">
			DataAugmentation
			.
			jl
		
<svg data-carbon-icon="Link16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32" fill="currentColor" width="16" height="16" preserveAspectRatio="xMidYMid meet" style="display:inline; transform: translate(-1px,-2px)" aria-hidden focusable="false"><path d="M29.25,6.76a6,6,0,0,0-8.5,0l1.42,1.42a4,4,0,1,1,5.67,5.67l-8,8a4,4,0,1,1-5.67-5.66l1.41-1.42-1.41-1.42-1.42,1.42a6,6,0,0,0,0,8.5A6,6,0,0,0,17,25a6,6,0,0,0,4.27-1.76l8-8A6,6,0,0,0,29.25,6.76Z"></path><path d="M4.19,24.82a4,4,0,0,1,0-5.67l8-8a4,4,0,0,1,5.67,0A3.94,3.94,0,0,1,19,14a4,4,0,0,1-1.17,2.85L15.71,19l1.42,1.42,2.12-2.12a6,6,0,0,0-8.51-8.51l-8,8a6,6,0,0,0,0,8.51A6,6,0,0,0,7,28a6.07,6.07,0,0,0,4.28-1.76L9.86,24.82A4,4,0,0,1,4.19,24.82Z"></path>
    
  </svg></a>
</span>
			 takes care of the lower levels of high-performance, composable data augmentations.</p></li>
			<li class="">
			<p class="">
			<span class="linkexternal"><a href="https://github.com/lorenzoh/FluxTraining.jl" class="svelte-1jfpqr">
			FluxTraining
			.
			jl
		
<svg data-carbon-icon="Link16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32" fill="currentColor" width="16" height="16" preserveAspectRatio="xMidYMid meet" style="display:inline; transform: translate(-1px,-2px)" aria-hidden focusable="false"><path d="M29.25,6.76a6,6,0,0,0-8.5,0l1.42,1.42a4,4,0,1,1,5.67,5.67l-8,8a4,4,0,1,1-5.67-5.66l1.41-1.42-1.41-1.42-1.42,1.42a6,6,0,0,0,0,8.5A6,6,0,0,0,17,25a6,6,0,0,0,4.27-1.76l8-8A6,6,0,0,0,29.25,6.76Z"></path><path d="M4.19,24.82a4,4,0,0,1,0-5.67l8-8a4,4,0,0,1,5.67,0A3.94,3.94,0,0,1,19,14a4,4,0,0,1-1.17,2.85L15.71,19l1.42,1.42,2.12-2.12a6,6,0,0,0-8.51-8.51l-8,8a6,6,0,0,0,0,8.51A6,6,0,0,0,7,28a6.07,6.07,0,0,0,4.28-1.76L9.86,24.82A4,4,0,0,1,4.19,24.82Z"></path>
    
  </svg></a>
</span>
			 contributes a highly extensible training loop with 2-way callbacks</p></li></ul>
			<p class="">
			If that seems like a lot: don’t worry! If you’ve installed FastAI.jl, the functionality of most of these packages is reexported and you don’t have to install any of them explicitly.</p>
			<h3 class="">
			Consistency across domains</h3>
			<p class="">
			While computer vision is the only domain with mature support for now, the abstractions underlying FastAI.jl are carefully crafted to ensure that learning tasks for different domains can be created using the same set of interfaces. This shows in that there’s no need for application-specific functionality above the data block API.</p>
			<h2 class="">
			Mid
			-
			level APIs</h2>
			<h3 class="">
			Learner</h3>
			<p class="">
			The 
			


<a href="/FastAI.jl/dev/references/FluxTraining.Learner" class="reference symbol ">
			<span class="code"><code class="codeinline ">
			Learner</code></span></a>
	
			 is very similar to fastai’s. It takes</p>
			<ul class="">
			<li class="">
			<p class="">
			a model: any parameterized, differentiable function like a neural network or even 
			<span class="linkexternal"><a href="https://fluxml.ai/blog/2019/03/05/dp-vs-rl.html" class="svelte-1jfpqr">
			a trebuchet simulator
		
<svg data-carbon-icon="Link16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32" fill="currentColor" width="16" height="16" preserveAspectRatio="xMidYMid meet" style="display:inline; transform: translate(-1px,-2px)" aria-hidden focusable="false"><path d="M29.25,6.76a6,6,0,0,0-8.5,0l1.42,1.42a4,4,0,1,1,5.67,5.67l-8,8a4,4,0,1,1-5.67-5.66l1.41-1.42-1.41-1.42-1.42,1.42a6,6,0,0,0,0,8.5A6,6,0,0,0,17,25a6,6,0,0,0,4.27-1.76l8-8A6,6,0,0,0,29.25,6.76Z"></path><path d="M4.19,24.82a4,4,0,0,1,0-5.67l8-8a4,4,0,0,1,5.67,0A3.94,3.94,0,0,1,19,14a4,4,0,0,1-1.17,2.85L15.71,19l1.42,1.42,2.12-2.12a6,6,0,0,0-8.51-8.51l-8,8a6,6,0,0,0,0,8.51A6,6,0,0,0,7,28a6.07,6.07,0,0,0,4.28-1.76L9.86,24.82A4,4,0,0,1,4.19,24.82Z"></path>
    
  </svg></a>
</span></p></li>
			<li class="">
			<p class="">
			training and validation data iterators: these can be 
			<span class="code"><code class="codeinline ">
			DataLoader</code></span>
			s which paralellize data loading but any iterator over batches can be used</p></li>
			<li class="">
			<p class="">
			optimizer</p></li>
			<li class="">
			<p class="">
			loss function</p></li></ul>
			<h3 class="">
			Two
			-
			way callbacks</h3>
			<p class="">
			The training loop also supports two-way callbacks. See the 
			<span class="linkexternal"><a href="https://fluxml.ai/FluxTraining.jl/dev/docs/callbacks/reference.md.html" class="svelte-1jfpqr">
			FluxTraining
			.
			jl docs
		
<svg data-carbon-icon="Link16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32" fill="currentColor" width="16" height="16" preserveAspectRatio="xMidYMid meet" style="display:inline; transform: translate(-1px,-2px)" aria-hidden focusable="false"><path d="M29.25,6.76a6,6,0,0,0-8.5,0l1.42,1.42a4,4,0,1,1,5.67,5.67l-8,8a4,4,0,1,1-5.67-5.66l1.41-1.42-1.41-1.42-1.42,1.42a6,6,0,0,0,0,8.5A6,6,0,0,0,17,25a6,6,0,0,0,4.27-1.76l8-8A6,6,0,0,0,29.25,6.76Z"></path><path d="M4.19,24.82a4,4,0,0,1,0-5.67l8-8a4,4,0,0,1,5.67,0A3.94,3.94,0,0,1,19,14a4,4,0,0,1-1.17,2.85L15.71,19l1.42,1.42,2.12-2.12a6,6,0,0,0-8.51-8.51l-8,8a6,6,0,0,0,0,8.51A6,6,0,0,0,7,28a6.07,6.07,0,0,0,4.28-1.76L9.86,24.82A4,4,0,0,1,4.19,24.82Z"></path>
    
  </svg></a>
</span>
			 for a list of all available callbacks. While supporting all the functionality of fastai’s callbacks and training loop, it also provides 
			<span class="linkexternal"><a href="https://fluxml.ai/FluxTraining.jl/dev/docs/tutorials/training.md.html" class="svelte-1jfpqr">
			an extensible training loop API
		
<svg data-carbon-icon="Link16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32" fill="currentColor" width="16" height="16" preserveAspectRatio="xMidYMid meet" style="display:inline; transform: translate(-1px,-2px)" aria-hidden focusable="false"><path d="M29.25,6.76a6,6,0,0,0-8.5,0l1.42,1.42a4,4,0,1,1,5.67,5.67l-8,8a4,4,0,1,1-5.67-5.66l1.41-1.42-1.41-1.42-1.42,1.42a6,6,0,0,0,0,8.5A6,6,0,0,0,17,25a6,6,0,0,0,4.27-1.76l8-8A6,6,0,0,0,29.25,6.76Z"></path><path d="M4.19,24.82a4,4,0,0,1,0-5.67l8-8a4,4,0,0,1,5.67,0A3.94,3.94,0,0,1,19,14a4,4,0,0,1-1.17,2.85L15.71,19l1.42,1.42,2.12-2.12a6,6,0,0,0-8.51-8.51l-8,8a6,6,0,0,0,0,8.51A6,6,0,0,0,7,28a6.07,6.07,0,0,0,4.28-1.76L9.86,24.82A4,4,0,0,1,4.19,24.82Z"></path>
    
  </svg></a>
</span>
			 that makes it straightforward to integrate custom training steps with the available callbacks. As a result, different training steps for problems other than standard supervised training can make use of existing callbacks  without the need to handle control flow through callbacks. Additionally, callbacks have an additional level of safety by being required to declare what state they access and modify. With a little more effort up-front, this guarantees correct ordering of callback execution through 
			<span class="linkexternal"><a href="https://fluxml.ai/FluxTraining.jl/dev/docs/callbacks/tipstricks.md.html#visualize-the-callback-dependency-graph" class="svelte-1jfpqr">
			a dependency graph
		
<svg data-carbon-icon="Link16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32" fill="currentColor" width="16" height="16" preserveAspectRatio="xMidYMid meet" style="display:inline; transform: translate(-1px,-2px)" aria-hidden focusable="false"><path d="M29.25,6.76a6,6,0,0,0-8.5,0l1.42,1.42a4,4,0,1,1,5.67,5.67l-8,8a4,4,0,1,1-5.67-5.66l1.41-1.42-1.41-1.42-1.42,1.42a6,6,0,0,0,0,8.5A6,6,0,0,0,17,25a6,6,0,0,0,4.27-1.76l8-8A6,6,0,0,0,29.25,6.76Z"></path><path d="M4.19,24.82a4,4,0,0,1,0-5.67l8-8a4,4,0,0,1,5.67,0A3.94,3.94,0,0,1,19,14a4,4,0,0,1-1.17,2.85L15.71,19l1.42,1.42,2.12-2.12a6,6,0,0,0-8.51-8.51l-8,8a6,6,0,0,0,0,8.51A6,6,0,0,0,7,28a6.07,6.07,0,0,0,4.28-1.76L9.86,24.82A4,4,0,0,1,4.19,24.82Z"></path>
    
  </svg></a>
</span>
			. In the future, this will also make it possible to automatically run callbacks in parallel and asynchronously to reduce overhead by long-running callbacks like costly metric calculations and logging over the network.</p>
			<h3 class="">
			Encodings and blocks</h3>
			<p class="">
			In the paper, this subsection is in the low-level section (named Transforms and Pipelines), but I’m putting it here since it is the core of FastAI.jl’s data block API. FastAI.jl provides 
			<span class="code"><code class="codeinline ">
			Encoding</code></span>
			s and 
			<span class="code"><code class="codeinline ">
			Block</code></span>
			s which correspond to fastai’s 
			<span class="code"><code class="codeinline ">
			Transform</code></span>
			s and 
			<span class="code"><code class="codeinline ">
			Block</code></span>
			s. Encodings implement an 
			<span class="code"><code class="codeinline ">
			encode</code></span>
			 (and optionally 
			<span class="code"><code class="codeinline ">
			decode</code></span>
			) function that describes how data corresponding to some blocks is transformed and how that transformation can be inverted. There is also support for stateful encodings like 
			


<a href="/FastAI.jl/dev/references/FastAI.Vision.ProjectiveTransforms" class="reference symbol ">
			<span class="code"><code class="codeinline ">
			ProjectiveTransforms</code></span></a>
	
			 which need to use the same random state to augment every data point. Additionally, encodings describe what kind of block data is returned from encoding, allowing inspection of the whole data pipeline. The 
			<span class="code"><code class="codeinline ">
			Block</code></span>
			s are used to dispatch in the 
			<span class="code"><code class="codeinline ">
			encode</code></span>
			 function to implement block-specific transformations. If no 
			<span class="code"><code class="codeinline ">
			encode</code></span>
			 task is implemented for a pair of encoding and block, the default is to pass the data through unchanged like in fastai.</p>
			<p class="">
			The 
			<span class="code"><code class="codeinline ">
			Block</code></span>
			s also allow implementing task-specific functionality:</p>
			<ul class="">
			<li class="">
			<p class="">
			


<a href="/FastAI.jl/dev/references/FastAI.blocklossfn" class="reference symbol ">
			<span class="code"><code class="codeinline ">
			blocklossfn</code></span></a>
	
			 takes a prediction and encoded target block to determine a good loss function to use. For example, for image classification we want to compare two one-hot encoded labels and hence define 
			<span class="code"><code class="codeinline ">
			blocklossfn(::OneHotTensor{0}, ::OneHotTensor{0}) = logitcrossentropy</code></span>
			.</p></li>
			<li class="">
			<p class="">
			


<a href="/FastAI.jl/dev/references/FastAI.blockmodel" class="reference symbol ">
			<span class="code"><code class="codeinline ">
			blockmodel</code></span></a>
	
			 constructs a model from a backbone that maps an input block to an output block. For example, for image segmentation we have 
			<span class="code"><code class="codeinline ">
			ImageTensor{N}()</code></span>
			 as the input block and 
			<span class="code"><code class="codeinline ">
			OneHotTensor{N}</code></span>
			 (one-hot encoded N-dimensional masks) as output, so 
			<span class="code"><code class="codeinline ">
			blockmodel</code></span>
			 turns the backbone into a U-Net.</p></li>
			<li class="">
			<p class="">
			


<a href="/FastAI.jl/dev/references/FastAI.showblock!" class="reference symbol ">
			<span class="code"><code class="codeinline ">
			showblock!</code></span></a>
	
			 defines how to visualize a block of data.</p></li></ul>
			<h3 class="">
			Generic optimizer</h3>
			<p class="">
			FastAI.jl uses the optimizers from Flux.jl, which provides a similarly 
			<span class="linkexternal"><a href="https://fluxml.ai/Flux.jl/stable/training/optimisers/#Composing-Optimisers" class="svelte-1jfpqr">
			composable API for optimzers
		
<svg data-carbon-icon="Link16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32" fill="currentColor" width="16" height="16" preserveAspectRatio="xMidYMid meet" style="display:inline; transform: translate(-1px,-2px)" aria-hidden focusable="false"><path d="M29.25,6.76a6,6,0,0,0-8.5,0l1.42,1.42a4,4,0,1,1,5.67,5.67l-8,8a4,4,0,1,1-5.67-5.66l1.41-1.42-1.41-1.42-1.42,1.42a6,6,0,0,0,0,8.5A6,6,0,0,0,17,25a6,6,0,0,0,4.27-1.76l8-8A6,6,0,0,0,29.25,6.76Z"></path><path d="M4.19,24.82a4,4,0,0,1,0-5.67l8-8a4,4,0,0,1,5.67,0A3.94,3.94,0,0,1,19,14a4,4,0,0,1-1.17,2.85L15.71,19l1.42,1.42,2.12-2.12a6,6,0,0,0-8.51-8.51l-8,8a6,6,0,0,0,0,8.51A6,6,0,0,0,7,28a6.07,6.07,0,0,0,4.28-1.76L9.86,24.82A4,4,0,0,1,4.19,24.82Z"></path>
    
  </svg></a>
</span>
			.</p>
			<h3 class="">
			Generalized metric API</h3>
			<p class="">
			Metrics are handled by the 
			


<a href="/FastAI.jl/dev/references/FluxTraining.Metrics" class="reference symbol ">
			<span class="code"><code class="codeinline ">
			Metrics</code></span></a>
	
			 callback which takes in reducing metric functions or 
			


<a href="/FastAI.jl/dev/references/FluxTraining.AbstractMetric" class="reference symbol ">
			<span class="code"><code class="codeinline ">
			FluxTraining.AbstractMetric</code></span></a>
	
			s which have a similar API to fastai’s.</p>
			<h3 class="">
			fastai
			.
			data
			.
			external</h3>
			<p class="">
			FastAI.jl makes all the same datasets available in 
			<span class="code"><code class="codeinline ">
			fastai.data.external</code></span>
			 available. See 
			<span class="code"><code class="codeinline ">
			FastAI.Datasets.DATASETS</code></span>
			 for a list of all datasets and use 
			


<a href="/FastAI.jl/dev/references/FastAI.Datasets.datasetpath" class="reference symbol ">
			<span class="code"><code class="codeinline ">
			datasetpath</code></span></a>
	
			<span class="code"><code class="codeinline ">
			(name)</code></span>
			 to download and extract a dataset.</p>
			<h3 class="">
			funcs
			_
			kwargs and DataLoader, fastai
			.
			data
			.
			core</h3>
			<p class="">
			In FastAI.jl, you are not restricted to a specific type of data iterator and can pass any iterator over batches to 
			<span class="code"><code class="codeinline ">
			Learner</code></span>
			. In cases where performance is important 
			<span class="code"><code class="codeinline ">
			DataLoader</code></span>
			 can speed up data iteration by loading and batching samples in parallel on background threads. All transformations of data happen through the data container interface which requires a type to implement 
			<span class="code"><code class="codeinline ">
			LearnBase.getobs</code></span>
			 and 
			<span class="code"><code class="codeinline ">
			LearnBase.nobs</code></span>
			, similar to PyTorch’s 
			<span class="code"><code class="codeinline ">
			torch.utils.data.Dataset</code></span>
			. Data containers are then transformed into other data containers. Some examples:</p>
			<ul class="">
			<li class="">
			<p class="">
			


<a href="/FastAI.jl/dev/references/FastAI.Datasets.mapobs" class="reference symbol ">
			<span class="code"><code class="codeinline ">
			mapobs</code></span></a>
	
			<span class="code"><code class="codeinline ">
			(f, data)</code></span>
			 lazily maps a function 
			<span class="code"><code class="codeinline ">
			f</code></span>
			 of over 
			<span class="code"><code class="codeinline ">
			data</code></span>
			 such that 
			<span class="code"><code class="codeinline ">
			getobs(mapobs(f, data), idx) == f(getobs(data, idx))</code></span>
			. For example 
			<span class="code"><code class="codeinline ">
			mapobs(loadfile, files)</code></span>
			 turns a vector of image files into a data container of images.</p></li>
			<li class="">
			<p class="">
			<span class="code"><code class="codeinline ">
			DataLoader(data, batchsize)</code></span>
			 is a wrapper around 
			<span class="code"><code class="codeinline ">
			batchviewcollated</code></span>
			 which turns a data container of samples into one of collated batches and 
			<span class="code"><code class="codeinline ">
			eachobsparallel</code></span>
			 which creates a parallel, buffered iterator over the observations (here batches) in the resulting container.</p></li>
			<li class="">
			<p class="">
			


<a href="/FastAI.jl/dev/references/FastAI.Datasets.groupobs" class="reference symbol ">
			<span class="code"><code class="codeinline ">
			groupobs</code></span></a>
	
			<span class="code"><code class="codeinline ">
			(f, data)</code></span>
			 splits a container into groups using a grouping function 
			<span class="code"><code class="codeinline ">
			f</code></span>
			. For example, 
			<span class="code"><code class="codeinline ">
			groupobs(grandparentname, files)</code></span>
			 creates training splits for files where the grandparent folder indicates the split.</p></li>
			<li class="">
			<p class="">
			<span class="code"><code class="codeinline ">
			datasubset</code></span>
			<span class="code"><code class="codeinline ">
			(data, idxs)</code></span>
			 lazily takes a subset of the observations in 
			<span class="code"><code class="codeinline ">
			data</code></span>
			.</p></li></ul>
			<p class="">
			For more information, see the 
			


<a href="/FastAI.jl/dev/documents/docs/data_containers.md" class="reference document ">
			data container tutorial</a>
	
			 and the 
			<span class="linkexternal"><a href="https://mldatapatternjl.readthedocs.io/en/latest/" class="svelte-1jfpqr">
			MLDataPattern
			.
			jl docs
		
<svg data-carbon-icon="Link16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32" fill="currentColor" width="16" height="16" preserveAspectRatio="xMidYMid meet" style="display:inline; transform: translate(-1px,-2px)" aria-hidden focusable="false"><path d="M29.25,6.76a6,6,0,0,0-8.5,0l1.42,1.42a4,4,0,1,1,5.67,5.67l-8,8a4,4,0,1,1-5.67-5.66l1.41-1.42-1.41-1.42-1.42,1.42a6,6,0,0,0,0,8.5A6,6,0,0,0,17,25a6,6,0,0,0,4.27-1.76l8-8A6,6,0,0,0,29.25,6.76Z"></path><path d="M4.19,24.82a4,4,0,0,1,0-5.67l8-8a4,4,0,0,1,5.67,0A3.94,3.94,0,0,1,19,14a4,4,0,0,1-1.17,2.85L15.71,19l1.42,1.42,2.12-2.12a6,6,0,0,0-8.51-8.51l-8,8a6,6,0,0,0,0,8.51A6,6,0,0,0,7,28a6.07,6.07,0,0,0,4.28-1.76L9.86,24.82A4,4,0,0,1,4.19,24.82Z"></path>
    
  </svg></a>
</span>
			. At a higher level, there are also convenience functions like 
			


<a href="/FastAI.jl/dev/references/FastAI.Datasets.FileDataset" class="reference symbol ">
			<span class="code"><code class="codeinline ">
			FileDataset</code></span></a>
	
			 to create data containers.</p>
			<h3 class="">
			Layers and architectures</h3>
			<p class="">
			Flux.jl already does a better job at functionally creating model architectures than PyTorch, so FastAI.jl makes use of its layers. For example 
			


<a href="/FastAI.jl/dev/references/Flux.SkipConnection" class="reference symbol ">
			<span class="code"><code class="codeinline ">
			Flux.SkipConnection</code></span></a>
	
			  corresponds to fastai’s 
			<span class="code"><code class="codeinline ">
			MergeLayer</code></span>
			. The 
			<span class="code"><code class="codeinline ">
			FastAI.Models</code></span>
			 submodule currently provides some high-level architectures like 
			


<a href="/FastAI.jl/dev/references/FastAI.Vision.Models.xresnet18" class="reference symbol ">
			<span class="code"><code class="codeinline ">
			xresnet18</code></span></a>
	
			 and a U-Net builder 
			


<a href="/FastAI.jl/dev/references/FastAI.Vision.Models.UNetDynamic" class="reference symbol ">
			<span class="code"><code class="codeinline ">
			UNetDynamic</code></span></a>
	
			 that can create U-Nets from 
			<em class="">
			any</em>
			 convolutional feature extractor. The 
			


<a href="/FastAI.jl/dev/documents/docs/setup.md" class="reference document ">
			optional dependency</a>
	
			 
			<span class="linkexternal"><a href="https://github.com/FluxML/Metalhead.jl" class="svelte-1jfpqr">
			Metalhead
			.
			jl
		
<svg data-carbon-icon="Link16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32" fill="currentColor" width="16" height="16" preserveAspectRatio="xMidYMid meet" style="display:inline; transform: translate(-1px,-2px)" aria-hidden focusable="false"><path d="M29.25,6.76a6,6,0,0,0-8.5,0l1.42,1.42a4,4,0,1,1,5.67,5.67l-8,8a4,4,0,1,1-5.67-5.66l1.41-1.42-1.41-1.42-1.42,1.42a6,6,0,0,0,0,8.5A6,6,0,0,0,17,25a6,6,0,0,0,4.27-1.76l8-8A6,6,0,0,0,29.25,6.76Z"></path><path d="M4.19,24.82a4,4,0,0,1,0-5.67l8-8a4,4,0,0,1,5.67,0A3.94,3.94,0,0,1,19,14a4,4,0,0,1-1.17,2.85L15.71,19l1.42,1.42,2.12-2.12a6,6,0,0,0-8.51-8.51l-8,8a6,6,0,0,0,0,8.51A6,6,0,0,0,7,28a6.07,6.07,0,0,0,4.28-1.76L9.86,24.82A4,4,0,0,1,4.19,24.82Z"></path>
    
  </svg></a>
</span>
			 also provides common pretrained vision models.</p>
			<h2 class="">
			Low
			-
			level APIs</h2>
			<p class="">
			Due to the nature of the Julia language and its design around multiple dispatch, packages tend to compose really well, so it was not necessary to reimplement or provide a unified API for low-level operations. We’ll comment on the libraries that we were able to use.</p>
			<h3 class="">
			PyTorch foundations</h3>
			<p class="">
			Unlike Python, Julia has native support for N-dimensional regular arrays. As such, there is a standard interface for arrays and libraries don’t need to implement their own. Consider that every deep learning framework in Python implements their own CPU and GPU arrays, which is part of the reason they are 
			<em class="">
			frameworks</em>
			, not 
			<em class="">
			libraries</em>
			 (with the latter being vastly preferable). Julia’s standard libraries implements the standard CPU 
			<span class="code"><code class="codeinline ">
			Array</code></span>
			 type. GPU arrays are implemented through 
			<span class="linkexternal"><a href="https://github.com/JuliaGPU/CUDA.jl" class="svelte-1jfpqr">
			CUDA
			.
			jl
		
<svg data-carbon-icon="Link16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32" fill="currentColor" width="16" height="16" preserveAspectRatio="xMidYMid meet" style="display:inline; transform: translate(-1px,-2px)" aria-hidden focusable="false"><path d="M29.25,6.76a6,6,0,0,0-8.5,0l1.42,1.42a4,4,0,1,1,5.67,5.67l-8,8a4,4,0,1,1-5.67-5.66l1.41-1.42-1.41-1.42-1.42,1.42a6,6,0,0,0,0,8.5A6,6,0,0,0,17,25a6,6,0,0,0,4.27-1.76l8-8A6,6,0,0,0,29.25,6.76Z"></path><path d="M4.19,24.82a4,4,0,0,1,0-5.67l8-8a4,4,0,0,1,5.67,0A3.94,3.94,0,0,1,19,14a4,4,0,0,1-1.17,2.85L15.71,19l1.42,1.42,2.12-2.12a6,6,0,0,0-8.51-8.51l-8,8a6,6,0,0,0,0,8.51A6,6,0,0,0,7,28a6.07,6.07,0,0,0,4.28-1.76L9.86,24.82A4,4,0,0,1,4.19,24.82Z"></path>
    
  </svg></a>
</span>
			 
			<span class="code"><code class="codeinline ">
			CuArray</code></span>
			 type (with unified support for GPU vendors other than nvidia in the works). As a result, Flux.jl, the deep learning library of choice for FastAI.jl, does not need to reimplement their own CPU and GPU array versions. This kind of composability in general largely benefits what can be accomplished in Julia.</p>
			<p class="">
			Some other libraries which are used under the hood: for image processing, the 
			<span class="linkexternal"><a href="https://juliaimages.org/" class="svelte-1jfpqr">
			Images
			.
			jl
		
<svg data-carbon-icon="Link16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32" fill="currentColor" width="16" height="16" preserveAspectRatio="xMidYMid meet" style="display:inline; transform: translate(-1px,-2px)" aria-hidden focusable="false"><path d="M29.25,6.76a6,6,0,0,0-8.5,0l1.42,1.42a4,4,0,1,1,5.67,5.67l-8,8a4,4,0,1,1-5.67-5.66l1.41-1.42-1.41-1.42-1.42,1.42a6,6,0,0,0,0,8.5A6,6,0,0,0,17,25a6,6,0,0,0,4.27-1.76l8-8A6,6,0,0,0,29.25,6.76Z"></path><path d="M4.19,24.82a4,4,0,0,1,0-5.67l8-8a4,4,0,0,1,5.67,0A3.94,3.94,0,0,1,19,14a4,4,0,0,1-1.17,2.85L15.71,19l1.42,1.42,2.12-2.12a6,6,0,0,0-8.51-8.51l-8,8a6,6,0,0,0,0,8.51A6,6,0,0,0,7,28a6.07,6.07,0,0,0,4.28-1.76L9.86,24.82A4,4,0,0,1,4.19,24.82Z"></path>
    
  </svg></a>
</span>
			 ecosystem of packages is used; for reading and processing tabular data 
			<span class="linkexternal"><a href="https://github.com/JuliaData/DataFrames.jl" class="svelte-1jfpqr">
			DataFrames
			.
			jl
		
<svg data-carbon-icon="Link16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32" fill="currentColor" width="16" height="16" preserveAspectRatio="xMidYMid meet" style="display:inline; transform: translate(-1px,-2px)" aria-hidden focusable="false"><path d="M29.25,6.76a6,6,0,0,0-8.5,0l1.42,1.42a4,4,0,1,1,5.67,5.67l-8,8a4,4,0,1,1-5.67-5.66l1.41-1.42-1.41-1.42-1.42,1.42a6,6,0,0,0,0,8.5A6,6,0,0,0,17,25a6,6,0,0,0,4.27-1.76l8-8A6,6,0,0,0,29.25,6.76Z"></path><path d="M4.19,24.82a4,4,0,0,1,0-5.67l8-8a4,4,0,0,1,5.67,0A3.94,3.94,0,0,1,19,14a4,4,0,0,1-1.17,2.85L15.71,19l1.42,1.42,2.12-2.12a6,6,0,0,0-8.51-8.51l-8,8a6,6,0,0,0,0,8.51A6,6,0,0,0,7,28a6.07,6.07,0,0,0,4.28-1.76L9.86,24.82A4,4,0,0,1,4.19,24.82Z"></path>
    
  </svg></a>
</span>
			 and 
			<span class="linkexternal"><a href="https://github.com/JuliaData/Tables.jl" class="svelte-1jfpqr">
			Tables
			.
			jl
		
<svg data-carbon-icon="Link16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32" fill="currentColor" width="16" height="16" preserveAspectRatio="xMidYMid meet" style="display:inline; transform: translate(-1px,-2px)" aria-hidden focusable="false"><path d="M29.25,6.76a6,6,0,0,0-8.5,0l1.42,1.42a4,4,0,1,1,5.67,5.67l-8,8a4,4,0,1,1-5.67-5.66l1.41-1.42-1.41-1.42-1.42,1.42a6,6,0,0,0,0,8.5A6,6,0,0,0,17,25a6,6,0,0,0,4.27-1.76l8-8A6,6,0,0,0,29.25,6.76Z"></path><path d="M4.19,24.82a4,4,0,0,1,0-5.67l8-8a4,4,0,0,1,5.67,0A3.94,3.94,0,0,1,19,14a4,4,0,0,1-1.17,2.85L15.71,19l1.42,1.42,2.12-2.12a6,6,0,0,0-8.51-8.51l-8,8a6,6,0,0,0,0,8.51A6,6,0,0,0,7,28a6.07,6.07,0,0,0,4.28-1.76L9.86,24.82A4,4,0,0,1,4.19,24.82Z"></path>
    
  </svg></a>
</span>
			; for plotting 
			<span class="linkexternal"><a href="https://github.com/JuliaPlots/Makie.jl" class="svelte-1jfpqr">
			Makie
			.
			jl
		
<svg data-carbon-icon="Link16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32" fill="currentColor" width="16" height="16" preserveAspectRatio="xMidYMid meet" style="display:inline; transform: translate(-1px,-2px)" aria-hidden focusable="false"><path d="M29.25,6.76a6,6,0,0,0-8.5,0l1.42,1.42a4,4,0,1,1,5.67,5.67l-8,8a4,4,0,1,1-5.67-5.66l1.41-1.42-1.41-1.42-1.42,1.42a6,6,0,0,0,0,8.5A6,6,0,0,0,17,25a6,6,0,0,0,4.27-1.76l8-8A6,6,0,0,0,29.25,6.76Z"></path><path d="M4.19,24.82a4,4,0,0,1,0-5.67l8-8a4,4,0,0,1,5.67,0A3.94,3.94,0,0,1,19,14a4,4,0,0,1-1.17,2.85L15.71,19l1.42,1.42,2.12-2.12a6,6,0,0,0-8.51-8.51l-8,8a6,6,0,0,0,0,8.51A6,6,0,0,0,7,28a6.07,6.07,0,0,0,4.28-1.76L9.86,24.82A4,4,0,0,1,4.19,24.82Z"></path>
    
  </svg></a>
</span>
			.</p>
			<h3 class="">
			Type dispatch</h3>
			<p class="">
			Multiple dispatch already is a core feature of the Julia language, hence the extensible interfaces in FastAI.jl are built around it and are natural fit for the language.</p>
			<h3 class="">
			Object
			-
			oriented semantic tensors</h3>
			<p class="">
			As mentioned above, Julia has great support for arrays with extra functionality available to packages that provide wrapper arrays like 
			<span class="linkexternal"><a href="https://github.com/invenia/NamedDims.jl" class="svelte-1jfpqr">
			NamedDims
			.
			jl
		
<svg data-carbon-icon="Link16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32" fill="currentColor" width="16" height="16" preserveAspectRatio="xMidYMid meet" style="display:inline; transform: translate(-1px,-2px)" aria-hidden focusable="false"><path d="M29.25,6.76a6,6,0,0,0-8.5,0l1.42,1.42a4,4,0,1,1,5.67,5.67l-8,8a4,4,0,1,1-5.67-5.66l1.41-1.42-1.41-1.42-1.42,1.42a6,6,0,0,0,0,8.5A6,6,0,0,0,17,25a6,6,0,0,0,4.27-1.76l8-8A6,6,0,0,0,29.25,6.76Z"></path><path d="M4.19,24.82a4,4,0,0,1,0-5.67l8-8a4,4,0,0,1,5.67,0A3.94,3.94,0,0,1,19,14a4,4,0,0,1-1.17,2.85L15.71,19l1.42,1.42,2.12-2.12a6,6,0,0,0-8.51-8.51l-8,8a6,6,0,0,0,0,8.51A6,6,0,0,0,7,28a6.07,6.07,0,0,0,4.28-1.76L9.86,24.82A4,4,0,0,1,4.19,24.82Z"></path>
    
  </svg></a>
</span>
			 which should generally 
			<em class="">
			just work</em>
			 with every part of the library. Hence there is no need for an addtional API that unifies separate packages, which in turn makes FastAI.jl more composable with other packages.</p>
			<p class="">
			In encodings, the array types are used for dispatch only where an especially performant implementation is possible, and the block information is used for dispatching the semantics of the encoding.</p>
			<h3 class="">
			GPU
			-
			accelerated augmentation</h3>
			<p class="">
			FastAI.jl does not support GPU-accelerated augmentation (yet). Please open an issue if you run into a situation where data processing 
			


<a href="/FastAI.jl/dev/documents/docs/background/datapipelines.md" class="reference document ">
			becomes the bottleneck</a>
	
			 and we’ll prioritize this. The affine transformations implemented in DataAugmentation.jl and used in FastAI.jl are properly composed to ensure high quality results. They are also optimized for speed and memory usage (with complete support for inplace transformations).</p>
			<h3 class="">
			Convenience functionality</h3>
			<p class="">
			Much of the convenience provided by fastai is not required in Julia:</p>
			<ul class="">
			<li class="">
			<p class="">
			<span class="code"><code class="codeinline ">
			@delegates</code></span>
			: Due to the absence of deep class hierarchies, keyword arguments are seldom passed around (the only instance where this happens in FastAI.jl is 
			


<a href="/FastAI.jl/dev/references/FastAI.tasklearner" class="reference symbol ">
			<span class="code"><code class="codeinline ">
			tasklearner</code></span></a>
	
			).</p></li>
			<li class="">
			<p class="">
			<span class="code"><code class="codeinline ">
			@patch</code></span>
			: since Julia is built around multiple dispatch, not classes, you just implement the task for a type, no patching needed</p></li>
			<li class="">
			<p class="">
			<span class="code"><code class="codeinline ">
			L</code></span>
			: due to first-class array support such a wrapper list container isn’t needed</p></li></ul>
			<h2 class="">
			nbdev</h2>
			<p class="">
			There is no 
			<span class="code"><code class="codeinline ">
			nbdev</code></span>
			-equivalent in Julia at the moment. That said, this documentation is generated by a document creation package 
			<span class="linkexternal"><a href="https://github.com/lorenzoh/Pollen.jl" class="svelte-1jfpqr">
			Pollen
			.
			jl
		
<svg data-carbon-icon="Link16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32" fill="currentColor" width="16" height="16" preserveAspectRatio="xMidYMid meet" style="display:inline; transform: translate(-1px,-2px)" aria-hidden focusable="false"><path d="M29.25,6.76a6,6,0,0,0-8.5,0l1.42,1.42a4,4,0,1,1,5.67,5.67l-8,8a4,4,0,1,1-5.67-5.66l1.41-1.42-1.41-1.42-1.42,1.42a6,6,0,0,0,0,8.5A6,6,0,0,0,17,25a6,6,0,0,0,4.27-1.76l8-8A6,6,0,0,0,29.25,6.76Z"></path><path d="M4.19,24.82a4,4,0,0,1,0-5.67l8-8a4,4,0,0,1,5.67,0A3.94,3.94,0,0,1,19,14a4,4,0,0,1-1.17,2.85L15.71,19l1.42,1.42,2.12-2.12a6,6,0,0,0-8.51-8.51l-8,8a6,6,0,0,0,0,8.51A6,6,0,0,0,7,28a6.07,6.07,0,0,0,4.28-1.76L9.86,24.82A4,4,0,0,1,4.19,24.82Z"></path>
    
  </svg></a>
</span>
			 that could be extended to support such a workflow. It already has support for different source and output formats like Jupyter notebooks, code execution and is built for interactive work with incremental rebuilds.</p>
			<span class="hr "></span>
			<p class="">
			Hopefully this page has given you some context for how FastAI.jl relates to fastai and how to map concepts between the two. You are encouraged to go through the tutorials to see the design decisions made in practice.</p></div></div>

<div class="more"></div></div></div></div>


		<script type="module" data-hydrate="iwyp6r">
		import { start } from "/FastAI.jl/internal/start-01fb7bee.js";
		start({
			target: document.querySelector('[data-hydrate="iwyp6r"]').parentNode,
			paths: {"base":"/FastAI.jl","assets":"/FastAI.jl"},
			session: {},
			route: false,
			spa: false,
			trailing_slash: "never",
			hydrate: {
				status: 200,
				error: null,
				nodes: [
					import("/FastAI.jl/internal/pages/__layout.svelte-4bac7188.js"),
						import("/FastAI.jl/internal/pages/_version_/_...documentId_.svelte-7aaa8049.js")
				],
				url: new URL("http://sveltekit-prerender/FastAI.jl/dev/documents/docs/fastai_api_comparison.md"),
				params: {version:"dev",documentId:"documents\u002Fdocs\u002Ffastai_api_comparison.md"}
			}
		});
	</script><script type="application/json" data-type="svelte-data" data-url="/FastAI.jl/data/dev/attributes.json">{"status":200,"statusText":"","headers":{"content-type":"application/json"},"body":"{\"references\u002FFastAI.withcallbacks\":{\"tag\":\"documentation\",\"title\":\"withcallbacks\"},\"references\u002FFastAI.lrfindtextplot!\":{\"tag\":\"documentation\",\"title\":\"lrfindtextplot!\"},\"references\u002FFastAI.Datasets.NamedTupleData\":{\"tag\":\"documentation\",\"title\":\"NamedTupleData\"},\"references\u002FFlux.GlobalMaxPool\":{\"tag\":\"documentation\",\"title\":\"GlobalMaxPool\"},\"references\u002FFastAI.Vision.IMAGENET_MEANS\":{\"tag\":\"documentation\",\"title\":\"IMAGENET_MEANS\"},\"documents\u002Fdocs\u002Fstatus.md\":{\"tag\":\"document\",\"title\":\"Status\"},\"references\u002FDataAugmentation.tensortoimage\":{\"tag\":\"documentation\",\"title\":\"tensortoimage\"},\"sourcefiles\u002FFlux\u002Fsrc\u002Foptimise\u002Foptimisers.jl\":{\"tag\":\"sourcefile\",\"title\":\"Flux\u002Fsrc\u002Foptimise\u002Foptimisers.jl\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002Ftraining\u002Fmetrics.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002Ftraining\u002Fmetrics.jl\"},\"references\u002FFlux._show_leaflike\":{\"tag\":\"documentation\",\"title\":\"_show_leaflike\"},\"references\u002FFastAI.ParamGroups\":{\"tag\":\"documentation\",\"title\":\"ParamGroups\"},\"references\u002FFastAI.Vision.Models.##InlineTest-01b48f5c342f65df7fcd07f28f0d2cacbb09f0a0.tests\":{\"tag\":\"documentation\",\"title\":\"tests\"},\"sourcefiles\u002FDataAugmentation\u002Fsrc\u002FDataAugmentation.jl\":{\"tag\":\"sourcefile\",\"title\":\"DataAugmentation\u002Fsrc\u002FDataAugmentation.jl\"},\"references\u002FFluxTraining.@pack_History!\":{\"tag\":\"documentation\",\"title\":\"@pack_History!\"},\"references\u002FFluxTraining.AbstractCallback\":{\"tag\":\"documentation\",\"title\":\"AbstractCallback\"},\"sourcefiles\u002FFlux\u002Fsrc\u002Flosses\u002Futils.jl\":{\"tag\":\"sourcefile\",\"title\":\"Flux\u002Fsrc\u002Flosses\u002Futils.jl\"},\"references\u002FFluxTraining.Phases.ValidationPhase\":{\"tag\":\"documentation\",\"title\":\"ValidationPhase\"},\"references\u002FDataAugmentation.showpolygon!\":{\"tag\":\"documentation\",\"title\":\"showpolygon!\"},\"references\u002FFluxTraining.iterpairs\":{\"tag\":\"documentation\",\"title\":\"iterpairs\"},\"references\u002FFluxTraining.StopOnNaNLoss\":{\"tag\":\"documentation\",\"title\":\"StopOnNaNLoss\"},\"references\u002FFlux._big_show\":{\"tag\":\"documentation\",\"title\":\"_big_show\"},\"references\u002FFlux.crosscor_dims\":{\"tag\":\"documentation\",\"title\":\"crosscor_dims\"},\"references\u002FFastAI.defaulttaskregistry\":{\"tag\":\"documentation\",\"title\":\"defaulttaskregistry\"},\"references\u002FFastAI.WrapperBlock\":{\"tag\":\"documentation\",\"title\":\"WrapperBlock\"},\"references\u002FFlux.nfan\":{\"tag\":\"documentation\",\"title\":\"nfan\"},\"references\u002FFlux.isleaflike\":{\"tag\":\"documentation\",\"title\":\"isleaflike\"},\"references\u002FFastAI.predictbatch\":{\"tag\":\"documentation\",\"title\":\"predictbatch\"},\"references\u002FFluxTraining.LinearRunner\":{\"tag\":\"documentation\",\"title\":\"LinearRunner\"},\"sourcefiles\u002FDataAugmentation\u002Fsrc\u002Fcolortransforms.jl\":{\"tag\":\"sourcefile\",\"title\":\"DataAugmentation\u002Fsrc\u002Fcolortransforms.jl\"},\"references\u002FFastAI._blockcell\":{\"tag\":\"documentation\",\"title\":\"_blockcell\"},\"references\u002FFastAI.mockinput\":{\"tag\":\"documentation\",\"title\":\"mockinput\"},\"references\u002FFastAI.Vision.Models.AdaptiveConcatPool\":{\"tag\":\"documentation\",\"title\":\"AdaptiveConcatPool\"},\"references\u002FFlux.ConvTranspose\":{\"tag\":\"documentation\",\"title\":\"ConvTranspose\"},\"references\u002FFlux.rand32\":{\"tag\":\"documentation\",\"title\":\"rand32\"},\"references\u002FFlux.Data\":{\"tag\":\"documentation\",\"title\":\"Data\"},\"references\u002FFluxTraining.setlearningrate!\":{\"tag\":\"documentation\",\"title\":\"setlearningrate!\"},\"references\u002FFastAI.Datasets.groupobs\":{\"tag\":\"documentation\",\"title\":\"groupobs\"},\"references\u002FFastAI.Vision.ImageKeypointRegression\":{\"tag\":\"documentation\",\"title\":\"ImageKeypointRegression\"},\"sourcefiles\u002FFlux\u002Fsrc\u002Futils.jl\":{\"tag\":\"sourcefile\",\"title\":\"Flux\u002Fsrc\u002Futils.jl\"},\"sourcefiles\u002FFluxTraining\u002Fsrc\u002Fcallbacks\u002Fhyperparameters.jl\":{\"tag\":\"sourcefile\",\"title\":\"FluxTraining\u002Fsrc\u002Fcallbacks\u002Fhyperparameters.jl\"},\"references\u002FFlux.CUDAint\":{\"tag\":\"documentation\",\"title\":\"CUDAint\"},\"references\u002FDataAugmentation.normalize!\":{\"tag\":\"documentation\",\"title\":\"normalize!\"},\"references\u002FFluxTraining.RunFirst\":{\"tag\":\"documentation\",\"title\":\"RunFirst\"},\"references\u002FFastAI.showblocksinterpretable\":{\"tag\":\"documentation\",\"title\":\"showblocksinterpretable\"},\"references\u002FFlux.testmode!\":{\"tag\":\"documentation\",\"title\":\"testmode!\"},\"references\u002FFastAI.setwrapped\":{\"tag\":\"documentation\",\"title\":\"setwrapped\"},\"references\u002FFluxTraining.ToDevice\":{\"tag\":\"documentation\",\"title\":\"ToDevice\"},\"references\u002FFluxTraining._on\":{\"tag\":\"documentation\",\"title\":\"_on\"},\"references\u002FFastAI.PropagateWrapper\":{\"tag\":\"documentation\",\"title\":\"PropagateWrapper\"},\"references\u002FFastAI.CONTEXTS\":{\"tag\":\"documentation\",\"title\":\"CONTEXTS\"},\"references\u002FFluxTraining.Loggables.Image\":{\"tag\":\"documentation\",\"title\":\"Image\"},\"references\u002FFlux.Optimise.apply!\":{\"tag\":\"documentation\",\"title\":\"apply!\"},\"documents\u002Fdocs\u002Fhowto\u002Faugmentvision.md\":{\"tag\":\"document\",\"title\":\"How to augment vision data\"},\"references\u002FFastAI.Tabular.TabularClassificationSingle\":{\"tag\":\"documentation\",\"title\":\"TabularClassificationSingle\"},\"references\u002FFastAI.describetask\":{\"tag\":\"documentation\",\"title\":\"describetask\"},\"references\u002FFlux._norm_layer_forward\":{\"tag\":\"documentation\",\"title\":\"_norm_layer_forward\"},\"references\u002FFastAI.fitonecycle!\":{\"tag\":\"documentation\",\"title\":\"fitonecycle!\"},\"references\u002FFluxTraining._dataiters\":{\"tag\":\"documentation\",\"title\":\"_dataiters\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002FTextual\u002FTextual.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002FTextual\u002FTextual.jl\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002FTextual\u002Fblocks\u002Ftext.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002FTextual\u002Fblocks\u002Ftext.jl\"},\"references\u002FFastAI.encodetarget\":{\"tag\":\"documentation\",\"title\":\"encodetarget\"},\"references\u002FFluxTraining.##InlineTest-01b48f5c342f65df7fcd07f28f0d2cacbb09f0a0.TESTSET_MACROS\":{\"tag\":\"documentation\",\"title\":\"TESTSET_MACROS\"},\"references\u002FFlux.trainmode!\":{\"tag\":\"documentation\",\"title\":\"trainmode!\"},\"references\u002FFastAI.shouldbatch\":{\"tag\":\"documentation\",\"title\":\"shouldbatch\"},\"references\u002FFastAI.frozen_optimizer\":{\"tag\":\"documentation\",\"title\":\"frozen_optimizer\"},\"references\u002FFluxTraining.Check\":{\"tag\":\"documentation\",\"title\":\"Check\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002Fdatasets\u002Frecipe.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002Fdatasets\u002Frecipe.jl\"},\"documents\u002Fdocs\u002Fbackground\u002Fblocksencodings.md\":{\"tag\":\"document\",\"title\":\"Blocks and encodings\"},\"references\u002FFluxTraining.throttle\":{\"tag\":\"documentation\",\"title\":\"throttle\"},\"references\u002FFluxTraining.Callbacks\":{\"tag\":\"documentation\",\"title\":\"Callbacks\"},\"references\u002FFluxTraining.LearningRate\":{\"tag\":\"documentation\",\"title\":\"LearningRate\"},\"references\u002FDataAugmentation.corners\":{\"tag\":\"documentation\",\"title\":\"corners\"},\"references\u002FFluxTraining.Metric\":{\"tag\":\"documentation\",\"title\":\"Metric\"},\"documents\u002Fnotebooks\u002Ftraining.ipynb\":{\"tag\":\"document\",\"title\":\"How to train a model\"},\"references\u002FFlux.modules\":{\"tag\":\"documentation\",\"title\":\"modules\"},\"sourcefiles\u002FFluxTraining\u002Fsrc\u002FFluxTraining.jl\":{\"tag\":\"sourcefile\",\"title\":\"FluxTraining\u002Fsrc\u002FFluxTraining.jl\"},\"sourcefiles\u002FFlux\u002Fsrc\u002Flayers\u002Fupsample.jl\":{\"tag\":\"sourcefile\",\"title\":\"Flux\u002Fsrc\u002Flayers\u002Fupsample.jl\"},\"references\u002FFastAI.tuplemap\":{\"tag\":\"documentation\",\"title\":\"tuplemap\"},\"references\u002FFastAI.default_showbackend\":{\"tag\":\"documentation\",\"title\":\"default_showbackend\"},\"sourcefiles\u002FFluxTraining\u002Fsrc\u002Fcallbacks\u002Fexecution.jl\":{\"tag\":\"sourcefile\",\"title\":\"FluxTraining\u002Fsrc\u002Fcallbacks\u002Fexecution.jl\"},\"references\u002FFastAI.Vision.IMAGENET_STDS\":{\"tag\":\"documentation\",\"title\":\"IMAGENET_STDS\"},\"references\u002FFlux.Losses._check_sizes\":{\"tag\":\"documentation\",\"title\":\"_check_sizes\"},\"references\u002FFastAI.Tabular.tabular_embedding_backbone\":{\"tag\":\"documentation\",\"title\":\"tabular_embedding_backbone\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002Finterpretation\u002Flearner.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002Finterpretation\u002Flearner.jl\"},\"references\u002FFluxTraining._combinename\":{\"tag\":\"documentation\",\"title\":\"_combinename\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002Ftasks\u002Fcheck.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002Ftasks\u002Fcheck.jl\"},\"references\u002FDataAugmentation.setdata\":{\"tag\":\"documentation\",\"title\":\"setdata\"},\"documents\u002Fnotebooks\u002Fserialization.ipynb\":{\"tag\":\"document\",\"title\":\"Saving and loading models for inference\"},\"references\u002FFastAI.OneHotLabel\":{\"tag\":\"documentation\",\"title\":\"OneHotLabel\"},\"references\u002FDataAugmentation.Sequence\":{\"tag\":\"documentation\",\"title\":\"Sequence\"},\"references\u002FFastAI.showencodedsample\":{\"tag\":\"documentation\",\"title\":\"showencodedsample\"},\"references\u002FFastAI.showencodedsamples\":{\"tag\":\"documentation\",\"title\":\"showencodedsamples\"},\"references\u002FFlux.Losses.mae\":{\"tag\":\"documentation\",\"title\":\"mae\"},\"references\u002FFlux.kaiming_normal\":{\"tag\":\"documentation\",\"title\":\"kaiming_normal\"},\"references\u002FFlux.GRU\":{\"tag\":\"documentation\",\"title\":\"GRU\"},\"references\u002FFlux.FluxCPUAdaptor\":{\"tag\":\"documentation\",\"title\":\"FluxCPUAdaptor\"},\"references\u002FFluxTraining.stateaccess\":{\"tag\":\"documentation\",\"title\":\"stateaccess\"},\"references\u002FDataAugmentation.fmap\":{\"tag\":\"documentation\",\"title\":\"fmap\"},\"references\u002FFastAI.showbatch\":{\"tag\":\"documentation\",\"title\":\"showbatch\"},\"sourcefiles\u002FFluxTraining\u002Fsrc\u002Fcallbacks\u002Flogging\u002FLoggables.jl\":{\"tag\":\"sourcefile\",\"title\":\"FluxTraining\u002Fsrc\u002Fcallbacks\u002Flogging\u002FLoggables.jl\"},\"references\u002FFluxTraining.Loggables.Graph\":{\"tag\":\"documentation\",\"title\":\"Graph\"},\"references\u002FFlux.LayerNorm\":{\"tag\":\"documentation\",\"title\":\"LayerNorm\"},\"references\u002FFastAI.withfields\":{\"tag\":\"documentation\",\"title\":\"withfields\"},\"references\u002FFastAI.Datasets.loadmask\":{\"tag\":\"documentation\",\"title\":\"loadmask\"},\"references\u002FFlux.Optimise.skip\":{\"tag\":\"documentation\",\"title\":\"skip\"},\"references\u002FFluxTraining.Events\":{\"tag\":\"documentation\",\"title\":\"Events\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002FVision\u002Fencodings\u002Fimagepreprocessing.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002FVision\u002Fencodings\u002Fimagepreprocessing.jl\"},\"references\u002FFastAI.mocktarget\":{\"tag\":\"documentation\",\"title\":\"mocktarget\"},\"references\u002FFastAI.Vision.getsamplebounds\":{\"tag\":\"documentation\",\"title\":\"getsamplebounds\"},\"references\u002FFlux._childarray_sum\":{\"tag\":\"documentation\",\"title\":\"_childarray_sum\"},\"references\u002FFlux.use_cuda\":{\"tag\":\"documentation\",\"title\":\"use_cuda\"},\"references\u002FFluxTraining.metricname\":{\"tag\":\"documentation\",\"title\":\"metricname\"},\"references\u002FFastAI.listdecodeblocks\":{\"tag\":\"documentation\",\"title\":\"listdecodeblocks\"},\"references\u002FFlux.Optimise.AdaBelief\":{\"tag\":\"documentation\",\"title\":\"AdaBelief\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002FVision\u002Ftasks\u002Fsegmentation.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002FVision\u002Ftasks\u002Fsegmentation.jl\"},\"references\u002FFlux.RNN\":{\"tag\":\"documentation\",\"title\":\"RNN\"},\"references\u002FFluxTraining.History\":{\"tag\":\"documentation\",\"title\":\"History\"},\"references\u002FFluxTraining.Scheduler\":{\"tag\":\"documentation\",\"title\":\"Scheduler\"},\"references\u002FFlux._gru_output\":{\"tag\":\"documentation\",\"title\":\"_gru_output\"},\"references\u002FFluxTraining.Checkpointer\":{\"tag\":\"documentation\",\"title\":\"Checkpointer\"},\"sourcefiles\u002FDataAugmentation\u002Fsrc\u002Foneof.jl\":{\"tag\":\"sourcefile\",\"title\":\"DataAugmentation\u002Fsrc\u002Foneof.jl\"},\"references\u002FFlux.gate\":{\"tag\":\"documentation\",\"title\":\"gate\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002Finterpretation\u002Fdetect.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002Finterpretation\u002Fdetect.jl\"},\"references\u002FFlux.frequencies\":{\"tag\":\"documentation\",\"title\":\"frequencies\"},\"references\u002FFlux._onehotindex\":{\"tag\":\"documentation\",\"title\":\"_onehotindex\"},\"references\u002FFastAI.encode\":{\"tag\":\"documentation\",\"title\":\"encode\"},\"references\u002FFastAI.OneHotTensorMulti\":{\"tag\":\"documentation\",\"title\":\"OneHotTensorMulti\"},\"references\u002FFastAI._predictx\":{\"tag\":\"documentation\",\"title\":\"_predictx\"},\"sourcefiles\u002FFlux\u002Fsrc\u002Flayers\u002Fbasic.jl\":{\"tag\":\"sourcefile\",\"title\":\"Flux\u002Fsrc\u002Flayers\u002Fbasic.jl\"},\"references\u002FDataAugmentation.MaskBinary\":{\"tag\":\"documentation\",\"title\":\"MaskBinary\"},\"references\u002FFastAI.smoothvalues\":{\"tag\":\"documentation\",\"title\":\"smoothvalues\"},\"references\u002FDataAugmentation.AbstractCrop\":{\"tag\":\"documentation\",\"title\":\"AbstractCrop\"},\"references\u002FFastAI.Tabular.##InlineTest-01b48f5c342f65df7fcd07f28f0d2cacbb09f0a0.TESTSET_MACROS\":{\"tag\":\"documentation\",\"title\":\"TESTSET_MACROS\"},\"references\u002FFastAI.Datasets.##InlineTest-01b48f5c342f65df7fcd07f28f0d2cacbb09f0a0.__init__\":{\"tag\":\"documentation\",\"title\":\"__init__\"},\"references\u002FFastAI.Datasets.FastAIDataset\":{\"tag\":\"documentation\",\"title\":\"FastAIDataset\"},\"references\u002FFastAI._decode\":{\"tag\":\"documentation\",\"title\":\"_decode\"},\"references\u002FFluxTraining.phasedataiter\":{\"tag\":\"documentation\",\"title\":\"phasedataiter\"},\"references\u002FFastAI.Vision.grabbounds\":{\"tag\":\"documentation\",\"title\":\"grabbounds\"},\"references\u002FFastAI.Vision.Models.##InlineTest-01b48f5c342f65df7fcd07f28f0d2cacbb09f0a0.__init__\":{\"tag\":\"documentation\",\"title\":\"__init__\"},\"references\u002FFastAI.Validation\":{\"tag\":\"documentation\",\"title\":\"Validation\"},\"references\u002FFastAI.Block\":{\"tag\":\"documentation\",\"title\":\"Block\"},\"references\u002FFlux.Losses.poisson_loss\":{\"tag\":\"documentation\",\"title\":\"poisson_loss\"},\"references\u002FDataAugmentation._channelview\":{\"tag\":\"documentation\",\"title\":\"_channelview\"},\"references\u002FFlux.Losses.msle\":{\"tag\":\"documentation\",\"title\":\"msle\"},\"references\u002FFlux.loadleaf!\":{\"tag\":\"documentation\",\"title\":\"loadleaf!\"},\"references\u002FFastAI.SupervisedTask\":{\"tag\":\"documentation\",\"title\":\"SupervisedTask\"},\"references\u002FFastAI.Datasets.rglob\":{\"tag\":\"documentation\",\"title\":\"rglob\"},\"references\u002FFluxTraining.epochvalue\":{\"tag\":\"documentation\",\"title\":\"epochvalue\"},\"references\u002FFlux.Losses.compute_beta_and_grad_kernel\":{\"tag\":\"documentation\",\"title\":\"compute_beta_and_grad_kernel\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002FTabular\u002Fblocks\u002Ftablerow.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002FTabular\u002Fblocks\u002Ftablerow.jl\"},\"references\u002FFlux.Optimise.stop\":{\"tag\":\"documentation\",\"title\":\"stop\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002Fblocks\u002Fcontinuous.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002Fblocks\u002Fcontinuous.jl\"},\"references\u002FFlux.Optimise.ADADelta\":{\"tag\":\"documentation\",\"title\":\"ADADelta\"},\"references\u002FFastAI.Training\":{\"tag\":\"documentation\",\"title\":\"Training\"},\"references\u002FDataAugmentation.RandomCrop\":{\"tag\":\"documentation\",\"title\":\"RandomCrop\"},\"references\u002FFastAI\":{\"tag\":\"documentation\",\"title\":\"FastAI\"},\"references\u002FFlux.GRUv3\":{\"tag\":\"documentation\",\"title\":\"GRUv3\"},\"references\u002FDataAugmentation.Rotate\":{\"tag\":\"documentation\",\"title\":\"Rotate\"},\"references\u002FFlux.GroupNorm\":{\"tag\":\"documentation\",\"title\":\"GroupNorm\"},\"references\u002FFlux._indices\":{\"tag\":\"documentation\",\"title\":\"_indices\"},\"references\u002FFastAI.Vision.Models.catchannels\":{\"tag\":\"documentation\",\"title\":\"catchannels\"},\"references\u002FDataAugmentation.OneOfProjective\":{\"tag\":\"documentation\",\"title\":\"OneOfProjective\"},\"references\u002FDataAugmentation.BufferedThreadsafe\":{\"tag\":\"documentation\",\"title\":\"BufferedThreadsafe\"},\"references\u002FFluxTraining.accesses\":{\"tag\":\"documentation\",\"title\":\"accesses\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002FVision\u002Fencodings\u002Fprojective.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002FVision\u002Fencodings\u002Fprojective.jl\"},\"references\u002FDataAugmentation.NormalizeRow\":{\"tag\":\"documentation\",\"title\":\"NormalizeRow\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002FTabular\u002Frecipes.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002FTabular\u002Frecipes.jl\"},\"references\u002FFlux.Optimise.update!\":{\"tag\":\"documentation\",\"title\":\"update!\"},\"references\u002FFastAI.Vision.ImageTensor\":{\"tag\":\"documentation\",\"title\":\"ImageTensor\"},\"references\u002FFastAI.Only\":{\"tag\":\"documentation\",\"title\":\"Only\"},\"references\u002FFastAI.Tabular.EncodedTableRow\":{\"tag\":\"documentation\",\"title\":\"EncodedTableRow\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002Fblocks\u002Flabel.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002Fblocks\u002Flabel.jl\"},\"references\u002FDataAugmentation.imagetotensor!\":{\"tag\":\"documentation\",\"title\":\"imagetotensor!\"},\"references\u002FFlux.SamePad\":{\"tag\":\"documentation\",\"title\":\"SamePad\"},\"references\u002FFluxTraining.PropDict\":{\"tag\":\"documentation\",\"title\":\"PropDict\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002FTabular\u002Ftasks\u002Fclassification.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002FTabular\u002Ftasks\u002Fclassification.jl\"},\"references\u002FFlux.Optimise.Optimiser\":{\"tag\":\"documentation\",\"title\":\"Optimiser\"},\"references\u002FFastAI.Datasets.##InlineTest-01b48f5c342f65df7fcd07f28f0d2cacbb09f0a0.TESTSET_MACROS\":{\"tag\":\"documentation\",\"title\":\"TESTSET_MACROS\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002Fdatablock\u002Fwrappers.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002Fdatablock\u002Fwrappers.jl\"},\"references\u002FDataAugmentation.getwrapped\":{\"tag\":\"documentation\",\"title\":\"getwrapped\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002Finterpretation\u002Ftask.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002Finterpretation\u002Ftask.jl\"},\"sourcefiles\u002FDataAugmentation\u002Fsrc\u002Fpreprocessing.jl\":{\"tag\":\"sourcefile\",\"title\":\"DataAugmentation\u002Fsrc\u002Fpreprocessing.jl\"},\"references\u002FFastAI.showoutput\":{\"tag\":\"documentation\",\"title\":\"showoutput\"},\"references\u002FFluxTraining.fit!\":{\"tag\":\"documentation\",\"title\":\"fit!\"},\"references\u002FFluxTraining.SanityCheckException\":{\"tag\":\"documentation\",\"title\":\"SanityCheckException\"},\"references\u002FFluxTraining.UnsafeCallback\":{\"tag\":\"documentation\",\"title\":\"UnsafeCallback\"},\"references\u002FFastAI.Textual\":{\"tag\":\"documentation\",\"title\":\"Textual\"},\"sourcefiles\u002FFluxTraining\u002Fsrc\u002Fcallbacks\u002Fcallbacks.jl\":{\"tag\":\"sourcefile\",\"title\":\"FluxTraining\u002Fsrc\u002Fcallbacks\u002Fcallbacks.jl\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002FTabular\u002FTabular.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002FTabular\u002FTabular.jl\"},\"references\u002FFastAI.Datasets\":{\"tag\":\"documentation\",\"title\":\"Datasets\"},\"references\u002FFluxTraining.Permission\":{\"tag\":\"documentation\",\"title\":\"Permission\"},\"references\u002FFlux.calc_padding\":{\"tag\":\"documentation\",\"title\":\"calc_padding\"},\"sourcefiles\u002FFlux\u002Fsrc\u002Flayers\u002Fnormalise.jl\":{\"tag\":\"sourcefile\",\"title\":\"Flux\u002Fsrc\u002Flayers\u002Fnormalise.jl\"},\"references\u002FDataAugmentation.normalize\":{\"tag\":\"documentation\",\"title\":\"normalize\"},\"references\u002FFastAI.Vision.Models.convxlayer\":{\"tag\":\"documentation\",\"title\":\"convxlayer\"},\"references\u002FFlux.OneHotMatrix\":{\"tag\":\"documentation\",\"title\":\"OneHotMatrix\"},\"references\u002FFastAI.Vision.DimSize\":{\"tag\":\"documentation\",\"title\":\"DimSize\"},\"references\u002FFluxTraining.removecallback!\":{\"tag\":\"documentation\",\"title\":\"removecallback!\"},\"references\u002FFastAI.Vision.Models.convx\":{\"tag\":\"documentation\",\"title\":\"convx\"},\"references\u002FDataAugmentation.testapply\":{\"tag\":\"documentation\",\"title\":\"testapply\"},\"references\u002FFluxTraining.addcallback!\":{\"tag\":\"documentation\",\"title\":\"addcallback!\"},\"references\u002FFastAI.Tabular.removecol\":{\"tag\":\"documentation\",\"title\":\"removecol\"},\"references\u002FFluxTraining.CheckDataIteratorTrain\":{\"tag\":\"documentation\",\"title\":\"CheckDataIteratorTrain\"},\"references\u002FFastAI.showblocks\":{\"tag\":\"documentation\",\"title\":\"showblocks\"},\"references\u002FDataAugmentation.MaskMulti\":{\"tag\":\"documentation\",\"title\":\"MaskMulti\"},\"sourcefiles\u002FFluxTraining\u002Fsrc\u002Fcallbacks\u002Fcallback.jl\":{\"tag\":\"sourcefile\",\"title\":\"FluxTraining\u002Fsrc\u002Fcallbacks\u002Fcallback.jl\"},\"references\u002FFluxTraining.Events.BackwardBegin\":{\"tag\":\"documentation\",\"title\":\"BackwardBegin\"},\"references\u002FFastAI.Datasets.FASTAI_DATA_REGISTRY\":{\"tag\":\"documentation\",\"title\":\"FASTAI_DATA_REGISTRY\"},\"sourcefiles\u002FFluxTraining\u002Fsrc\u002Fcallbacks\u002Fphases.jl\":{\"tag\":\"sourcefile\",\"title\":\"FluxTraining\u002Fsrc\u002Fcallbacks\u002Fphases.jl\"},\"references\u002FFastAI.encodeinput\":{\"tag\":\"documentation\",\"title\":\"encodeinput\"},\"references\u002FDataAugmentation.offsetcropbounds\":{\"tag\":\"documentation\",\"title\":\"offsetcropbounds\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002Fdatasets\u002Fregistry.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002Fdatasets\u002Fregistry.jl\"},\"references\u002FDataAugmentation._default_digits\":{\"tag\":\"documentation\",\"title\":\"_default_digits\"},\"references\u002FFlux.Losses.logitcrossentropy\":{\"tag\":\"documentation\",\"title\":\"logitcrossentropy\"},\"references\u002FFastAI.listencodeblocks\":{\"tag\":\"documentation\",\"title\":\"listencodeblocks\"},\"references\u002FFastAI.LabelMulti\":{\"tag\":\"documentation\",\"title\":\"LabelMulti\"},\"references\u002FFluxTraining.LogHistograms\":{\"tag\":\"documentation\",\"title\":\"LogHistograms\"},\"references\u002FFluxTraining.shouldrun\":{\"tag\":\"documentation\",\"title\":\"shouldrun\"},\"references\u002FFlux.Chain\":{\"tag\":\"documentation\",\"title\":\"Chain\"},\"references\u002FFluxTraining.init!\":{\"tag\":\"documentation\",\"title\":\"init!\"},\"references\u002FFastAI.decodedblockfilled\":{\"tag\":\"documentation\",\"title\":\"decodedblockfilled\"},\"sourcefiles\u002FFlux\u002Fsrc\u002FFlux.jl\":{\"tag\":\"sourcefile\",\"title\":\"Flux\u002Fsrc\u002FFlux.jl\"},\"references\u002FFluxTraining.setfieldperm!\":{\"tag\":\"documentation\",\"title\":\"setfieldperm!\"},\"references\u002FFluxTraining.getfieldperm\":{\"tag\":\"documentation\",\"title\":\"getfieldperm\"},\"references\u002FFlux.GRUCell\":{\"tag\":\"documentation\",\"title\":\"GRUCell\"},\"references\u002FFluxTraining.CHECKS\":{\"tag\":\"documentation\",\"title\":\"CHECKS\"},\"references\u002FFastAI.registerlearningtask!\":{\"tag\":\"documentation\",\"title\":\"registerlearningtask!\"},\"references\u002FFluxTraining.Metrics\":{\"tag\":\"documentation\",\"title\":\"Metrics\"},\"references\u002FFlux.Losses.hinge_loss\":{\"tag\":\"documentation\",\"title\":\"hinge_loss\"},\"references\u002FFastAI.Vision.augs_projection\":{\"tag\":\"documentation\",\"title\":\"augs_projection\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002Ftasks\u002Fpredict.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002Ftasks\u002Fpredict.jl\"},\"references\u002FFastAI.Tabular.getcoltypes\":{\"tag\":\"documentation\",\"title\":\"getcoltypes\"},\"references\u002FFastAI.findlearningtasks\":{\"tag\":\"documentation\",\"title\":\"findlearningtasks\"},\"references\u002FFastAI.Vision.Models.xresnet50\":{\"tag\":\"documentation\",\"title\":\"xresnet50\"},\"documents\u002Fnotebooks\u002Fvae.ipynb\":{\"tag\":\"document\",\"title\":\"Variational autoencoders\"},\"references\u002FFastAI.test_task_show\":{\"tag\":\"documentation\",\"title\":\"test_task_show\"},\"references\u002FFlux.check_use_cuda\":{\"tag\":\"documentation\",\"title\":\"check_use_cuda\"},\"references\u002FFastAI.Vision.ImageFolders\":{\"tag\":\"documentation\",\"title\":\"ImageFolders\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002Finterpretation\u002Fshowinterpretable.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002Finterpretation\u002Fshowinterpretable.jl\"},\"references\u002FFastAI.Datasets.filterobs\":{\"tag\":\"documentation\",\"title\":\"filterobs\"},\"references\u002FFluxTraining.Loggables.Loggable\":{\"tag\":\"documentation\",\"title\":\"Loggable\"},\"references\u002FDataAugmentation.projectionbounds\":{\"tag\":\"documentation\",\"title\":\"projectionbounds\"},\"references\u002FFluxTraining.Read\":{\"tag\":\"documentation\",\"title\":\"Read\"},\"references\u002FFlux.reshape_cell_output\":{\"tag\":\"documentation\",\"title\":\"reshape_cell_output\"},\"references\u002FFastAI.AbstractBlockTask\":{\"tag\":\"documentation\",\"title\":\"AbstractBlockTask\"},\"references\u002FDataAugmentation._colorview\":{\"tag\":\"documentation\",\"title\":\"_colorview\"},\"references\u002FFlux.Optimise.Momentum\":{\"tag\":\"documentation\",\"title\":\"Momentum\"},\"references\u002FFlux.Parallel\":{\"tag\":\"documentation\",\"title\":\"Parallel\"},\"references\u002FFastAI.LREstimator\":{\"tag\":\"documentation\",\"title\":\"LREstimator\"},\"sourcefiles\u002FFlux\u002Fsrc\u002Flayers\u002Fshow.jl\":{\"tag\":\"sourcefile\",\"title\":\"Flux\u002Fsrc\u002Flayers\u002Fshow.jl\"},\"references\u002FFluxTraining.getcallback\":{\"tag\":\"documentation\",\"title\":\"getcallback\"},\"references\u002FFastAI.Vision.Models.XResNet\":{\"tag\":\"documentation\",\"title\":\"XResNet\"},\"references\u002FFastAI.decodewhile\":{\"tag\":\"documentation\",\"title\":\"decodewhile\"},\"references\u002FFluxTraining._resolveconflict\":{\"tag\":\"documentation\",\"title\":\"_resolveconflict\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002FVision\u002Fmodels\u002Funet.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002FVision\u002Fmodels\u002Funet.jl\"},\"sourcefiles\u002FFluxTraining\u002Fsrc\u002Fcallbacks\u002Flogging\u002Ftensorboard.jl\":{\"tag\":\"sourcefile\",\"title\":\"FluxTraining\u002Fsrc\u002Fcallbacks\u002Flogging\u002Ftensorboard.jl\"},\"references\u002FFlux.flatten\":{\"tag\":\"documentation\",\"title\":\"flatten\"},\"references\u002FFlux.truncated_normal\":{\"tag\":\"documentation\",\"title\":\"truncated_normal\"},\"references\u002FFlux.conv_transpose_dims\":{\"tag\":\"documentation\",\"title\":\"conv_transpose_dims\"},\"references\u002FFastAI.Datasets.loadfolderdata\":{\"tag\":\"documentation\",\"title\":\"loadfolderdata\"},\"references\u002FFastAI.Vision.##InlineTest-01b48f5c342f65df7fcd07f28f0d2cacbb09f0a0.TESTSET_MACROS\":{\"tag\":\"documentation\",\"title\":\"TESTSET_MACROS\"},\"references\u002FFastAI.MinDivByTen\":{\"tag\":\"documentation\",\"title\":\"MinDivByTen\"},\"sourcefiles\u002FDataAugmentation\u002Fsrc\u002Fprojective\u002Fbase.jl\":{\"tag\":\"sourcefile\",\"title\":\"DataAugmentation\u002Fsrc\u002Fprojective\u002Fbase.jl\"},\"references\u002FFastAI.Vision.Models.PixelShuffle\":{\"tag\":\"documentation\",\"title\":\"PixelShuffle\"},\"references\u002FFluxTraining.Loggables.Value\":{\"tag\":\"documentation\",\"title\":\"Value\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002FVision\u002FVision.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002FVision\u002FVision.jl\"},\"references\u002FFlux.Optimise.ClipNorm\":{\"tag\":\"documentation\",\"title\":\"ClipNorm\"},\"documents\u002Fdocs\u002Ftutorials\u002Flearningmethod.md\":{\"tag\":\"document\",\"title\":\"learningmethod\"},\"references\u002FFastAI.Tabular.TableRegressionRecipe\":{\"tag\":\"documentation\",\"title\":\"TableRegressionRecipe\"},\"references\u002FFlux.f64\":{\"tag\":\"documentation\",\"title\":\"f64\"},\"sourcefiles\u002FFluxTraining\u002Fsrc\u002Fcallbacks\u002Fscheduler.jl\":{\"tag\":\"sourcefile\",\"title\":\"FluxTraining\u002Fsrc\u002Fcallbacks\u002Fscheduler.jl\"},\"documents\u002Fnotebooks\u002Fhow_to_visualize.ipynb\":{\"tag\":\"document\",\"title\":\"How to visualize data\"},\"references\u002FFluxTraining.CheckModelLossStep\":{\"tag\":\"documentation\",\"title\":\"CheckModelLossStep\"},\"references\u002FFastAI.createhandle\":{\"tag\":\"documentation\",\"title\":\"createhandle\"},\"references\u002FFlux._onehot_bool_type\":{\"tag\":\"documentation\",\"title\":\"_onehot_bool_type\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002Fdatasets\u002Ffastairegistry.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002Fdatasets\u002Ffastairegistry.jl\"},\"references\u002FFlux._maybetuple_string\":{\"tag\":\"documentation\",\"title\":\"_maybetuple_string\"},\"references\u002FFastAI.taskmodel\":{\"tag\":\"documentation\",\"title\":\"taskmodel\"},\"references\u002FFastAI.Vision.Models.upsample_block_small\":{\"tag\":\"documentation\",\"title\":\"upsample_block_small\"},\"references\u002FFastAI.encodeinput!\":{\"tag\":\"documentation\",\"title\":\"encodeinput!\"},\"references\u002FFlux.applychain\":{\"tag\":\"documentation\",\"title\":\"applychain\"},\"references\u002FFastAI.Datasets.registerdataset!\":{\"tag\":\"documentation\",\"title\":\"registerdataset!\"},\"references\u002FDataAugmentation.Image\":{\"tag\":\"documentation\",\"title\":\"Image\"},\"references\u002FFastAI.Tabular\":{\"tag\":\"documentation\",\"title\":\"Tabular\"},\"references\u002FFastAI.Datasets.DatasetRegistry\":{\"tag\":\"documentation\",\"title\":\"DatasetRegistry\"},\"references\u002FFluxTraining.print_epoch_table\":{\"tag\":\"documentation\",\"title\":\"print_epoch_table\"},\"references\u002FFastAI.Tabular.linbndrop\":{\"tag\":\"documentation\",\"title\":\"linbndrop\"},\"references\u002FDataAugmentation.denormalize!\":{\"tag\":\"documentation\",\"title\":\"denormalize!\"},\"references\u002FFastAI.Label\":{\"tag\":\"documentation\",\"title\":\"Label\"},\"sourcefiles\u002FFluxTraining\u002Fsrc\u002Fcallbacks\u002Fcustom.jl\":{\"tag\":\"sourcefile\",\"title\":\"FluxTraining\u002Fsrc\u002Fcallbacks\u002Fcustom.jl\"},\"references\u002FFluxTraining.Protected\":{\"tag\":\"documentation\",\"title\":\"Protected\"},\"references\u002FFastAI.encodedblock\":{\"tag\":\"documentation\",\"title\":\"encodedblock\"},\"references\u002FFluxTraining.paramsrec\":{\"tag\":\"documentation\",\"title\":\"paramsrec\"},\"references\u002FFlux.Optimise.OADAM\":{\"tag\":\"documentation\",\"title\":\"OADAM\"},\"references\u002FFastAI.Named\":{\"tag\":\"documentation\",\"title\":\"Named\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002Fdatasets\u002Fload.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002Fdatasets\u002Fload.jl\"},\"references\u002FFluxTraining.edgesrunafter\":{\"tag\":\"documentation\",\"title\":\"edgesrunafter\"},\"references\u002FFastAI.ShowMakie\":{\"tag\":\"documentation\",\"title\":\"ShowMakie\"},\"references\u002FFastAI.taskdataloaders\":{\"tag\":\"documentation\",\"title\":\"taskdataloaders\"},\"references\u002FFluxTraining.resolveconflict\":{\"tag\":\"documentation\",\"title\":\"resolveconflict\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002Ftraining\u002Futils.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002Ftraining\u002Futils.jl\"},\"references\u002FFluxTraining.stepvalue\":{\"tag\":\"documentation\",\"title\":\"stepvalue\"},\"references\u002FFlux.outputsize\":{\"tag\":\"documentation\",\"title\":\"outputsize\"},\"references\u002FFastAI.Vision.ImageTableMultiLabel\":{\"tag\":\"documentation\",\"title\":\"ImageTableMultiLabel\"},\"references\u002FDataAugmentation.Reflect\":{\"tag\":\"documentation\",\"title\":\"Reflect\"},\"references\u002FFastAI.Tabular._registerrecipes\":{\"tag\":\"documentation\",\"title\":\"_registerrecipes\"},\"references\u002FFastAI.Datasets.##InlineTest-01b48f5c342f65df7fcd07f28f0d2cacbb09f0a0.tests\":{\"tag\":\"documentation\",\"title\":\"tests\"},\"references\u002FFlux._nan_show\":{\"tag\":\"documentation\",\"title\":\"_nan_show\"},\"references\u002FFluxTraining.ProtectedException\":{\"tag\":\"documentation\",\"title\":\"ProtectedException\"},\"references\u002FFastAI.Tabular.TabularModel\":{\"tag\":\"documentation\",\"title\":\"TabularModel\"},\"references\u002FFluxTraining.Events.StepEnd\":{\"tag\":\"documentation\",\"title\":\"StepEnd\"},\"references\u002FFastAI.mockblock\":{\"tag\":\"documentation\",\"title\":\"mockblock\"},\"references\u002FFastAI.Textual.##InlineTest-01b48f5c342f65df7fcd07f28f0d2cacbb09f0a0.__init__\":{\"tag\":\"documentation\",\"title\":\"__init__\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002Ftasks\u002Ftask.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002Ftasks\u002Ftask.jl\"},\"references\u002FDataAugmentation.boundsof\":{\"tag\":\"documentation\",\"title\":\"boundsof\"},\"references\u002FFluxTraining.Loggables.Audio\":{\"tag\":\"documentation\",\"title\":\"Audio\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002Fdatasets\u002Fcontainers.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002Fdatasets\u002Fcontainers.jl\"},\"references\u002FDataAugmentation.__round\":{\"tag\":\"documentation\",\"title\":\"__round\"},\"documents\u002Fnotebooks\u002F10_26_showblock.ipynb\":{\"tag\":\"document\",\"title\":\"New visualization tools for FastAI.jl\"},\"references\u002FFastAI.Vision.##InlineTest-01b48f5c342f65df7fcd07f28f0d2cacbb09f0a0.tests\":{\"tag\":\"documentation\",\"title\":\"tests\"},\"references\u002FFlux.onecold\":{\"tag\":\"documentation\",\"title\":\"onecold\"},\"references\u002FFastAI.ShowText\":{\"tag\":\"documentation\",\"title\":\"ShowText\"},\"sourcefiles\u002FFluxTraining\u002Fsrc\u002Fcallbacks\u002Flogging\u002Flogger.jl\":{\"tag\":\"sourcefile\",\"title\":\"FluxTraining\u002Fsrc\u002Fcallbacks\u002Flogging\u002Flogger.jl\"},\"references\u002FDataAugmentation.itemdata\":{\"tag\":\"documentation\",\"title\":\"itemdata\"},\"references\u002FFastAI.PropagateSameBlock\":{\"tag\":\"documentation\",\"title\":\"PropagateSameBlock\"},\"sourcefiles\u002FDataAugmentation\u002Fsrc\u002Fprojective\u002Fcrop.jl\":{\"tag\":\"sourcefile\",\"title\":\"DataAugmentation\u002Fsrc\u002Fprojective\u002Fcrop.jl\"},\"references\u002FFlux._fast_argmax\":{\"tag\":\"documentation\",\"title\":\"_fast_argmax\"},\"sourcefiles\u002FFlux\u002Fsrc\u002Foptimise\u002Ftrain.jl\":{\"tag\":\"sourcefile\",\"title\":\"Flux\u002Fsrc\u002Foptimise\u002Ftrain.jl\"},\"references\u002FFlux.Optimise.ADAMW\":{\"tag\":\"documentation\",\"title\":\"ADAMW\"},\"references\u002FFluxTraining.accuracy\":{\"tag\":\"documentation\",\"title\":\"accuracy\"},\"references\u002FDataAugmentation.ResizePadDivisible\":{\"tag\":\"documentation\",\"title\":\"ResizePadDivisible\"},\"sourcefiles\u002FFluxTraining\u002Fsrc\u002Fcallbackutils.jl\":{\"tag\":\"sourcefile\",\"title\":\"FluxTraining\u002Fsrc\u002Fcallbackutils.jl\"},\"references\u002FFastAI.blocktypesmatch\":{\"tag\":\"documentation\",\"title\":\"blocktypesmatch\"},\"references\u002FFastAI.Vision.Models.unetlayers\":{\"tag\":\"documentation\",\"title\":\"unetlayers\"},\"references\u002FFastAI.showblock!\":{\"tag\":\"documentation\",\"title\":\"showblock!\"},\"references\u002FFastAI.Tabular.TableRow\":{\"tag\":\"documentation\",\"title\":\"TableRow\"},\"references\u002FFluxTraining.FitException\":{\"tag\":\"documentation\",\"title\":\"FitException\"},\"documents\u002Fnotebooks\u002Fkeypointregression.ipynb\":{\"tag\":\"document\",\"title\":\"Keypoint regression\"},\"references\u002FFastAI.Steepest\":{\"tag\":\"documentation\",\"title\":\"Steepest\"},\"references\u002FFastAI.setup\":{\"tag\":\"documentation\",\"title\":\"setup\"},\"references\u002FFlux.Losses.squared_hinge_loss\":{\"tag\":\"documentation\",\"title\":\"squared_hinge_loss\"},\"references\u002FFlux.Dense\":{\"tag\":\"documentation\",\"title\":\"Dense\"},\"references\u002FFlux._dropout_kernel\":{\"tag\":\"documentation\",\"title\":\"_dropout_kernel\"},\"sourcefiles\u002FDataAugmentation\u002Fsrc\u002Fbase.jl\":{\"tag\":\"sourcefile\",\"title\":\"DataAugmentation\u002Fsrc\u002Fbase.jl\"},\"references\u002FFastAI.methodlossfn\":{\"tag\":\"documentation\",\"title\":\"methodlossfn\"},\"references\u002FDataAugmentation.CropFrom\":{\"tag\":\"documentation\",\"title\":\"CropFrom\"},\"references\u002FDataAugmentation.testapply!\":{\"tag\":\"documentation\",\"title\":\"testapply!\"},\"documents\u002Fdocs\u002Fapi.md\":{\"tag\":\"document\",\"title\":\"FastAI.jl interfaces\"},\"references\u002FFastAI.Tabular.gettransformdict\":{\"tag\":\"documentation\",\"title\":\"gettransformdict\"},\"references\u002FDataAugmentation.PadDivisible\":{\"tag\":\"documentation\",\"title\":\"PadDivisible\"},\"references\u002FFastAI.methodlearner\":{\"tag\":\"documentation\",\"title\":\"methodlearner\"},\"references\u002FFluxTraining.Phases.AbstractTrainingPhase\":{\"tag\":\"documentation\",\"title\":\"AbstractTrainingPhase\"},\"references\u002FFlux._findval\":{\"tag\":\"documentation\",\"title\":\"_findval\"},\"references\u002FDataAugmentation.testitem\":{\"tag\":\"documentation\",\"title\":\"testitem\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002Fdeprecations.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002Fdeprecations.jl\"},\"references\u002FFluxTraining.GarbageCollect\":{\"tag\":\"documentation\",\"title\":\"GarbageCollect\"},\"references\u002FFastAI.Vision.Mask\":{\"tag\":\"documentation\",\"title\":\"Mask\"},\"references\u002FFluxTraining.LogVisualization\":{\"tag\":\"documentation\",\"title\":\"LogVisualization\"},\"references\u002FFastAI.Datasets.JoinedData\":{\"tag\":\"documentation\",\"title\":\"JoinedData\"},\"references\u002FFastAI.blockmodel\":{\"tag\":\"documentation\",\"title\":\"blockmodel\"},\"references\u002FFluxTraining.Events.Event\":{\"tag\":\"documentation\",\"title\":\"Event\"},\"references\u002FFluxTraining.setindexperm!\":{\"tag\":\"documentation\",\"title\":\"setindexperm!\"},\"references\u002FDataAugmentation.adjustcontrast\":{\"tag\":\"documentation\",\"title\":\"adjustcontrast\"},\"references\u002FFluxTraining.CancelFittingException\":{\"tag\":\"documentation\",\"title\":\"CancelFittingException\"},\"references\u002FFastAI.Vision\":{\"tag\":\"documentation\",\"title\":\"Vision\"},\"references\u002FDataAugmentation.ImageToTensor\":{\"tag\":\"documentation\",\"title\":\"ImageToTensor\"},\"references\u002FFlux.plateau\":{\"tag\":\"documentation\",\"title\":\"plateau\"},\"references\u002FFastAI.Vision.RECIPES\":{\"tag\":\"documentation\",\"title\":\"RECIPES\"},\"references\u002FFastAI.wrapped\":{\"tag\":\"documentation\",\"title\":\"wrapped\"},\"references\u002FFastAI.Vision.Models.linbndrop\":{\"tag\":\"documentation\",\"title\":\"linbndrop\"},\"references\u002FFluxTraining.hasconflict\":{\"tag\":\"documentation\",\"title\":\"hasconflict\"},\"references\u002FFastAI.group\":{\"tag\":\"documentation\",\"title\":\"group\"},\"references\u002FDataAugmentation.apply\":{\"tag\":\"documentation\",\"title\":\"apply\"},\"references\u002FFluxTraining.LogHyperParams\":{\"tag\":\"documentation\",\"title\":\"LogHyperParams\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002Finterpretation\u002Fbackend.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002Finterpretation\u002Fbackend.jl\"},\"references\u002FFlux.Optimise.train!\":{\"tag\":\"documentation\",\"title\":\"train!\"},\"references\u002FFlux._dropout_mask\":{\"tag\":\"documentation\",\"title\":\"_dropout_mask\"},\"references\u002FFluxTraining.Events.BackwardEnd\":{\"tag\":\"documentation\",\"title\":\"BackwardEnd\"},\"references\u002FFastAI.Vision.Keypoints\":{\"tag\":\"documentation\",\"title\":\"Keypoints\"},\"documents\u002Fnotebooks\u002Fpresizing.ipynb\":{\"tag\":\"document\",\"title\":\"Presizing vision datasets for performance\"},\"references\u002FDataAugmentation.FlipY\":{\"tag\":\"documentation\",\"title\":\"FlipY\"},\"sourcefiles\u002FDataAugmentation\u002Fsrc\u002Fbuffered.jl\":{\"tag\":\"sourcefile\",\"title\":\"DataAugmentation\u002Fsrc\u002Fbuffered.jl\"},\"references\u002FFluxTraining.Loggables.Histogram\":{\"tag\":\"documentation\",\"title\":\"Histogram\"},\"sourcefiles\u002FDataAugmentation\u002Fsrc\u002Ftesting.jl\":{\"tag\":\"sourcefile\",\"title\":\"DataAugmentation\u002Fsrc\u002Ftesting.jl\"},\"sourcefiles\u002FFlux\u002Fsrc\u002Flosses\u002Ffunctions.jl\":{\"tag\":\"sourcefile\",\"title\":\"Flux\u002Fsrc\u002Flosses\u002Ffunctions.jl\"},\"references\u002FFastAI.Datasets.AbstractDatasetRegistry\":{\"tag\":\"documentation\",\"title\":\"AbstractDatasetRegistry\"},\"references\u002FFastAI.Tabular.RECIPES\":{\"tag\":\"documentation\",\"title\":\"RECIPES\"},\"references\u002FFlux.Optimise.AdaMax\":{\"tag\":\"documentation\",\"title\":\"AdaMax\"},\"references\u002FFastAI.decodey!\":{\"tag\":\"documentation\",\"title\":\"decodey!\"},\"references\u002FFluxTraining.CheckIteratesTuples\":{\"tag\":\"documentation\",\"title\":\"CheckIteratesTuples\"},\"references\u002FFastAI.Vision.Models.pixelshufflehead\":{\"tag\":\"documentation\",\"title\":\"pixelshufflehead\"},\"references\u002FFlux.zeros32\":{\"tag\":\"documentation\",\"title\":\"zeros32\"},\"references\u002FFlux.Losses.siamese_contrastive_loss\":{\"tag\":\"documentation\",\"title\":\"siamese_contrastive_loss\"},\"references\u002FFlux.flip\":{\"tag\":\"documentation\",\"title\":\"flip\"},\"references\u002FFastAI.Datasets.pathparent\":{\"tag\":\"documentation\",\"title\":\"pathparent\"},\"references\u002FFluxTraining.sethyperparameter!\":{\"tag\":\"documentation\",\"title\":\"sethyperparameter!\"},\"references\u002FFastAI.Datasets.recipeblocks\":{\"tag\":\"documentation\",\"title\":\"recipeblocks\"},\"references\u002FFastAI.encodesample\":{\"tag\":\"documentation\",\"title\":\"encodesample\"},\"references\u002FFastAI.Datasets.RE_TEXTFILE\":{\"tag\":\"documentation\",\"title\":\"RE_TEXTFILE\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002FTabular\u002Fmodels.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002FTabular\u002Fmodels.jl\"},\"references\u002FFastAI.Vision.ImagePreprocessing\":{\"tag\":\"documentation\",\"title\":\"ImagePreprocessing\"},\"references\u002FFluxTraining.testlearner\":{\"tag\":\"documentation\",\"title\":\"testlearner\"},\"references\u002FFastAI.Datasets.loadrecipe\":{\"tag\":\"documentation\",\"title\":\"loadrecipe\"},\"references\u002FFastAI.Tabular.TabularRegression\":{\"tag\":\"documentation\",\"title\":\"TabularRegression\"},\"references\u002FFlux.Losses.logaddexp\":{\"tag\":\"documentation\",\"title\":\"logaddexp\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002FVision\u002Fblocks\u002Fbounded.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002FVision\u002Fblocks\u002Fbounded.jl\"},\"references\u002FFlux.InstanceNorm\":{\"tag\":\"documentation\",\"title\":\"InstanceNorm\"},\"references\u002FFluxTraining.epoch!\":{\"tag\":\"documentation\",\"title\":\"epoch!\"},\"references\u002FFastAI.Vision.Models.visionhead\":{\"tag\":\"documentation\",\"title\":\"visionhead\"},\"sourcefiles\u002FDataAugmentation\u002Fsrc\u002Fprojective\u002Faffine.jl\":{\"tag\":\"sourcefile\",\"title\":\"DataAugmentation\u002Fsrc\u002Fprojective\u002Faffine.jl\"},\"references\u002FFluxTraining.setcallbacks!\":{\"tag\":\"documentation\",\"title\":\"setcallbacks!\"},\"references\u002FFlux.activations\":{\"tag\":\"documentation\",\"title\":\"activations\"},\"references\u002FDataAugmentation.imagetotensor\":{\"tag\":\"documentation\",\"title\":\"imagetotensor\"},\"references\u002FFluxTraining.Unresolvable\":{\"tag\":\"documentation\",\"title\":\"Unresolvable\"},\"references\u002FFastAI.Datasets.pathname\":{\"tag\":\"documentation\",\"title\":\"pathname\"},\"references\u002FDataAugmentation.RandomResizeCrop\":{\"tag\":\"documentation\",\"title\":\"RandomResizeCrop\"},\"references\u002FFlux.rng_from_array\":{\"tag\":\"documentation\",\"title\":\"rng_from_array\"},\"references\u002FFluxTraining.testbatches\":{\"tag\":\"documentation\",\"title\":\"testbatches\"},\"references\u002FFastAI.Vision.ImageClassificationSingle\":{\"tag\":\"documentation\",\"title\":\"ImageClassificationSingle\"},\"references\u002FFastAI.Many\":{\"tag\":\"documentation\",\"title\":\"Many\"},\"references\u002FFluxTraining.Phases.AbstractValidationPhase\":{\"tag\":\"documentation\",\"title\":\"AbstractValidationPhase\"},\"references\u002FFastAI.Textual.replace_sentence_case\":{\"tag\":\"documentation\",\"title\":\"replace_sentence_case\"},\"references\u002FFlux.randn32\":{\"tag\":\"documentation\",\"title\":\"randn32\"},\"references\u002FFluxTraining.NotDefined\":{\"tag\":\"documentation\",\"title\":\"NotDefined\"},\"references\u002FFluxTraining.findconflicts\":{\"tag\":\"documentation\",\"title\":\"findconflicts\"},\"references\u002FFluxTraining.Loggables.Text\":{\"tag\":\"documentation\",\"title\":\"Text\"},\"references\u002FFastAI.Vision.Bounded\":{\"tag\":\"documentation\",\"title\":\"Bounded\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002Finterpretation\u002Ftext.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002Finterpretation\u002Ftext.jl\"},\"references\u002FFlux.underscorise\":{\"tag\":\"documentation\",\"title\":\"underscorise\"},\"references\u002FDataAugmentation.AbstractArrayItem\":{\"tag\":\"documentation\",\"title\":\"AbstractArrayItem\"},\"sourcefiles\u002FFlux\u002Fsrc\u002Flayers\u002Fconv.jl\":{\"tag\":\"sourcefile\",\"title\":\"Flux\u002Fsrc\u002Flayers\u002Fconv.jl\"},\"references\u002FDataAugmentation.NormalizeIntensity\":{\"tag\":\"documentation\",\"title\":\"NormalizeIntensity\"},\"references\u002FFlux._all\":{\"tag\":\"documentation\",\"title\":\"_all\"},\"references\u002FDataAugmentation.ArrayItem\":{\"tag\":\"documentation\",\"title\":\"ArrayItem\"},\"references\u002FFastAI.Datasets.DESCRIPTIONS\":{\"tag\":\"documentation\",\"title\":\"DESCRIPTIONS\"},\"references\u002FFlux._show_children\":{\"tag\":\"documentation\",\"title\":\"_show_children\"},\"references\u002FFastAI.lrfind\":{\"tag\":\"documentation\",\"title\":\"lrfind\"},\"references\u002FDataAugmentation\":{\"tag\":\"documentation\",\"title\":\"DataAugmentation\"},\"references\u002FDataAugmentation.WarpAffine\":{\"tag\":\"documentation\",\"title\":\"WarpAffine\"},\"references\u002FFastAI.##InlineTest-01b48f5c342f65df7fcd07f28f0d2cacbb09f0a0.__init__\":{\"tag\":\"documentation\",\"title\":\"__init__\"},\"references\u002FFluxTraining.runstep\":{\"tag\":\"documentation\",\"title\":\"runstep\"},\"references\u002FFastAI.##InlineTest-01b48f5c342f65df7fcd07f28f0d2cacbb09f0a0.tests\":{\"tag\":\"documentation\",\"title\":\"tests\"},\"documents\u002Fdocs\u002Flearning_methods.md\":{\"tag\":\"document\",\"title\":\"Custom learning tasks\"},\"references\u002FDataAugmentation.makebuffer\":{\"tag\":\"documentation\",\"title\":\"makebuffer\"},\"sourcefiles\u002FFlux\u002Fsrc\u002Fcuda\u002Fcudnn.jl\":{\"tag\":\"sourcefile\",\"title\":\"Flux\u002Fsrc\u002Fcuda\u002Fcudnn.jl\"},\"references\u002FFlux.reset!\":{\"tag\":\"documentation\",\"title\":\"reset!\"},\"references\u002FFastAI.Datasets.DatasetRecipe\":{\"tag\":\"documentation\",\"title\":\"DatasetRecipe\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002Fdatablock\u002Fblock.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002Fdatablock\u002Fblock.jl\"},\"references\u002FFlux.Zeros\":{\"tag\":\"documentation\",\"title\":\"Zeros\"},\"references\u002FFlux.throttle\":{\"tag\":\"documentation\",\"title\":\"throttle\"},\"references\u002FFastAI.Datasets.MappedData\":{\"tag\":\"documentation\",\"title\":\"MappedData\"},\"references\u002FFluxTraining.reset!\":{\"tag\":\"documentation\",\"title\":\"reset!\"},\"references\u002FFastAI.Datasets.loadfile\":{\"tag\":\"documentation\",\"title\":\"loadfile\"},\"references\u002FFastAI.decodedblock\":{\"tag\":\"documentation\",\"title\":\"decodedblock\"},\"references\u002FFastAI.decodeŷ!\":{\"tag\":\"documentation\",\"title\":\"decodeŷ!\"},\"references\u002FFastAI.Vision.Image\":{\"tag\":\"documentation\",\"title\":\"Image\"},\"references\u002FFastAI.mocksample\":{\"tag\":\"documentation\",\"title\":\"mocksample\"},\"references\u002FDataAugmentation.Buffered\":{\"tag\":\"documentation\",\"title\":\"Buffered\"},\"references\u002FFastAI._encode\":{\"tag\":\"documentation\",\"title\":\"_encode\"},\"sourcefiles\u002FDataAugmentation\u002Fsrc\u002Fwrapper.jl\":{\"tag\":\"sourcefile\",\"title\":\"DataAugmentation\u002Fsrc\u002Fwrapper.jl\"},\"references\u002FFastAI.Textual.##InlineTest-01b48f5c342f65df7fcd07f28f0d2cacbb09f0a0.TESTSET_MACROS\":{\"tag\":\"documentation\",\"title\":\"TESTSET_MACROS\"},\"references\u002FFastAI.describeencodings\":{\"tag\":\"documentation\",\"title\":\"describeencodings\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002FVision\u002Ftests.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002FVision\u002Ftests.jl\"},\"references\u002FFlux.RNNCell\":{\"tag\":\"documentation\",\"title\":\"RNNCell\"},\"references\u002FFastAI.Datasets.RE_IMAGEFILE\":{\"tag\":\"documentation\",\"title\":\"RE_IMAGEFILE\"},\"references\u002FFluxTraining.Loggables.File\":{\"tag\":\"documentation\",\"title\":\"File\"},\"references\u002FFastAI.Vision.colorchannels\":{\"tag\":\"documentation\",\"title\":\"colorchannels\"},\"references\u002FFlux.Losses.ctc_loss\":{\"tag\":\"documentation\",\"title\":\"ctc_loss\"},\"references\u002FFastAI.Datasets.TableDataset\":{\"tag\":\"documentation\",\"title\":\"TableDataset\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002Ffasterai\u002Fdefaults.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002Ffasterai\u002Fdefaults.jl\"},\"references\u002FFastAI.Datasets.testrecipe\":{\"tag\":\"documentation\",\"title\":\"testrecipe\"},\"references\u002FFluxTraining.log_parameters\":{\"tag\":\"documentation\",\"title\":\"log_parameters\"},\"references\u002FFluxTraining.model!\":{\"tag\":\"documentation\",\"title\":\"model!\"},\"references\u002FFluxTraining.CallbackCondition\":{\"tag\":\"documentation\",\"title\":\"CallbackCondition\"},\"references\u002FFlux._dropout_shape\":{\"tag\":\"documentation\",\"title\":\"_dropout_shape\"},\"references\u002FDataAugmentation.Transform\":{\"tag\":\"documentation\",\"title\":\"Transform\"},\"references\u002FFlux.kaiming_uniform\":{\"tag\":\"documentation\",\"title\":\"kaiming_uniform\"},\"references\u002FFlux.MaxPool\":{\"tag\":\"documentation\",\"title\":\"MaxPool\"},\"references\u002FFlux.Optimise.batchmemaybe\":{\"tag\":\"documentation\",\"title\":\"batchmemaybe\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002FVision\u002Fmodels\u002FModels.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002FVision\u002Fmodels\u002FModels.jl\"},\"references\u002FFlux.Optimise.AbstractOptimiser\":{\"tag\":\"documentation\",\"title\":\"AbstractOptimiser\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002Ftraining\u002Fonecycle.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002Ftraining\u002Fonecycle.jl\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002FVision\u002Ftasks\u002Futils.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002FVision\u002Ftasks\u002Futils.jl\"},\"references\u002FFlux.cpu\":{\"tag\":\"documentation\",\"title\":\"cpu\"},\"references\u002FFlux.Conv\":{\"tag\":\"documentation\",\"title\":\"Conv\"},\"references\u002FFastAI.estimatelr\":{\"tag\":\"documentation\",\"title\":\"estimatelr\"},\"references\u002FFluxTraining.SafeCallback\":{\"tag\":\"documentation\",\"title\":\"SafeCallback\"},\"references\u002FFastAI.assigngroups!\":{\"tag\":\"documentation\",\"title\":\"assigngroups!\"},\"references\u002FDataAugmentation.CenterCrop\":{\"tag\":\"documentation\",\"title\":\"CenterCrop\"},\"sourcefiles\u002FFlux\u002Fsrc\u002Flosses\u002Fctc.jl\":{\"tag\":\"sourcefile\",\"title\":\"Flux\u002Fsrc\u002Flosses\u002Fctc.jl\"},\"documents\u002Fdocs\u002Fsetup.md\":{\"tag\":\"document\",\"title\":\"Setup\"},\"references\u002FFastAI.Vision.getimagepreprocessing\":{\"tag\":\"documentation\",\"title\":\"getimagepreprocessing\"},\"references\u002FFlux.BatchNorm\":{\"tag\":\"documentation\",\"title\":\"BatchNorm\"},\"references\u002FFlux.DepthwiseConv\":{\"tag\":\"documentation\",\"title\":\"DepthwiseConv\"},\"references\u002FFluxTraining.TestModel\":{\"tag\":\"documentation\",\"title\":\"TestModel\"},\"references\u002FFastAI.Tabular.TabularPreprocessing\":{\"tag\":\"documentation\",\"title\":\"TabularPreprocessing\"},\"references\u002FFastAI.StatefulEncoding\":{\"tag\":\"documentation\",\"title\":\"StatefulEncoding\"},\"references\u002FDataAugmentation.FillMissing\":{\"tag\":\"documentation\",\"title\":\"FillMissing\"},\"references\u002FFluxTraining.HyperParameter\":{\"tag\":\"documentation\",\"title\":\"HyperParameter\"},\"references\u002FFluxTraining.savemodel\":{\"tag\":\"documentation\",\"title\":\"savemodel\"},\"references\u002FDataAugmentation.Polygon\":{\"tag\":\"documentation\",\"title\":\"Polygon\"},\"references\u002FDataAugmentation.threepointwarpaffine\":{\"tag\":\"documentation\",\"title\":\"threepointwarpaffine\"},\"references\u002FFluxTraining.CancelStepException\":{\"tag\":\"documentation\",\"title\":\"CancelStepException\"},\"references\u002FDataAugmentation.Normalize\":{\"tag\":\"documentation\",\"title\":\"Normalize\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002Fencodings\u002Fonehot.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002Fencodings\u002Fonehot.jl\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002FVision\u002Ftasks\u002Fclassification.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002FVision\u002Ftasks\u002Fclassification.jl\"},\"references\u002FFastAI.decodey\":{\"tag\":\"documentation\",\"title\":\"decodey\"},\"sourcefiles\u002FFluxTraining\u002Fsrc\u002Fcallbacks\u002Fmetrics.jl\":{\"tag\":\"sourcefile\",\"title\":\"FluxTraining\u002Fsrc\u002Fcallbacks\u002Fmetrics.jl\"},\"references\u002FFastAI.Vision._registerrecipes\":{\"tag\":\"documentation\",\"title\":\"_registerrecipes\"},\"references\u002FFlux.PixelShuffle\":{\"tag\":\"documentation\",\"title\":\"PixelShuffle\"},\"references\u002FDataAugmentation.FromOrigin\":{\"tag\":\"documentation\",\"title\":\"FromOrigin\"},\"documents\u002Fdocs\u002Finterfaces.md\":{\"tag\":\"document\",\"title\":\"Interfaces\"},\"references\u002FFastAI.Tabular.##InlineTest-01b48f5c342f65df7fcd07f28f0d2cacbb09f0a0.tests\":{\"tag\":\"documentation\",\"title\":\"tests\"},\"references\u002FFlux.Embedding\":{\"tag\":\"documentation\",\"title\":\"Embedding\"},\"references\u002FFastAI.Tabular.sigmoidrange\":{\"tag\":\"documentation\",\"title\":\"sigmoidrange\"},\"references\u002FFastAI.Datasets.DATASETS_IMAGECLASSIFICATION\":{\"tag\":\"documentation\",\"title\":\"DATASETS_IMAGECLASSIFICATION\"},\"references\u002FFastAI.LearningTaskRegistry\":{\"tag\":\"documentation\",\"title\":\"LearningTaskRegistry\"},\"references\u002FFastAI.encodesample!\":{\"tag\":\"documentation\",\"title\":\"encodesample!\"},\"references\u002FFlux._paddims\":{\"tag\":\"documentation\",\"title\":\"_paddims\"},\"references\u002FFastAI.Datasets.datasetpath\":{\"tag\":\"documentation\",\"title\":\"datasetpath\"},\"references\u002FFluxTraining.Events.StepBegin\":{\"tag\":\"documentation\",\"title\":\"StepBegin\"},\"references\u002FFastAI.Textual.runtests\":{\"tag\":\"documentation\",\"title\":\"runtests\"},\"references\u002FFluxTraining.AbstractMetric\":{\"tag\":\"documentation\",\"title\":\"AbstractMetric\"},\"references\u002FFastAI.Vision.KeypointPreprocessing\":{\"tag\":\"documentation\",\"title\":\"KeypointPreprocessing\"},\"references\u002FFastAI.Tabular.tabular_continuous_backbone\":{\"tag\":\"documentation\",\"title\":\"tabular_continuous_backbone\"},\"references\u002FFlux.Optimise.NADAM\":{\"tag\":\"documentation\",\"title\":\"NADAM\"},\"references\u002FDataAugmentation.showgrid\":{\"tag\":\"documentation\",\"title\":\"showgrid\"},\"references\u002FFluxTraining.@pack_History\":{\"tag\":\"documentation\",\"title\":\"@pack_History\"},\"references\u002FDataAugmentation.project\":{\"tag\":\"documentation\",\"title\":\"project\"},\"references\u002FFastAI.Datasets.joinobs\":{\"tag\":\"documentation\",\"title\":\"joinobs\"},\"references\u002FFluxTraining.formataccess\":{\"tag\":\"documentation\",\"title\":\"formataccess\"},\"sourcefiles\u002FDataAugmentation\u002Fsrc\u002Fitems\u002Fkeypoints.jl\":{\"tag\":\"sourcefile\",\"title\":\"DataAugmentation\u002Fsrc\u002Fitems\u002Fkeypoints.jl\"},\"references\u002FFastAI.tasklossfn\":{\"tag\":\"documentation\",\"title\":\"tasklossfn\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002FVision\u002Ftasks\u002Fkeypointregression.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002FVision\u002Ftasks\u002Fkeypointregression.jl\"},\"references\u002FFluxTraining.Loggables\":{\"tag\":\"documentation\",\"title\":\"Loggables\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002Fdatablock\u002Fmodels.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002Fdatablock\u002Fmodels.jl\"},\"references\u002FFastAI.Vision.Models.UNetBlock\":{\"tag\":\"documentation\",\"title\":\"UNetBlock\"},\"sourcefiles\u002FFlux\u002Fsrc\u002Flayers\u002Fstateless.jl\":{\"tag\":\"sourcefile\",\"title\":\"Flux\u002Fsrc\u002Flayers\u002Fstateless.jl\"},\"references\u002FFlux.Losses.dice_coeff_loss\":{\"tag\":\"documentation\",\"title\":\"dice_coeff_loss\"},\"references\u002FFastAI.Vision.Models.UNetMiddleBlock\":{\"tag\":\"documentation\",\"title\":\"UNetMiddleBlock\"},\"references\u002FFlux.Optimise.ClipValue\":{\"tag\":\"documentation\",\"title\":\"ClipValue\"},\"references\u002FDataAugmentation.BoundingBox\":{\"tag\":\"documentation\",\"title\":\"BoundingBox\"},\"references\u002FDataAugmentation.AbstractItem\":{\"tag\":\"documentation\",\"title\":\"AbstractItem\"},\"references\u002FFlux.Losses.focal_loss\":{\"tag\":\"documentation\",\"title\":\"focal_loss\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002Fdatasets\u002Ffastaidatasets.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002Fdatasets\u002Ffastaidatasets.jl\"},\"references\u002FFlux.Optimise.call\":{\"tag\":\"documentation\",\"title\":\"call\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002Ftasks\u002Ftaskdata.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002Ftasks\u002Ftaskdata.jl\"},\"references\u002FDataAugmentation.FromRandom\":{\"tag\":\"documentation\",\"title\":\"FromRandom\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002Fdatablock\u002Ftask.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002Fdatablock\u002Ftask.jl\"},\"references\u002FFlux.SkipConnection\":{\"tag\":\"documentation\",\"title\":\"SkipConnection\"},\"references\u002FFastAI.Vision.Models.conv_final\":{\"tag\":\"documentation\",\"title\":\"conv_final\"},\"references\u002FFastAI.##InlineTest-01b48f5c342f65df7fcd07f28f0d2cacbb09f0a0.TESTSET_MACROS\":{\"tag\":\"documentation\",\"title\":\"TESTSET_MACROS\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002FVision\u002Fblocks\u002Fmask.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002FVision\u002Fblocks\u002Fmask.jl\"},\"references\u002FFluxTraining.CustomCallback\":{\"tag\":\"documentation\",\"title\":\"CustomCallback\"},\"references\u002FDataAugmentation.onehot\":{\"tag\":\"documentation\",\"title\":\"onehot\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002Fdatablock\u002Floss.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002Fdatablock\u002Floss.jl\"},\"documents\u002Fdocs\u002Fintroduction.md\":{\"tag\":\"document\",\"title\":\"Introduction\"},\"references\u002FFlux.Optimise.Nesterov\":{\"tag\":\"documentation\",\"title\":\"Nesterov\"},\"references\u002FDataAugmentation.ProjectiveTransform\":{\"tag\":\"documentation\",\"title\":\"ProjectiveTransform\"},\"references\u002FFastAI.showblock\":{\"tag\":\"documentation\",\"title\":\"showblock\"},\"references\u002FFlux.orthogonal\":{\"tag\":\"documentation\",\"title\":\"orthogonal\"},\"references\u002FFastAI.Tabular.TableDatasetRecipe\":{\"tag\":\"documentation\",\"title\":\"TableDatasetRecipe\"},\"references\u002FFlux.glorot_normal\":{\"tag\":\"documentation\",\"title\":\"glorot_normal\"},\"references\u002FDataAugmentation.allequal\":{\"tag\":\"documentation\",\"title\":\"allequal\"},\"references\u002FFlux.epseltype\":{\"tag\":\"documentation\",\"title\":\"epseltype\"},\"references\u002FFlux.Optimise.@epochs\":{\"tag\":\"documentation\",\"title\":\"@epochs\"},\"references\u002FFastAI.Vision.Models.make_layer\":{\"tag\":\"documentation\",\"title\":\"make_layer\"},\"references\u002FFlux._show_layers\":{\"tag\":\"documentation\",\"title\":\"_show_layers\"},\"references\u002FDataAugmentation.Maybe\":{\"tag\":\"documentation\",\"title\":\"Maybe\"},\"references\u002FFastAI.savemethodmodel\":{\"tag\":\"documentation\",\"title\":\"savemethodmodel\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002FVision\u002Fmodels.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002FVision\u002Fmodels.jl\"},\"references\u002FFastAI.encodingscolumn\":{\"tag\":\"documentation\",\"title\":\"encodingscolumn\"},\"references\u002FFlux.onehotbatch\":{\"tag\":\"documentation\",\"title\":\"onehotbatch\"},\"references\u002FFlux.OneHotVector\":{\"tag\":\"documentation\",\"title\":\"OneHotVector\"},\"sourcefiles\u002FFlux\u002Fsrc\u002Fdeprecations.jl\":{\"tag\":\"sourcefile\",\"title\":\"Flux\u002Fsrc\u002Fdeprecations.jl\"},\"references\u002FFlux.extraChain\":{\"tag\":\"documentation\",\"title\":\"extraChain\"},\"references\u002FDataAugmentation.Identity\":{\"tag\":\"documentation\",\"title\":\"Identity\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002Ftraining\u002Flrfind.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002Ftraining\u002Flrfind.jl\"},\"references\u002FFlux.hasaffine\":{\"tag\":\"documentation\",\"title\":\"hasaffine\"},\"references\u002FFastAI.blockbackbone\":{\"tag\":\"documentation\",\"title\":\"blockbackbone\"},\"references\u002FFastAI.Vision.Models.iterlayers\":{\"tag\":\"documentation\",\"title\":\"iterlayers\"},\"references\u002FFastAI.Textual.convert_lowercase\":{\"tag\":\"documentation\",\"title\":\"convert_lowercase\"},\"references\u002FFastAI.ShowBackend\":{\"tag\":\"documentation\",\"title\":\"ShowBackend\"},\"references\u002FFlux.Losses.binary_focal_loss\":{\"tag\":\"documentation\",\"title\":\"binary_focal_loss\"},\"references\u002FFlux.paramtype\":{\"tag\":\"documentation\",\"title\":\"paramtype\"},\"references\u002FFastAI.Vision.ImageSegmentation\":{\"tag\":\"documentation\",\"title\":\"ImageSegmentation\"},\"references\u002FFlux.LSTM\":{\"tag\":\"documentation\",\"title\":\"LSTM\"},\"references\u002FFastAI.showprediction\":{\"tag\":\"documentation\",\"title\":\"showprediction\"},\"references\u002FFastAI.Vision.Models.UNetCombineLayer\":{\"tag\":\"documentation\",\"title\":\"UNetCombineLayer\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002FVision\u002Fblocks\u002Fimage.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002FVision\u002Fblocks\u002Fimage.jl\"},\"sourcefiles\u002FDataAugmentation\u002Fsrc\u002Fprojective\u002Fwarp.jl\":{\"tag\":\"sourcefile\",\"title\":\"DataAugmentation\u002Fsrc\u002Fprojective\u002Fwarp.jl\"},\"references\u002FFastAI.Vision.Models.PixelShuffleICNR\":{\"tag\":\"documentation\",\"title\":\"PixelShuffleICNR\"},\"references\u002FFlux._print_conv_opt\":{\"tag\":\"documentation\",\"title\":\"_print_conv_opt\"},\"sourcefiles\u002FDataAugmentation\u002Fsrc\u002Fvisualization.jl\":{\"tag\":\"sourcefile\",\"title\":\"DataAugmentation\u002Fsrc\u002Fvisualization.jl\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002FTextual\u002Frecipes.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002FTextual\u002Frecipes.jl\"},\"documents\u002Fdocs\u002Fdiscovery.md\":{\"tag\":\"document\",\"title\":\"Discovery\"},\"references\u002FFluxTraining.runtests\":{\"tag\":\"documentation\",\"title\":\"runtests\"},\"references\u002FDataAugmentation.getbounds\":{\"tag\":\"documentation\",\"title\":\"getbounds\"},\"references\u002FFlux.patience\":{\"tag\":\"documentation\",\"title\":\"patience\"},\"references\u002FFlux.zeros\":{\"tag\":\"documentation\",\"title\":\"zeros\"},\"references\u002FFastAI.IndexGrouper\":{\"tag\":\"documentation\",\"title\":\"IndexGrouper\"},\"references\u002FFastAI.taskdataset\":{\"tag\":\"documentation\",\"title\":\"taskdataset\"},\"references\u002FDataAugmentation.project!\":{\"tag\":\"documentation\",\"title\":\"project!\"},\"references\u002FFlux.expand\":{\"tag\":\"documentation\",\"title\":\"expand\"},\"references\u002FFlux.Losses.kldivergence\":{\"tag\":\"documentation\",\"title\":\"kldivergence\"},\"references\u002FFlux.AdaptiveMeanPool\":{\"tag\":\"documentation\",\"title\":\"AdaptiveMeanPool\"},\"references\u002FFastAI.ParamGrouper\":{\"tag\":\"documentation\",\"title\":\"ParamGrouper\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002Fdatasets\u002Ftransformations.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002Fdatasets\u002Ftransformations.jl\"},\"references\u002FFlux.Optimise.WeightDecay\":{\"tag\":\"documentation\",\"title\":\"WeightDecay\"},\"references\u002FFluxTraining.ES\":{\"tag\":\"documentation\",\"title\":\"ES\"},\"references\u002FFluxTraining.runafter\":{\"tag\":\"documentation\",\"title\":\"runafter\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002Fdatablock\u002Fdescribe.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002Fdatablock\u002Fdescribe.jl\"},\"references\u002FFluxTraining.MetricsPrinter\":{\"tag\":\"documentation\",\"title\":\"MetricsPrinter\"},\"references\u002FFastAI.Vision.Models.UNetFinalBlock\":{\"tag\":\"documentation\",\"title\":\"UNetFinalBlock\"},\"references\u002FFluxTraining.ConditionalCallback\":{\"tag\":\"documentation\",\"title\":\"ConditionalCallback\"},\"references\u002FFastAI.Vision.Models\":{\"tag\":\"documentation\",\"title\":\"Models\"},\"references\u002FFlux.Optimise.RMSProp\":{\"tag\":\"documentation\",\"title\":\"RMSProp\"},\"references\u002FFlux.istraining\":{\"tag\":\"documentation\",\"title\":\"istraining\"},\"references\u002FDataAugmentation.mask_extrapolation\":{\"tag\":\"documentation\",\"title\":\"mask_extrapolation\"},\"references\u002FDataAugmentation.transformbounds\":{\"tag\":\"documentation\",\"title\":\"transformbounds\"},\"references\u002FFlux.Scale\":{\"tag\":\"documentation\",\"title\":\"Scale\"},\"references\u002FFastAI.methodmodel\":{\"tag\":\"documentation\",\"title\":\"methodmodel\"},\"references\u002FFastAI.Tabular.gettransforms\":{\"tag\":\"documentation\",\"title\":\"gettransforms\"},\"references\u002FFastAI.PropagateNever\":{\"tag\":\"documentation\",\"title\":\"PropagateNever\"},\"references\u002FFastAI.Datasets.grandparentname\":{\"tag\":\"documentation\",\"title\":\"grandparentname\"},\"references\u002FDataAugmentation.ScaleRatio\":{\"tag\":\"documentation\",\"title\":\"ScaleRatio\"},\"references\u002FFastAI.finetune!\":{\"tag\":\"documentation\",\"title\":\"finetune!\"},\"references\u002FFastAI.Textual._registerrecipes\":{\"tag\":\"documentation\",\"title\":\"_registerrecipes\"},\"references\u002FFastAI.Context\":{\"tag\":\"documentation\",\"title\":\"Context\"},\"references\u002FDataAugmentation.ComposedProjectiveTransform\":{\"tag\":\"documentation\",\"title\":\"ComposedProjectiveTransform\"},\"references\u002FDataAugmentation.showbounds!\":{\"tag\":\"documentation\",\"title\":\"showbounds!\"},\"references\u002FFluxTraining.EarlyStopping\":{\"tag\":\"documentation\",\"title\":\"EarlyStopping\"},\"documents\u002Fnotebooks\u002Fimagesegmentation.ipynb\":{\"tag\":\"document\",\"title\":\"Image segmentation\"},\"references\u002FDataAugmentation.setwrapped\":{\"tag\":\"documentation\",\"title\":\"setwrapped\"},\"references\u002FFluxTraining.Write\":{\"tag\":\"documentation\",\"title\":\"Write\"},\"references\u002FFluxTraining.callbackgraph\":{\"tag\":\"documentation\",\"title\":\"callbackgraph\"},\"references\u002FDataAugmentation.PinOrigin\":{\"tag\":\"documentation\",\"title\":\"PinOrigin\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002Fdatasets\u002FDatasets.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002Fdatasets\u002FDatasets.jl\"},\"references\u002FFastAI.Textual.##InlineTest-01b48f5c342f65df7fcd07f28f0d2cacbb09f0a0.tests\":{\"tag\":\"documentation\",\"title\":\"tests\"},\"references\u002FFluxTraining.TensorBoardBackend\":{\"tag\":\"documentation\",\"title\":\"TensorBoardBackend\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002FVision\u002Fencodings\u002Fonehot.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002FVision\u002Fencodings\u002Fonehot.jl\"},\"references\u002FFluxTraining.garbagecollect\":{\"tag\":\"documentation\",\"title\":\"garbagecollect\"},\"references\u002FFastAI.Vision.KeypointTensor\":{\"tag\":\"documentation\",\"title\":\"KeypointTensor\"},\"references\u002FDataAugmentation.Categorify\":{\"tag\":\"documentation\",\"title\":\"Categorify\"},\"references\u002FDataAugmentation.scaleprojection\":{\"tag\":\"documentation\",\"title\":\"scaleprojection\"},\"sourcefiles\u002FFlux\u002Fsrc\u002Fdata\u002FData.jl\":{\"tag\":\"sourcefile\",\"title\":\"Flux\u002Fsrc\u002Fdata\u002FData.jl\"},\"references\u002FFlux.Optimise.StopException\":{\"tag\":\"documentation\",\"title\":\"StopException\"},\"references\u002FFastAI.Vision._gettfm\":{\"tag\":\"documentation\",\"title\":\"_gettfm\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002Fserialization.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002Fserialization.jl\"},\"references\u002FDataAugmentation.showbounds\":{\"tag\":\"documentation\",\"title\":\"showbounds\"},\"references\u002FDataAugmentation.Keypoints\":{\"tag\":\"documentation\",\"title\":\"Keypoints\"},\"references\u002FFastAI.showoutputs\":{\"tag\":\"documentation\",\"title\":\"showoutputs\"},\"references\u002FFlux.GRUv3Cell\":{\"tag\":\"documentation\",\"title\":\"GRUv3Cell\"},\"references\u002FFastAI.checktask_core\":{\"tag\":\"documentation\",\"title\":\"checktask_core\"},\"references\u002FFastAI.Vision.Models.##InlineTest-01b48f5c342f65df7fcd07f28f0d2cacbb09f0a0.TESTSET_MACROS\":{\"tag\":\"documentation\",\"title\":\"TESTSET_MACROS\"},\"references\u002FFastAI.BlockTask\":{\"tag\":\"documentation\",\"title\":\"BlockTask\"},\"references\u002FFastAI.Vision.Models.xresnet18\":{\"tag\":\"documentation\",\"title\":\"xresnet18\"},\"references\u002FFlux.Losses.add_blanks\":{\"tag\":\"documentation\",\"title\":\"add_blanks\"},\"references\u002FFluxTraining.Events.LossBegin\":{\"tag\":\"documentation\",\"title\":\"LossBegin\"},\"references\u002FFluxTraining.Recorder\":{\"tag\":\"documentation\",\"title\":\"Recorder\"},\"references\u002FFlux._isbitsarray\":{\"tag\":\"documentation\",\"title\":\"_isbitsarray\"},\"references\u002FFluxTraining.LogMetrics\":{\"tag\":\"documentation\",\"title\":\"LogMetrics\"},\"references\u002FDataAugmentation._round\":{\"tag\":\"documentation\",\"title\":\"_round\"},\"references\u002FFlux.Losses.xlogx\":{\"tag\":\"documentation\",\"title\":\"xlogx\"},\"references\u002FFlux.loadparams!\":{\"tag\":\"documentation\",\"title\":\"loadparams!\"},\"references\u002FFastAI.Textual.TextFolders\":{\"tag\":\"documentation\",\"title\":\"TextFolders\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002FVision\u002Fmodels\u002Flayers.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002FVision\u002Fmodels\u002Flayers.jl\"},\"sourcefiles\u002FFlux\u002Fsrc\u002Ffunctor.jl\":{\"tag\":\"sourcefile\",\"title\":\"Flux\u002Fsrc\u002Ffunctor.jl\"},\"sourcefiles\u002FFluxTraining\u002Fsrc\u002Ftestutils.jl\":{\"tag\":\"sourcefile\",\"title\":\"FluxTraining\u002Fsrc\u002Ftestutils.jl\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002FVision\u002Fblocks\u002Fkeypoints.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002FVision\u002Fblocks\u002Fkeypoints.jl\"},\"references\u002FFlux.create_bias\":{\"tag\":\"documentation\",\"title\":\"create_bias\"},\"references\u002FFlux.Losses.ctc_alpha\":{\"tag\":\"documentation\",\"title\":\"ctc_alpha\"},\"references\u002FDataAugmentation.MapElem\":{\"tag\":\"documentation\",\"title\":\"MapElem\"},\"references\u002FFlux.NilNumber.Nil\":{\"tag\":\"documentation\",\"title\":\"Nil\"},\"references\u002FFlux.Bilinear\":{\"tag\":\"documentation\",\"title\":\"Bilinear\"},\"references\u002FFastAI.findlearningmethods\":{\"tag\":\"documentation\",\"title\":\"findlearningmethods\"},\"references\u002FFluxTraining.CallbackRunner\":{\"tag\":\"documentation\",\"title\":\"CallbackRunner\"},\"references\u002FFastAI.methoddataloaders\":{\"tag\":\"documentation\",\"title\":\"methoddataloaders\"},\"references\u002FFastAI.Vision.##InlineTest-01b48f5c342f65df7fcd07f28f0d2cacbb09f0a0.__init__\":{\"tag\":\"documentation\",\"title\":\"__init__\"},\"references\u002FFastAI.Vision.ProjectiveTransforms\":{\"tag\":\"documentation\",\"title\":\"ProjectiveTransforms\"},\"sourcefiles\u002FFluxTraining\u002Fsrc\u002Flearner.jl\":{\"tag\":\"sourcefile\",\"title\":\"FluxTraining\u002Fsrc\u002Flearner.jl\"},\"references\u002FFluxTraining.Loss\":{\"tag\":\"documentation\",\"title\":\"Loss\"},\"references\u002FFluxTraining.runepoch\":{\"tag\":\"documentation\",\"title\":\"runepoch\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002Fblocks\u002Fmany.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002Fblocks\u002Fmany.jl\"},\"references\u002FFastAI.Encoding\":{\"tag\":\"documentation\",\"title\":\"Encoding\"},\"references\u002FDataAugmentation.FlipX\":{\"tag\":\"documentation\",\"title\":\"FlipX\"},\"references\u002FFastAI.predict\":{\"tag\":\"documentation\",\"title\":\"predict\"},\"references\u002FFastAI.lrfindtextplot\":{\"tag\":\"documentation\",\"title\":\"lrfindtextplot\"},\"references\u002FFastAI.Vision.Models.pixelshuffle\":{\"tag\":\"documentation\",\"title\":\"pixelshuffle\"},\"references\u002FFastAI.Vision.mockarray\":{\"tag\":\"documentation\",\"title\":\"mockarray\"},\"references\u002FFastAI.Vision._checksizedim\":{\"tag\":\"documentation\",\"title\":\"_checksizedim\"},\"references\u002FFlux.Optimise.SkipException\":{\"tag\":\"documentation\",\"title\":\"SkipException\"},\"sourcefiles\u002FFluxTraining\u002Fsrc\u002Fcallbacks\u002Fevents.jl\":{\"tag\":\"sourcefile\",\"title\":\"FluxTraining\u002Fsrc\u002Fcallbacks\u002Fevents.jl\"},\"documents\u002Fnotebooks\u002Fquickstart.ipynb\":{\"tag\":\"document\",\"title\":\"Quickstart\"},\"references\u002FFluxTraining.##InlineTest-01b48f5c342f65df7fcd07f28f0d2cacbb09f0a0.__init__\":{\"tag\":\"documentation\",\"title\":\"__init__\"},\"references\u002FFastAI.Datasets.istextfile\":{\"tag\":\"documentation\",\"title\":\"istextfile\"},\"references\u002FFlux._big_finale\":{\"tag\":\"documentation\",\"title\":\"_big_finale\"},\"sourcefiles\u002FDataAugmentation\u002Fsrc\u002Frowtransforms.jl\":{\"tag\":\"sourcefile\",\"title\":\"DataAugmentation\u002Fsrc\u002Frowtransforms.jl\"},\"references\u002FFlux.ones32\":{\"tag\":\"documentation\",\"title\":\"ones32\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002FVision\u002Fencodings\u002Fkeypointpreprocessing.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002FVision\u002Fencodings\u002Fkeypointpreprocessing.jl\"},\"sourcefiles\u002FDataAugmentation\u002Fsrc\u002Fitems\u002Farrayitem.jl\":{\"tag\":\"sourcefile\",\"title\":\"DataAugmentation\u002Fsrc\u002Fitems\u002Farrayitem.jl\"},\"references\u002FFlux.params!\":{\"tag\":\"documentation\",\"title\":\"params!\"},\"references\u002FDataAugmentation.Project\":{\"tag\":\"documentation\",\"title\":\"Project\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002FTabular\u002Fencodings\u002Ftabularpreprocessing.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002FTabular\u002Fencodings\u002Ftabularpreprocessing.jl\"},\"references\u002FFlux.Losses.crossentropy\":{\"tag\":\"documentation\",\"title\":\"crossentropy\"},\"references\u002FFastAI.Vision.imagestats\":{\"tag\":\"documentation\",\"title\":\"imagestats\"},\"references\u002FFastAI.OneHotTensor\":{\"tag\":\"documentation\",\"title\":\"OneHotTensor\"},\"references\u002FFastAI.describemethod\":{\"tag\":\"documentation\",\"title\":\"describemethod\"},\"references\u002FFluxTraining.loadmodel\":{\"tag\":\"documentation\",\"title\":\"loadmodel\"},\"references\u002FFlux.Losses.mse\":{\"tag\":\"documentation\",\"title\":\"mse\"},\"references\u002FFastAI.Datasets.registerrecipe!\":{\"tag\":\"documentation\",\"title\":\"registerrecipe!\"},\"references\u002FFlux.Optimise.ADAGrad\":{\"tag\":\"documentation\",\"title\":\"ADAGrad\"},\"references\u002FFastAI.TaskDataset\":{\"tag\":\"documentation\",\"title\":\"TaskDataset\"},\"sourcefiles\u002FFlux\u002Fsrc\u002Flosses\u002FLosses.jl\":{\"tag\":\"sourcefile\",\"title\":\"Flux\u002Fsrc\u002Flosses\u002FLosses.jl\"},\"references\u002FFastAI.discrlr_optimizer\":{\"tag\":\"documentation\",\"title\":\"discrlr_optimizer\"},\"references\u002FFlux._isonehot\":{\"tag\":\"documentation\",\"title\":\"_isonehot\"},\"references\u002FFlux.AlphaDropout\":{\"tag\":\"documentation\",\"title\":\"AlphaDropout\"},\"references\u002FFlux._channels_in\":{\"tag\":\"documentation\",\"title\":\"_channels_in\"},\"references\u002FDataAugmentation.CenterResizeCrop\":{\"tag\":\"documentation\",\"title\":\"CenterResizeCrop\"},\"references\u002FFastAI.accuracy_thresh\":{\"tag\":\"documentation\",\"title\":\"accuracy_thresh\"},\"references\u002FFluxTraining.step!\":{\"tag\":\"documentation\",\"title\":\"step!\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002Fencodings\u002Fonly.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002Fencodings\u002Fonly.jl\"},\"references\u002FFlux.normalise\":{\"tag\":\"documentation\",\"title\":\"normalise\"},\"sourcefiles\u002FFlux\u002Fsrc\u002Foutputsize.jl\":{\"tag\":\"sourcefile\",\"title\":\"Flux\u002Fsrc\u002Foutputsize.jl\"},\"references\u002FDataAugmentation._autorange\":{\"tag\":\"documentation\",\"title\":\"_autorange\"},\"references\u002FFlux._isleaf\":{\"tag\":\"documentation\",\"title\":\"_isleaf\"},\"references\u002FFlux.GlobalMeanPool\":{\"tag\":\"documentation\",\"title\":\"GlobalMeanPool\"},\"references\u002FFluxTraining.CheckDataIteratorValid\":{\"tag\":\"documentation\",\"title\":\"CheckDataIteratorValid\"},\"references\u002FFlux.OneHotArray\":{\"tag\":\"documentation\",\"title\":\"OneHotArray\"},\"sourcefiles\u002FFlux\u002Fsrc\u002Fonehot.jl\":{\"tag\":\"sourcefile\",\"title\":\"Flux\u002Fsrc\u002Fonehot.jl\"},\"references\u002FFlux.Optimise.runall\":{\"tag\":\"documentation\",\"title\":\"runall\"},\"references\u002FDataAugmentation.testprojective\":{\"tag\":\"documentation\",\"title\":\"testprojective\"},\"references\u002FFastAI.Vision.Models.UNetDynamic\":{\"tag\":\"documentation\",\"title\":\"UNetDynamic\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002Finterpretation\u002Fmakie\u002Fstub.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002Finterpretation\u002Fmakie\u002Fstub.jl\"},\"references\u002FDataAugmentation.ToEltype\":{\"tag\":\"documentation\",\"title\":\"ToEltype\"},\"documents\u002Fdeveloping.md\":{\"tag\":\"document\",\"title\":\"Development workflow\"},\"documents\u002FCHANGELOG.md\":{\"tag\":\"document\",\"title\":\"Changelog\"},\"references\u002FFlux._tie_check\":{\"tag\":\"documentation\",\"title\":\"_tie_check\"},\"references\u002FFastAI.Vision.checksize\":{\"tag\":\"documentation\",\"title\":\"checksize\"},\"references\u002FFastAI.BlockMethod\":{\"tag\":\"documentation\",\"title\":\"BlockMethod\"},\"references\u002FFlux.sparse_init\":{\"tag\":\"documentation\",\"title\":\"sparse_init\"},\"references\u002FFluxTraining.ConflictResolution\":{\"tag\":\"documentation\",\"title\":\"ConflictResolution\"},\"references\u002FFluxTraining.replacecallback!\":{\"tag\":\"documentation\",\"title\":\"replacecallback!\"},\"references\u002FFastAI.propagatewrapper\":{\"tag\":\"documentation\",\"title\":\"propagatewrapper\"},\"references\u002FFastAI.showblockinterpretable\":{\"tag\":\"documentation\",\"title\":\"showblockinterpretable\"},\"references\u002FDataAugmentation.showitems\":{\"tag\":\"documentation\",\"title\":\"showitems\"},\"references\u002FFastAI.showblocks!\":{\"tag\":\"documentation\",\"title\":\"showblocks!\"},\"references\u002FFluxTraining.##InlineTest-01b48f5c342f65df7fcd07f28f0d2cacbb09f0a0.tests\":{\"tag\":\"documentation\",\"title\":\"tests\"},\"references\u002FFastAI.Vision.blockitemtype\":{\"tag\":\"documentation\",\"title\":\"blockitemtype\"},\"sourcefiles\u002FDataAugmentation\u002Fsrc\u002Fsequence.jl\":{\"tag\":\"sourcefile\",\"title\":\"DataAugmentation\u002Fsrc\u002Fsequence.jl\"},\"references\u002FDataAugmentation.copyitemdata!\":{\"tag\":\"documentation\",\"title\":\"copyitemdata!\"},\"references\u002FFlux.Losses\":{\"tag\":\"documentation\",\"title\":\"Losses\"},\"documents\u002Fdocs\u002Fhowto\u002Flogtensorboard.md\":{\"tag\":\"document\",\"title\":\"How to log to TensorBoard\"},\"references\u002FFlux.gpu\":{\"tag\":\"documentation\",\"title\":\"gpu\"},\"references\u002FFluxTraining.log_to\":{\"tag\":\"documentation\",\"title\":\"log_to\"},\"documents\u002Fnotebooks\u002Fsiamese.ipynb\":{\"tag\":\"document\",\"title\":\"Siamese image similarity\"},\"references\u002FFlux.Recur\":{\"tag\":\"documentation\",\"title\":\"Recur\"},\"references\u002FFlux.dropout_mask\":{\"tag\":\"documentation\",\"title\":\"dropout_mask\"},\"references\u002FFluxTraining.getindexperm\":{\"tag\":\"documentation\",\"title\":\"getindexperm\"},\"references\u002FFlux._layer_show\":{\"tag\":\"documentation\",\"title\":\"_layer_show\"},\"references\u002FFluxTraining.Callback\":{\"tag\":\"documentation\",\"title\":\"Callback\"},\"references\u002FFastAI.Datasets.runtests\":{\"tag\":\"documentation\",\"title\":\"runtests\"},\"references\u002FFastAI.Vision.Models.ResBlock\":{\"tag\":\"documentation\",\"title\":\"ResBlock\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002FVision\u002Frecipes.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002FVision\u002Frecipes.jl\"},\"references\u002FFastAI.showpredictions\":{\"tag\":\"documentation\",\"title\":\"showpredictions\"},\"documents\u002Fnotebooks\u002Ftabularclassification.ipynb\":{\"tag\":\"document\",\"title\":\"Tabular Classification\"},\"references\u002FFlux._bool_tie_check\":{\"tag\":\"documentation\",\"title\":\"_bool_tie_check\"},\"references\u002FFastAI.decay_optim\":{\"tag\":\"documentation\",\"title\":\"decay_optim\"},\"documents\u002Fdocs\u002Ffastai_api_comparison.md\":{\"tag\":\"document\",\"title\":\"fastai API comparison\"},\"references\u002FFlux.ones\":{\"tag\":\"documentation\",\"title\":\"ones\"},\"references\u002FFlux.Losses.huber_loss\":{\"tag\":\"documentation\",\"title\":\"huber_loss\"},\"references\u002FFlux.LSTMCell\":{\"tag\":\"documentation\",\"title\":\"LSTMCell\"},\"references\u002FFluxTraining.protect\":{\"tag\":\"documentation\",\"title\":\"protect\"},\"references\u002FFlux.onehot\":{\"tag\":\"documentation\",\"title\":\"onehot\"},\"references\u002FFlux.Losses.label_smoothing\":{\"tag\":\"documentation\",\"title\":\"label_smoothing\"},\"references\u002FFlux.Dropout\":{\"tag\":\"documentation\",\"title\":\"Dropout\"},\"references\u002FFlux.MeanPool\":{\"tag\":\"documentation\",\"title\":\"MeanPool\"},\"references\u002FDataAugmentation.AdjustBrightness\":{\"tag\":\"documentation\",\"title\":\"AdjustBrightness\"},\"references\u002FFastAI.getgroup\":{\"tag\":\"documentation\",\"title\":\"getgroup\"},\"sourcefiles\u002FFluxTraining\u002Fsrc\u002Ftraining.jl\":{\"tag\":\"sourcefile\",\"title\":\"FluxTraining\u002Fsrc\u002Ftraining.jl\"},\"references\u002FDataAugmentation.ItemWrapper\":{\"tag\":\"documentation\",\"title\":\"ItemWrapper\"},\"references\u002FFastAI.methoddataset\":{\"tag\":\"documentation\",\"title\":\"methoddataset\"},\"references\u002FFlux.Losses.tversky_loss\":{\"tag\":\"documentation\",\"title\":\"tversky_loss\"},\"references\u002FFastAI.Tabular._emb_sz_rule\":{\"tag\":\"documentation\",\"title\":\"_emb_sz_rule\"},\"references\u002FFlux.convfilter\":{\"tag\":\"documentation\",\"title\":\"convfilter\"},\"references\u002FFlux.conv_reshape_bias\":{\"tag\":\"documentation\",\"title\":\"conv_reshape_bias\"},\"references\u002FFluxTraining.@unpack_History\":{\"tag\":\"documentation\",\"title\":\"@unpack_History\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002Ffasterai\u002Ftaskregistry.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002Ffasterai\u002Ftaskregistry.jl\"},\"references\u002FFlux._track_stats!\":{\"tag\":\"documentation\",\"title\":\"_track_stats!\"},\"references\u002FFluxTraining.FrequencyThrottle\":{\"tag\":\"documentation\",\"title\":\"FrequencyThrottle\"},\"documents\u002Fdocs\u002Fglossary.md\":{\"tag\":\"document\",\"title\":\"Glossary\"},\"references\u002FFluxTraining.SanityCheck\":{\"tag\":\"documentation\",\"title\":\"SanityCheck\"},\"references\u002FFastAI.checkblock\":{\"tag\":\"documentation\",\"title\":\"checkblock\"},\"references\u002FDataAugmentation.FromCenter\":{\"tag\":\"documentation\",\"title\":\"FromCenter\"},\"sourcefiles\u002FFluxTraining\u002Fsrc\u002Fcallbacks\u002Fprotect.jl\":{\"tag\":\"sourcefile\",\"title\":\"FluxTraining\u002Fsrc\u002Fcallbacks\u002Fprotect.jl\"},\"references\u002FDataAugmentation.Bounds\":{\"tag\":\"documentation\",\"title\":\"Bounds\"},\"sourcefiles\u002FDataAugmentation\u002Fsrc\u002Fitems\u002Fmask.jl\":{\"tag\":\"sourcefile\",\"title\":\"DataAugmentation\u002Fsrc\u002Fitems\u002Fmask.jl\"},\"references\u002FFastAI.encodestate\":{\"tag\":\"documentation\",\"title\":\"encodestate\"},\"references\u002FFluxTraining.ToGPU\":{\"tag\":\"documentation\",\"title\":\"ToGPU\"},\"sourcefiles\u002FFluxTraining\u002Fsrc\u002Ffunctional\u002Fmetrics.jl\":{\"tag\":\"sourcefile\",\"title\":\"FluxTraining\u002Fsrc\u002Ffunctional\u002Fmetrics.jl\"},\"references\u002FFastAI.loadmethodmodel\":{\"tag\":\"documentation\",\"title\":\"loadmethodmodel\"},\"references\u002FFastAI.defaultgrouper\":{\"tag\":\"documentation\",\"title\":\"defaultgrouper\"},\"references\u002FFluxTraining.on\":{\"tag\":\"documentation\",\"title\":\"on\"},\"references\u002FDataAugmentation.showitem!\":{\"tag\":\"documentation\",\"title\":\"showitem!\"},\"references\u002FDataAugmentation.centered\":{\"tag\":\"documentation\",\"title\":\"centered\"},\"references\u002FFastAI.defaultdataregistry\":{\"tag\":\"documentation\",\"title\":\"defaultdataregistry\"},\"references\u002FFastAI.Datasets.initdatadeps\":{\"tag\":\"documentation\",\"title\":\"initdatadeps\"},\"references\u002FFastAI.showsample\":{\"tag\":\"documentation\",\"title\":\"showsample\"},\"references\u002FDataAugmentation.Crop\":{\"tag\":\"documentation\",\"title\":\"Crop\"},\"references\u002FFlux.Losses.binarycrossentropy\":{\"tag\":\"documentation\",\"title\":\"binarycrossentropy\"},\"sourcefiles\u002FFluxTraining\u002Fsrc\u002Fcallbacks\u002Fgraph.jl\":{\"tag\":\"sourcefile\",\"title\":\"FluxTraining\u002Fsrc\u002Fcallbacks\u002Fgraph.jl\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002FVision\u002Fmodels\u002Fxresnet.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002FVision\u002Fmodels\u002Fxresnet.jl\"},\"references\u002FDataAugmentation.denormalize\":{\"tag\":\"documentation\",\"title\":\"denormalize\"},\"references\u002FFlux.NilNumber.nil\":{\"tag\":\"documentation\",\"title\":\"nil\"},\"references\u002FFluxTraining.testbatch\":{\"tag\":\"documentation\",\"title\":\"testbatch\"},\"references\u002FFlux.multigate\":{\"tag\":\"documentation\",\"title\":\"multigate\"},\"references\u002FDataAugmentation.OneOf\":{\"tag\":\"documentation\",\"title\":\"OneOf\"},\"references\u002FFastAI.Datasets.matches\":{\"tag\":\"documentation\",\"title\":\"matches\"},\"references\u002FFastAI.mockmodel\":{\"tag\":\"documentation\",\"title\":\"mockmodel\"},\"references\u002FFlux.NilNumber\":{\"tag\":\"documentation\",\"title\":\"NilNumber\"},\"references\u002FFastAI.Textual.Paragraph\":{\"tag\":\"documentation\",\"title\":\"Paragraph\"},\"references\u002FDataAugmentation.TabularItem\":{\"tag\":\"documentation\",\"title\":\"TabularItem\"},\"references\u002FFastAI.decodestate\":{\"tag\":\"documentation\",\"title\":\"decodestate\"},\"references\u002FFastAI.setschedules!\":{\"tag\":\"documentation\",\"title\":\"setschedules!\"},\"references\u002FFastAI.Vision.ImageSegmentationFolders\":{\"tag\":\"documentation\",\"title\":\"ImageSegmentationFolders\"},\"documents\u002FREADME.md\":{\"tag\":\"document\",\"title\":\"FastAI\"},\"references\u002FFlux.Losses.∇ctc_loss\":{\"tag\":\"documentation\",\"title\":\"∇ctc_loss\"},\"references\u002FFlux.Upsample\":{\"tag\":\"documentation\",\"title\":\"Upsample\"},\"sourcefiles\u002FFlux\u002Fsrc\u002Foptimise\u002FOptimise.jl\":{\"tag\":\"sourcefile\",\"title\":\"Flux\u002Fsrc\u002Foptimise\u002FOptimise.jl\"},\"documents\u002Fdocs\u002Fbackground\u002Fdatapipelines.md\":{\"tag\":\"document\",\"title\":\"Performant data pipelines\"},\"references\u002FFastAI.Tabular._get_emb_sz\":{\"tag\":\"documentation\",\"title\":\"_get_emb_sz\"},\"references\u002FDataAugmentation.AdjustContrast\":{\"tag\":\"documentation\",\"title\":\"AdjustContrast\"},\"references\u002FFastAI.OneHot\":{\"tag\":\"documentation\",\"title\":\"OneHot\"},\"references\u002FFluxTraining.defaultcallbacks\":{\"tag\":\"documentation\",\"title\":\"defaultcallbacks\"},\"references\u002FFluxTraining.NoConflict\":{\"tag\":\"documentation\",\"title\":\"NoConflict\"},\"references\u002FFastAI.decodeypred!\":{\"tag\":\"documentation\",\"title\":\"decodeypred!\"},\"references\u002FFastAI.Vision._segmentationloss\":{\"tag\":\"documentation\",\"title\":\"_segmentationloss\"},\"references\u002FFluxTraining.Learner\":{\"tag\":\"documentation\",\"title\":\"Learner\"},\"sourcefiles\u002FFlux\u002Fsrc\u002Fcuda\u002Fcuda.jl\":{\"tag\":\"sourcefile\",\"title\":\"Flux\u002Fsrc\u002Fcuda\u002Fcuda.jl\"},\"documents\u002Fdocs\u002Fdata_containers.md\":{\"tag\":\"document\",\"title\":\"Data containers\"},\"references\u002FFastAI.Textual.replace_all_caps\":{\"tag\":\"documentation\",\"title\":\"replace_all_caps\"},\"references\u002FFlux.OneHotLike\":{\"tag\":\"documentation\",\"title\":\"OneHotLike\"},\"references\u002FFastAI.PropagateAlways\":{\"tag\":\"documentation\",\"title\":\"PropagateAlways\"},\"references\u002FFluxTraining.runchecks\":{\"tag\":\"documentation\",\"title\":\"runchecks\"},\"references\u002FFastAI.Vision.Models.runtests\":{\"tag\":\"documentation\",\"title\":\"runtests\"},\"references\u002FFluxTraining.TimeThrottle\":{\"tag\":\"documentation\",\"title\":\"TimeThrottle\"},\"sourcefiles\u002FFluxTraining\u002Fsrc\u002Fcallbacks\u002Fsanitycheck.jl\":{\"tag\":\"sourcefile\",\"title\":\"FluxTraining\u002Fsrc\u002Fcallbacks\u002Fsanitycheck.jl\"},\"references\u002FFluxTraining.Phases.TrainingPhase\":{\"tag\":\"documentation\",\"title\":\"TrainingPhase\"},\"references\u002FFastAI.fillblock\":{\"tag\":\"documentation\",\"title\":\"fillblock\"},\"references\u002FFlux\":{\"tag\":\"documentation\",\"title\":\"Flux\"},\"references\u002FFlux.Optimise.InvDecay\":{\"tag\":\"documentation\",\"title\":\"InvDecay\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002Ftraining\u002Ffinetune.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002Ftraining\u002Ffinetune.jl\"},\"references\u002FDataAugmentation.ScaleFixed\":{\"tag\":\"documentation\",\"title\":\"ScaleFixed\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002Fdatablock\u002Fencoding.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002Fdatablock\u002Fencoding.jl\"},\"references\u002FDataAugmentation.Zoom\":{\"tag\":\"documentation\",\"title\":\"Zoom\"},\"references\u002FFlux.AdaptiveMaxPool\":{\"tag\":\"documentation\",\"title\":\"AdaptiveMaxPool\"},\"references\u002FFlux.Optimise.ExpDecay\":{\"tag\":\"documentation\",\"title\":\"ExpDecay\"},\"references\u002FFastAI.Vision._maskimage\":{\"tag\":\"documentation\",\"title\":\"_maskimage\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002Ftraining\u002Fparamgroups.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002Ftraining\u002Fparamgroups.jl\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002FVision\u002Fmodels\u002Fblocks.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002FVision\u002Fmodels\u002Fblocks.jl\"},\"references\u002FFlux._isactive\":{\"tag\":\"documentation\",\"title\":\"_isactive\"},\"references\u002FDataAugmentation.getprojection\":{\"tag\":\"documentation\",\"title\":\"getprojection\"},\"references\u002FDataAugmentation.adjustcontrast!\":{\"tag\":\"documentation\",\"title\":\"adjustcontrast!\"},\"references\u002FFlux.Optimise.Descent\":{\"tag\":\"documentation\",\"title\":\"Descent\"},\"references\u002FFastAI.blocklossfn\":{\"tag\":\"documentation\",\"title\":\"blocklossfn\"},\"references\u002FFlux.conv_dims\":{\"tag\":\"documentation\",\"title\":\"conv_dims\"},\"references\u002FFlux._channels_out\":{\"tag\":\"documentation\",\"title\":\"_channels_out\"},\"references\u002FFluxTraining.Events.EpochEnd\":{\"tag\":\"documentation\",\"title\":\"EpochEnd\"},\"references\u002FFastAI.getencodings\":{\"tag\":\"documentation\",\"title\":\"getencodings\"},\"references\u002FFlux.early_stopping\":{\"tag\":\"documentation\",\"title\":\"early_stopping\"},\"references\u002FFastAI.Datasets.mapobs\":{\"tag\":\"documentation\",\"title\":\"mapobs\"},\"references\u002FFluxTraining.Phases\":{\"tag\":\"documentation\",\"title\":\"Phases\"},\"references\u002FFlux.Losses.xlogy\":{\"tag\":\"documentation\",\"title\":\"xlogy\"},\"references\u002FDataAugmentation.CroppedProjectiveTransform\":{\"tag\":\"documentation\",\"title\":\"CroppedProjectiveTransform\"},\"references\u002FDataAugmentation.apply!\":{\"tag\":\"documentation\",\"title\":\"apply!\"},\"references\u002FFastAI.Datasets.parentname\":{\"tag\":\"documentation\",\"title\":\"parentname\"},\"references\u002FDataAugmentation.itemfield\":{\"tag\":\"documentation\",\"title\":\"itemfield\"},\"references\u002FFlux.Optimise.EPS\":{\"tag\":\"documentation\",\"title\":\"EPS\"},\"references\u002FFluxTraining.SmoothLoss\":{\"tag\":\"documentation\",\"title\":\"SmoothLoss\"},\"sourcefiles\u002FDataAugmentation\u002Fsrc\u002Fitems\u002Fimage.jl\":{\"tag\":\"sourcefile\",\"title\":\"DataAugmentation\u002Fsrc\u002Fitems\u002Fimage.jl\"},\"references\u002FFlux.dropout\":{\"tag\":\"documentation\",\"title\":\"dropout\"},\"references\u002FFluxTraining.Phases.Phase\":{\"tag\":\"documentation\",\"title\":\"Phase\"},\"references\u002FFastAI.Vision.imagedatasetstats\":{\"tag\":\"documentation\",\"title\":\"imagedatasetstats\"},\"references\u002FFluxTraining\":{\"tag\":\"documentation\",\"title\":\"FluxTraining\"},\"references\u002FFastAI.showoutputbatch\":{\"tag\":\"documentation\",\"title\":\"showoutputbatch\"},\"references\u002FFlux.params\":{\"tag\":\"documentation\",\"title\":\"params\"},\"references\u002FFastAI.Datasets.loaddataset\":{\"tag\":\"documentation\",\"title\":\"loaddataset\"},\"references\u002FFlux.Optimise.AMSGrad\":{\"tag\":\"documentation\",\"title\":\"AMSGrad\"},\"references\u002FFlux.Optimise.RADAM\":{\"tag\":\"documentation\",\"title\":\"RADAM\"},\"sourcefiles\u002FFluxTraining\u002Fsrc\u002Fcallbacks\u002Frecorder.jl\":{\"tag\":\"sourcefile\",\"title\":\"FluxTraining\u002Fsrc\u002Fcallbacks\u002Frecorder.jl\"},\"references\u002FFlux.Losses.MAX_THREADS\":{\"tag\":\"documentation\",\"title\":\"MAX_THREADS\"},\"references\u002FFlux.CrossCor\":{\"tag\":\"documentation\",\"title\":\"CrossCor\"},\"references\u002FFastAI.showsamples\":{\"tag\":\"documentation\",\"title\":\"showsamples\"},\"references\u002FFastAI.Inference\":{\"tag\":\"documentation\",\"title\":\"Inference\"},\"references\u002FDataAugmentation.showimage!\":{\"tag\":\"documentation\",\"title\":\"showimage!\"},\"references\u002FFastAI.LearningTask\":{\"tag\":\"documentation\",\"title\":\"LearningTask\"},\"references\u002FFlux.ofeltype\":{\"tag\":\"documentation\",\"title\":\"ofeltype\"},\"references\u002FFluxTraining.CancelEpochException\":{\"tag\":\"documentation\",\"title\":\"CancelEpochException\"},\"references\u002FFastAI.Tabular.TableClassificationRecipe\":{\"tag\":\"documentation\",\"title\":\"TableClassificationRecipe\"},\"references\u002FFlux.nil_input\":{\"tag\":\"documentation\",\"title\":\"nil_input\"},\"references\u002FFastAI.Datasets.DATASETS\":{\"tag\":\"documentation\",\"title\":\"DATASETS\"},\"references\u002FFastAI.Vision.augs_lighting\":{\"tag\":\"documentation\",\"title\":\"augs_lighting\"},\"references\u002FFastAI.makebatch\":{\"tag\":\"documentation\",\"title\":\"makebatch\"},\"references\u002FFastAI.decode\":{\"tag\":\"documentation\",\"title\":\"decode\"},\"references\u002FFastAI.Textual.RECIPES\":{\"tag\":\"documentation\",\"title\":\"RECIPES\"},\"references\u002FFastAI.Datasets.isimagefile\":{\"tag\":\"documentation\",\"title\":\"isimagefile\"},\"references\u002FFastAI.Datasets.maskfromimage\":{\"tag\":\"documentation\",\"title\":\"maskfromimage\"},\"references\u002FFastAI.isshowable\":{\"tag\":\"documentation\",\"title\":\"isshowable\"},\"references\u002FFastAI.encodedblockfilled\":{\"tag\":\"documentation\",\"title\":\"encodedblockfilled\"},\"references\u002FFlux._any\":{\"tag\":\"documentation\",\"title\":\"_any\"},\"references\u002FFastAI.getbatch\":{\"tag\":\"documentation\",\"title\":\"getbatch\"},\"references\u002FFastAI.AbstractBlock\":{\"tag\":\"documentation\",\"title\":\"AbstractBlock\"},\"sourcefiles\u002FDataAugmentation\u002Fsrc\u002Fprojective\u002Fcompose.jl\":{\"tag\":\"sourcefile\",\"title\":\"DataAugmentation\u002Fsrc\u002Fprojective\u002Fcompose.jl\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002FFastAI.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002FFastAI.jl\"},\"sourcefiles\u002FDataAugmentation\u002Fsrc\u002Fitems\u002Ftable.jl\":{\"tag\":\"sourcefile\",\"title\":\"DataAugmentation\u002Fsrc\u002Fitems\u002Ftable.jl\"},\"references\u002FFlux.Losses.log_plus_f\":{\"tag\":\"documentation\",\"title\":\"log_plus_f\"},\"references\u002FFlux.Optimise.ADAM\":{\"tag\":\"documentation\",\"title\":\"ADAM\"},\"references\u002FFastAI.loadtaskmodel\":{\"tag\":\"documentation\",\"title\":\"loadtaskmodel\"},\"references\u002FFastAI.Tabular.##InlineTest-01b48f5c342f65df7fcd07f28f0d2cacbb09f0a0.__init__\":{\"tag\":\"documentation\",\"title\":\"__init__\"},\"references\u002FFlux._onehotbatch\":{\"tag\":\"documentation\",\"title\":\"_onehotbatch\"},\"sourcefiles\u002FFluxTraining\u002Fsrc\u002Fcallbacks\u002Fconditional.jl\":{\"tag\":\"sourcefile\",\"title\":\"FluxTraining\u002Fsrc\u002Fcallbacks\u002Fconditional.jl\"},\"references\u002FFastAI.decodeypred\":{\"tag\":\"documentation\",\"title\":\"decodeypred\"},\"references\u002FDataAugmentation.compose\":{\"tag\":\"documentation\",\"title\":\"compose\"},\"references\u002FDataAugmentation.showkeypoint!\":{\"tag\":\"documentation\",\"title\":\"showkeypoint!\"},\"references\u002FFastAI.Datasets._iterobs\":{\"tag\":\"documentation\",\"title\":\"_iterobs\"},\"references\u002FFlux.FluxCUDAAdaptor\":{\"tag\":\"documentation\",\"title\":\"FluxCUDAAdaptor\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002Flearner.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002Flearner.jl\"},\"references\u002FFlux.Losses.compute_alpha_kernel\":{\"tag\":\"documentation\",\"title\":\"compute_alpha_kernel\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002FTextual\u002Ftransform.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002FTextual\u002Ftransform.jl\"},\"references\u002FFastAI.tasklearner\":{\"tag\":\"documentation\",\"title\":\"tasklearner\"},\"references\u002FDataAugmentation.getrandstate\":{\"tag\":\"documentation\",\"title\":\"getrandstate\"},\"references\u002FFlux.∇eachlastdim\":{\"tag\":\"documentation\",\"title\":\"∇eachlastdim\"},\"references\u002FFastAI.Datasets.finddatasets\":{\"tag\":\"documentation\",\"title\":\"finddatasets\"},\"references\u002FFastAI.Tabular.runtests\":{\"tag\":\"documentation\",\"title\":\"runtests\"},\"sourcefiles\u002FFlux\u002Fsrc\u002Floading.jl\":{\"tag\":\"sourcefile\",\"title\":\"Flux\u002Fsrc\u002Floading.jl\"},\"references\u002FFlux.Losses.logitbinarycrossentropy\":{\"tag\":\"documentation\",\"title\":\"logitbinarycrossentropy\"},\"references\u002FFlux.loadmodel!\":{\"tag\":\"documentation\",\"title\":\"loadmodel!\"},\"references\u002FFastAI.Datasets.FileDataset\":{\"tag\":\"documentation\",\"title\":\"FileDataset\"},\"sourcefiles\u002FFlux\u002Fsrc\u002Flayers\u002Frecurrent.jl\":{\"tag\":\"sourcefile\",\"title\":\"Flux\u002Fsrc\u002Flayers\u002Frecurrent.jl\"},\"references\u002FFluxTraining.Events.EpochBegin\":{\"tag\":\"documentation\",\"title\":\"EpochBegin\"},\"sourcefiles\u002FFluxTraining\u002Fsrc\u002Fcallbacks\u002Flogging\u002Fcheckpointer.jl\":{\"tag\":\"sourcefile\",\"title\":\"FluxTraining\u002Fsrc\u002Fcallbacks\u002Flogging\u002Fcheckpointer.jl\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002Ftraining\u002Fdiscriminativelrs.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002Ftraining\u002Fdiscriminativelrs.jl\"},\"references\u002FFlux.crosscor\":{\"tag\":\"documentation\",\"title\":\"crosscor\"},\"references\u002FFastAI.decodeŷ\":{\"tag\":\"documentation\",\"title\":\"decodeŷ\"},\"references\u002FFluxTraining.onecycle\":{\"tag\":\"documentation\",\"title\":\"onecycle\"},\"sourcefiles\u002FFluxTraining\u002Fsrc\u002Fcallbacks\u002Fearlystopping.jl\":{\"tag\":\"sourcefile\",\"title\":\"FluxTraining\u002Fsrc\u002Fcallbacks\u002Fearlystopping.jl\"},\"references\u002FFastAI.DiscriminativeLRs\":{\"tag\":\"documentation\",\"title\":\"DiscriminativeLRs\"},\"sourcefiles\u002FFastAI\u002Fsrc\u002FTabular\u002Ftasks\u002Fregression.jl\":{\"tag\":\"sourcefile\",\"title\":\"FastAI\u002Fsrc\u002FTabular\u002Ftasks\u002Fregression.jl\"},\"references\u002FFastAI.Datasets.listdatasources\":{\"tag\":\"documentation\",\"title\":\"listdatasources\"},\"references\u002FFastAI.blockcolumn\":{\"tag\":\"documentation\",\"title\":\"blockcolumn\"},\"references\u002FFlux.identity_init\":{\"tag\":\"documentation\",\"title\":\"identity_init\"},\"references\u002FFastAI.Datasets.blocksmatch\":{\"tag\":\"documentation\",\"title\":\"blocksmatch\"},\"references\u002FFlux.eachlastdim\":{\"tag\":\"documentation\",\"title\":\"eachlastdim\"},\"references\u002FFastAI.savetaskmodel\":{\"tag\":\"documentation\",\"title\":\"savetaskmodel\"},\"references\u002FFastAI.Continuous\":{\"tag\":\"documentation\",\"title\":\"Continuous\"},\"references\u002FFluxTraining.ProgressPrinter\":{\"tag\":\"documentation\",\"title\":\"ProgressPrinter\"},\"references\u002FFastAI.testencoding\":{\"tag\":\"documentation\",\"title\":\"testencoding\"},\"references\u002FFluxTraining.handle\":{\"tag\":\"documentation\",\"title\":\"handle\"},\"references\u002FFlux.Losses.count_repeats\":{\"tag\":\"documentation\",\"title\":\"count_repeats\"},\"references\u002FDataAugmentation.OneHot\":{\"tag\":\"documentation\",\"title\":\"OneHot\"},\"references\u002FDataAugmentation.adjustbrightness!\":{\"tag\":\"documentation\",\"title\":\"adjustbrightness!\"},\"references\u002FDataAugmentation.Item\":{\"tag\":\"documentation\",\"title\":\"Item\"},\"references\u002FFastAI.Datasets.ROOT_URL\":{\"tag\":\"documentation\",\"title\":\"ROOT_URL\"},\"references\u002FFastAI.typify\":{\"tag\":\"documentation\",\"title\":\"typify\"},\"references\u002FDataAugmentation.reflectionmatrix\":{\"tag\":\"documentation\",\"title\":\"reflectionmatrix\"},\"references\u002FFlux.Maxout\":{\"tag\":\"documentation\",\"title\":\"Maxout\"},\"references\u002FFluxTraining.errorwriteconflict\":{\"tag\":\"documentation\",\"title\":\"errorwriteconflict\"},\"references\u002FFastAI.Datasets.DATASETCONFIGS\":{\"tag\":\"documentation\",\"title\":\"DATASETCONFIGS\"},\"references\u002FFastAI.getblocks\":{\"tag\":\"documentation\",\"title\":\"getblocks\"},\"references\u002FFlux.f32\":{\"tag\":\"documentation\",\"title\":\"f32\"},\"references\u002FFlux.Optimise\":{\"tag\":\"documentation\",\"title\":\"Optimise\"},\"references\u002FDataAugmentation.ScaleKeepAspect\":{\"tag\":\"documentation\",\"title\":\"ScaleKeepAspect\"},\"references\u002FFastAI.Vision.ImageClassificationMulti\":{\"tag\":\"documentation\",\"title\":\"ImageClassificationMulti\"},\"references\u002FDataAugmentation.adjustbrightness\":{\"tag\":\"documentation\",\"title\":\"adjustbrightness\"},\"references\u002FFastAI.LRFinderResult\":{\"tag\":\"documentation\",\"title\":\"LRFinderResult\"},\"references\u002FFluxTraining.LoggerBackend\":{\"tag\":\"documentation\",\"title\":\"LoggerBackend\"},\"references\u002FFlux.glorot_uniform\":{\"tag\":\"documentation\",\"title\":\"glorot_uniform\"}}"}</script>
	<script type="application/json" data-type="svelte-data" data-url="/FastAI.jl/data/dev/config.json">{"status":200,"statusText":"","headers":{"content-type":"application/json"},"body":"{\"linktree\":{\"Overview\":\"documents\u002FREADME.md\",\"Setup\":\"documents\u002Fdocs\u002Fsetup.md\",\"Quickstart\":\"documents\u002Fnotebooks\u002Fquickstart.ipynb\",\"Core\":{\"Tutorials\":{\"Introduction\":\"documents\u002Fdocs\u002Fintroduction.md\",\"Discovering functionality\":\"documents\u002Fdocs\u002Fdiscovery.md\",\"Intermediate\":{\"Data containers\":\"documents\u002Fdocs\u002Fdata_containers.md\"},\"Advanced\":{\"Unsupervised learning with VAEs\":\"documents\u002Fnotebooks\u002Fvae.ipynb\"}},\"How-to\":{\"Train a model\":\"documents\u002Fnotebooks\u002Ftraining.ipynb\",\"Load and save models\":\"documents\u002Fnotebooks\u002Fserialization.ipynb\",\"Log to TensorBoard\":\"documents\u002Fnotebooks\u002Ftraining.ipynb\"},\"Background\":{\"Comparison to fast.ai\":\"documents\u002Fdocs\u002Ffastai_api_comparison.md\",\"Performant data pipelines\":\"documents\u002Fdocs\u002Fbackground\u002Fdatapipelines.md\",\"Blocks and Encodings\":\"documents\u002Fdocs\u002Fbackground\u002Fblocksencodings.md\"}},\"Computer vision\":{\"Tasks\":{\"Image segmentation\":\"documents\u002Fnotebooks\u002Fimagesegmentation.ipynb\",\"Keypoint regression\":\"documents\u002Fnotebooks\u002Fkeypointregression.ipynb\"},\"How-To\":{\"Use augmentations\":\"documents\u002Fdocs\u002Fhowto\u002Faugmentvision.md\",\"Presize vision datasets\":\"documents\u002Fnotebooks\u002Fpresizing.ipynb\"}},\"Tabular data\":{\"Tasks\":{\"Tabular classification\":\"documents\u002Fnotebooks\u002Ftabularclassification.ipynb\"}}},\"columnWidth\":650,\"title\":\"FastAI.jl\",\"url\":\"https:\u002F\u002Fgithub.com\u002FFluxML\u002FFastAI.jl\",\"defaultDocument\":\"documents\u002FREADME.md\"}"}</script>
	<script type="application/json" data-type="svelte-data" data-url="/FastAI.jl/data/dev/documents/docs/fastai_api_comparison.md.json">{"status":200,"statusText":"","headers":{"content-type":"application/json"},"body":"{\"attributes\":{\"backlinks\":[],\"path\":\"\u002Fhome\u002Frunner\u002F.julia\u002Fpackages\u002FFastAI\u002FTAk8d\u002Fdocs\u002Ffastai_api_comparison.md\",\"title\":\"fastai API comparison\"},\"tag\":\"document\",\"children\":[{\"attributes\":{},\"tag\":\"md\",\"children\":[{\"attributes\":{},\"tag\":\"h1\",\"children\":[\"fastai API comparison\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"p\",\"children\":[\"FastAI.jl is in many ways similar to the original Python \",{\"attributes\":{\"reftype\":\"document\",\"href\":\"docs.fast.ai\",\"title\":\"\",\"document_id\":\"documents\u002Fdocs\u002Fdocs.fast.ai\"},\"tag\":\"reference\",\"children\":[\"fastai\"],\"type\":\"node\"},\", but also has its differences. This reference goes through all the sections in the \",{\"attributes\":{\"href\":\"https:\u002F\u002Farxiv.org\u002Fabs\u002F2002.04688\",\"title\":\"\"},\"tag\":\"a\",\"children\":[\"fastai: A Layered API for Deep Learning\"],\"type\":\"node\"},\" paper and comments what the interfaces for the same functionality in FastAI.jl are, and where they differ or functionality is still missing.\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"h2\",\"children\":[\"Applications\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"p\",\"children\":[\"FastAI.jl’s own data block API makes it possible to derive every part of a high-level interface with a unified API across tasks. Instead it suffices to create a learning task and based on the blocks and encodings specified the proper model builder, loss function, and visualizations are implemented (see below). For a high-level API, a complete \",{\"attributes\":{},\"tag\":\"code\",\"children\":[\"Learner\"],\"type\":\"node\"},\" can be constructed using \",{\"attributes\":{\"reftype\":\"symbol\",\"document_id\":\"references\u002FFastAI.tasklearner\"},\"tag\":\"reference\",\"children\":[{\"attributes\":{},\"tag\":\"code\",\"children\":[\"tasklearner\"],\"type\":\"node\"}],\"type\":\"node\"},\" without much boilerplate. There are some helper functions for  creating these learning tasks, for example \",{\"attributes\":{\"reftype\":\"symbol\",\"document_id\":\"references\u002FFastAI.Vision.ImageClassificationSingle\"},\"tag\":\"reference\",\"children\":[{\"attributes\":{},\"tag\":\"code\",\"children\":[\"ImageClassificationSingle\"],\"type\":\"node\"}],\"type\":\"node\"},\" and \",{\"attributes\":{\"reftype\":\"symbol\",\"document_id\":\"references\u002FFastAI.Vision.ImageSegmentation\"},\"tag\":\"reference\",\"children\":[{\"attributes\":{},\"tag\":\"code\",\"children\":[\"ImageSegmentation\"],\"type\":\"node\"}],\"type\":\"node\"},\".\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"p\",\"children\":[\"FastAI.jl additionally has a unified API for registering and discovering functionality across applications also based on the data block abstraction.  \",{\"attributes\":{},\"tag\":\"code\",\"children\":[\"finddatasets\"],\"type\":\"node\"},\" and \",{\"attributes\":{},\"tag\":\"code\",\"children\":[\"loaddataset\"],\"type\":\"node\"},\" let you quickly load common datasets matching some data modality and \",{\"attributes\":{},\"tag\":\"code\",\"children\":[\"findlearningtask\"],\"type\":\"node\"},\" lets you find learning task helpers for common tasks. See \",{\"attributes\":{\"reftype\":\"document\",\"href\":\"discovery.md\",\"title\":\"\",\"document_id\":\"documents\u002Fdocs\u002Fdiscovery.md\"},\"tag\":\"reference\",\"children\":[\"the discovery tutorial\"],\"type\":\"node\"},\" for more info.\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"h3\",\"children\":[\"Vision\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"p\",\"children\":[\"Computer vision is the most developed part of FastAI.jl with good support for different tasks and optimized data pipelines with N-dimensional images, masks and keypoints. See the tutorial section for many examples.\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"h3\",\"children\":[\"Tabular\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"p\",\"children\":[\"Support for tabular data is merged into master but is lacking documentation which will come with the next release (0.2.0).\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"h3\",\"children\":[\"Deployment\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"p\",\"children\":[\"Through FastAI.jl’s \",{\"attributes\":{\"reftype\":\"document\",\"href\":\".\u002Flearning_tasks.md\",\"title\":\"\",\"document_id\":\"documents\u002Fdocs\u002Flearning_tasks.md\"},\"tag\":\"reference\",\"children\":[{\"attributes\":{},\"tag\":\"code\",\"children\":[\"LearningTask\"],\"type\":\"node\"},\" interface\"],\"type\":\"node\"},\", the data processing logic is decoupled from the dataset creation and training and can be easily serialized and loaded to make predictions. See the tutorial on \",{\"attributes\":{\"reftype\":\"document\",\"href\":\"..\u002Fnotebooks\u002Fserialization.ipynb\",\"title\":\"\",\"document_id\":\"documents\u002Fnotebooks\u002Fserialization.ipynb\"},\"tag\":\"reference\",\"children\":[\"saving and loading models\"],\"type\":\"node\"},\".\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"hr\",\"children\":[],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"p\",\"children\":[\"There is no integration (yet!) for text and collaborative filtering applications.\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"h2\",\"children\":[\"High\",\"-\",\"level API\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"h3\",\"children\":[\"High\",\"-\",\"level API foundations\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"p\",\"children\":[\"FastAI.jl also has a data block API but it differs from fastai’s in a number of ways. In the Julia package it only handles the data encoding and decoding part, and doesn’t concern itself with creating datasets. For dataset loading, see the \",{\"attributes\":{\"reftype\":\"document\",\"href\":\"data_containers.md\",\"title\":\"\",\"document_id\":\"documents\u002Fdocs\u002Fdata_containers.md\"},\"tag\":\"reference\",\"children\":[\"data container API\"],\"type\":\"node\"},\". As mentioned above, the high-level application-specific logic is also derived from the data block API. To use it you need to specify a tuple of input and target blocks as well as a tuple of encodings that are applied to the data. The encodings  are invertible data-specific data processing steps which correspond to \",{\"attributes\":{},\"tag\":\"code\",\"children\":[\"fastai.Transform\"],\"type\":\"node\"},\"s. As in fastai, dispatch is used to transform applicable data and pass other data through unchanged. Unlike in fastai, there are no default steps associated with a block, allowing greater flexibility.\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"p\",\"children\":[\"We can create a \",{\"attributes\":{},\"tag\":\"code\",\"children\":[\"BlockTask\"],\"type\":\"node\"},\" (similar to \",{\"attributes\":{},\"tag\":\"code\",\"children\":[\"fastai.DataBlock\"],\"type\":\"node\"},\") and get information about the representations the data goes through.\"],\"type\":\"node\"},{\"attributes\":{\"cell\":\"main\",\"lang\":\"julia\"},\"tag\":\"codecell\",\"children\":[{\"attributes\":{},\"tag\":\"codeinput\",\"children\":[{\"attributes\":{\"cell\":\"main\",\"lang\":\"julia\"},\"tag\":\"codeblock\",\"children\":[{\"attributes\":{},\"tag\":\"julia\",\"children\":[{\"attributes\":{},\"tag\":\"USING\",\"children\":[{\"attributes\":{},\"tag\":\"USING\",\"children\":[\"using\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"DOT\",\"children\":[{\"attributes\":{},\"tag\":\"WHITESPACE\",\"children\":[\" \"],\"type\":\"node\"},{\"attributes\":{\"reftype\":\"symbol\",\"document_id\":\"references\u002FFastAI\"},\"tag\":\"reference\",\"children\":[\"FastAI\"],\"type\":\"node\"}],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"NEWLINE_WS\",\"children\":[\"\\n\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"IMPORT\",\"children\":[{\"attributes\":{},\"tag\":\"COLON\",\"children\":[{\"attributes\":{},\"tag\":\"IMPORT\",\"children\":[\"import\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"DOT\",\"children\":[{\"attributes\":{},\"tag\":\"WHITESPACE\",\"children\":[\" \"],\"type\":\"node\"},{\"attributes\":{\"reftype\":\"symbol\",\"document_id\":\"references\u002FFastAI\"},\"tag\":\"reference\",\"children\":[\"FastAI\"],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"COLON\",\"children\":[\":\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"DOT\",\"children\":[{\"attributes\":{},\"tag\":\"WHITESPACE\",\"children\":[\" \"],\"type\":\"node\"},{\"attributes\":{\"reftype\":\"symbol\",\"document_id\":\"references\u002FDataAugmentation.Image\"},\"tag\":\"reference\",\"children\":[\"Image\"],\"type\":\"node\"}],\"type\":\"node\"}],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"NEWLINE_WS\",\"children\":[\"\\n\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"NEWLINE_WS\",\"children\":[\"\\n\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"EQ\",\"children\":[{\"attributes\":{},\"tag\":\"IDENTIFIER\",\"children\":[\"task\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"WHITESPACE\",\"children\":[\" \"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"EQ\",\"children\":[\"=\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"WHITESPACE\",\"children\":[\" \"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"CALL\",\"children\":[{\"attributes\":{\"reftype\":\"symbol\",\"document_id\":\"references\u002FFastAI.BlockTask\"},\"tag\":\"reference\",\"children\":[\"BlockTask\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"LPAREN\",\"children\":[\"(\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"NEWLINE_WS\",\"children\":[\"\\n    \"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"TUPLE\",\"children\":[{\"attributes\":{},\"tag\":\"LPAREN\",\"children\":[\"(\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"CALL\",\"children\":[{\"attributes\":{},\"tag\":\"CURLY\",\"children\":[{\"attributes\":{\"reftype\":\"symbol\",\"document_id\":\"references\u002FDataAugmentation.Image\"},\"tag\":\"reference\",\"children\":[\"Image\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"LBRACE\",\"children\":[\"{\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"INTEGER\",\"children\":[\"2\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"RBRACE\",\"children\":[\"}\"],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"LPAREN\",\"children\":[\"(\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"RPAREN\",\"children\":[\")\"],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"COMMA\",\"children\":[\",\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"WHITESPACE\",\"children\":[\" \"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"CALL\",\"children\":[{\"attributes\":{},\"tag\":\"CURLY\",\"children\":[{\"attributes\":{\"reftype\":\"symbol\",\"document_id\":\"references\u002FFastAI.Vision.Mask\"},\"tag\":\"reference\",\"children\":[\"Mask\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"LBRACE\",\"children\":[\"{\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"INTEGER\",\"children\":[\"2\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"RBRACE\",\"children\":[\"}\"],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"LPAREN\",\"children\":[\"(\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"VECT\",\"children\":[{\"attributes\":{},\"tag\":\"LSQUARE\",\"children\":[\"[\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"DQUOTE\",\"children\":[\"\\\"\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"STRING\",\"children\":[\"foreground\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"DQUOTE\",\"children\":[\"\\\"\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"COMMA\",\"children\":[\",\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"WHITESPACE\",\"children\":[\" \"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"DQUOTE\",\"children\":[\"\\\"\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"STRING\",\"children\":[\"background\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"DQUOTE\",\"children\":[\"\\\"\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"RSQUARE\",\"children\":[\"]\"],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"RPAREN\",\"children\":[\")\"],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"RPAREN\",\"children\":[\")\"],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"COMMA\",\"children\":[\",\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"NEWLINE_WS\",\"children\":[\"\\n    \"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"TUPLE\",\"children\":[{\"attributes\":{},\"tag\":\"LPAREN\",\"children\":[\"(\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"NEWLINE_WS\",\"children\":[\"\\n        \"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"CALL\",\"children\":[{\"attributes\":{\"reftype\":\"symbol\",\"document_id\":\"references\u002FFastAI.Vision.ProjectiveTransforms\"},\"tag\":\"reference\",\"children\":[\"ProjectiveTransforms\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"LPAREN\",\"children\":[\"(\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"TUPLE\",\"children\":[{\"attributes\":{},\"tag\":\"LPAREN\",\"children\":[\"(\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"INTEGER\",\"children\":[\"128\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"COMMA\",\"children\":[\",\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"WHITESPACE\",\"children\":[\" \"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"INTEGER\",\"children\":[\"128\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"RPAREN\",\"children\":[\")\"],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"RPAREN\",\"children\":[\")\"],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"COMMA\",\"children\":[\",\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"NEWLINE_WS\",\"children\":[\"\\n        \"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"CALL\",\"children\":[{\"attributes\":{\"reftype\":\"symbol\",\"document_id\":\"references\u002FFastAI.Vision.ImagePreprocessing\"},\"tag\":\"reference\",\"children\":[\"ImagePreprocessing\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"LPAREN\",\"children\":[\"(\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"RPAREN\",\"children\":[\")\"],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"COMMA\",\"children\":[\",\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"NEWLINE_WS\",\"children\":[\"\\n        \"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"CALL\",\"children\":[{\"attributes\":{\"reftype\":\"symbol\",\"document_id\":\"references\u002FDataAugmentation.OneHot\"},\"tag\":\"reference\",\"children\":[\"OneHot\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"LPAREN\",\"children\":[\"(\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"RPAREN\",\"children\":[\")\"],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"COMMA\",\"children\":[\",\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"NEWLINE_WS\",\"children\":[\"\\n    \"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"RPAREN\",\"children\":[\")\"],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"NEWLINE_WS\",\"children\":[\"\\n\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"RPAREN\",\"children\":[\")\"],\"type\":\"node\"}],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"NEWLINE_WS\",\"children\":[\"\\n\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"CALL\",\"children\":[{\"attributes\":{\"reftype\":\"symbol\",\"document_id\":\"references\u002FFastAI.describetask\"},\"tag\":\"reference\",\"children\":[\"describetask\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"LPAREN\",\"children\":[\"(\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"IDENTIFIER\",\"children\":[\"task\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"RPAREN\",\"children\":[\")\"],\"type\":\"node\"}],\"type\":\"node\"}],\"type\":\"node\"}],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"coderesult\",\"children\":[{\"mimes\":{\"text\u002Fhtml\":\"\u003Cdiv class=\\\"markdown\\\"\u003E\u003Cp\u003E\u003Cstrong\u003E\u003Ccode\u003ESupervisedTask\u003C\u002Fcode\u003E summary\u003C\u002Fstrong\u003E\u003C\u002Fp\u003E\\n\u003Cp\u003ELearning task for the supervised task with input \u003Ccode\u003EImage&#123;2&#125;\u003C\u002Fcode\u003E and target \u003Ccode\u003EMask&#123;2, String&#125;\u003C\u002Fcode\u003E. Compatible with \u003Ccode\u003Emodel\u003C\u002Fcode\u003Es that take in \u003Ccode\u003EBounded&#123;2, FastAI.Vision.ImageTensor&#123;2&#125;&#125;\u003C\u002Fcode\u003E and output \u003Ccode\u003EBounded&#123;2, FastAI.OneHotTensor&#123;2, String&#125;&#125;\u003C\u002Fcode\u003E.\u003C\u002Fp\u003E\\n\u003Cp\u003EEncoding a sample &#40;\u003Ccode\u003Eencodesample&#40;task, context, sample&#41;\u003C\u002Fcode\u003E&#41; is done through the following encodings:\u003C\u002Fp\u003E\\n\u003Ctable\u003E\u003Ctr\u003E\u003Cth align=\\\"right\\\"\u003EEncoding\u003C\u002Fth\u003E\u003Cth align=\\\"right\\\"\u003EName\u003C\u002Fth\u003E\u003Cth align=\\\"right\\\"\u003E\u003Ccode\u003Eblocks.input\u003C\u002Fcode\u003E\u003C\u002Fth\u003E\u003Cth align=\\\"right\\\"\u003E\u003Ccode\u003Eblocks.target\u003C\u002Fcode\u003E\u003C\u002Fth\u003E\u003C\u002Ftr\u003E\u003Ctr\u003E\u003Ctd align=\\\"right\\\"\u003E\u003C\u002Ftd\u003E\u003Ctd align=\\\"right\\\"\u003E\u003Ccode\u003E&#40;input, target&#41;\u003C\u002Fcode\u003E\u003C\u002Ftd\u003E\u003Ctd align=\\\"right\\\"\u003E\u003Ccode\u003EImage&#123;2&#125;\u003C\u002Fcode\u003E\u003C\u002Ftd\u003E\u003Ctd align=\\\"right\\\"\u003E\u003Ccode\u003EMask&#123;2, String&#125;\u003C\u002Fcode\u003E\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003Ctr\u003E\u003Ctd align=\\\"right\\\"\u003E\u003Ccode\u003EProjectiveTransforms\u003C\u002Fcode\u003E\u003C\u002Ftd\u003E\u003Ctd align=\\\"right\\\"\u003E\u003C\u002Ftd\u003E\u003Ctd align=\\\"right\\\"\u003E\u003Cstrong\u003E\u003Ccode\u003EBounded&#123;2, Image&#123;2&#125;&#125;\u003C\u002Fcode\u003E\u003C\u002Fstrong\u003E\u003C\u002Ftd\u003E\u003Ctd align=\\\"right\\\"\u003E\u003Cstrong\u003E\u003Ccode\u003EBounded&#123;2, Mask&#123;2, String&#125;&#125;\u003C\u002Fcode\u003E\u003C\u002Fstrong\u003E\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003Ctr\u003E\u003Ctd align=\\\"right\\\"\u003E\u003Ccode\u003EImagePreprocessing\u003C\u002Fcode\u003E\u003C\u002Ftd\u003E\u003Ctd align=\\\"right\\\"\u003E\u003C\u002Ftd\u003E\u003Ctd align=\\\"right\\\"\u003E\u003Cstrong\u003E\u003Ccode\u003EBounded&#123;2, FastAI.Vision.ImageTensor&#123;2&#125;&#125;\u003C\u002Fcode\u003E\u003C\u002Fstrong\u003E\u003C\u002Ftd\u003E\u003Ctd align=\\\"right\\\"\u003E\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003Ctr\u003E\u003Ctd align=\\\"right\\\"\u003E\u003Ccode\u003EOneHot\u003C\u002Fcode\u003E\u003C\u002Ftd\u003E\u003Ctd align=\\\"right\\\"\u003E\u003Ccode\u003E&#40;x, y&#41;\u003C\u002Fcode\u003E\u003C\u002Ftd\u003E\u003Ctd align=\\\"right\\\"\u003E\u003C\u002Ftd\u003E\u003Ctd align=\\\"right\\\"\u003E\u003Cstrong\u003E\u003Ccode\u003EBounded&#123;2, FastAI.OneHotTensor&#123;2, String&#125;&#125;\u003C\u002Fcode\u003E\u003C\u002Fstrong\u003E\u003C\u002Ftd\u003E\u003C\u002Ftr\u003E\u003C\u002Ftable\u003E\\n\u003C\u002Fdiv\u003E\"},\"type\":\"leaf\"}],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"p\",\"children\":[\"From this short definition, many things can be derived:\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"ul\",\"children\":[{\"attributes\":{},\"tag\":\"li\",\"children\":[{\"attributes\":{},\"tag\":\"p\",\"children\":[\"data encoding\"],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"li\",\"children\":[{\"attributes\":{},\"tag\":\"p\",\"children\":[\"model output decoding\"],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"li\",\"children\":[{\"attributes\":{},\"tag\":\"p\",\"children\":[\"how to create a model from a backbone\"],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"li\",\"children\":[{\"attributes\":{},\"tag\":\"p\",\"children\":[\"the loss function to use\"],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"li\",\"children\":[{\"attributes\":{},\"tag\":\"p\",\"children\":[\"how to visualize samples and predictions\"],\"type\":\"node\"}],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"p\",\"children\":[\"Together with a \",{\"attributes\":{\"reftype\":\"document\",\"href\":\"data_container\",\"title\":\"\",\"document_id\":\"documents\u002Fdocs\u002Fdata_container\"},\"tag\":\"reference\",\"children\":[\"data container\"],\"type\":\"node\"},\" \",{\"attributes\":{},\"tag\":\"code\",\"children\":[\"data\"],\"type\":\"node\"},\", we can quickly create a \",{\"attributes\":{},\"tag\":\"code\",\"children\":[\"Learner\"],\"type\":\"node\"},\" using \",{\"attributes\":{\"reftype\":\"symbol\",\"document_id\":\"references\u002FFastAI.tasklearner\"},\"tag\":\"reference\",\"children\":[{\"attributes\":{},\"tag\":\"code\",\"children\":[\"tasklearner\"],\"type\":\"node\"}],\"type\":\"node\"},\" which, like in fastai, handles the training for us. There are no application-specific \",{\"attributes\":{},\"tag\":\"code\",\"children\":[\"Learner\"],\"type\":\"node\"},\" constructors like \",{\"attributes\":{},\"tag\":\"code\",\"children\":[\"cnn_learner\"],\"type\":\"node\"},\" or \",{\"attributes\":{},\"tag\":\"code\",\"children\":[\"unet_learner\"],\"type\":\"node\"},\" in FastAI.jl.\"],\"type\":\"node\"},{\"attributes\":{\"lang\":\"julia\"},\"tag\":\"codeblock\",\"children\":[{\"attributes\":{},\"tag\":\"julia\",\"children\":[{\"attributes\":{},\"tag\":\"EQ\",\"children\":[{\"attributes\":{},\"tag\":\"IDENTIFIER\",\"children\":[\"learner\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"WHITESPACE\",\"children\":[\" \"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"EQ\",\"children\":[\"=\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"WHITESPACE\",\"children\":[\" \"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"CALL\",\"children\":[{\"attributes\":{\"reftype\":\"symbol\",\"document_id\":\"references\u002FFastAI.tasklearner\"},\"tag\":\"reference\",\"children\":[\"tasklearner\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"LPAREN\",\"children\":[\"(\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"IDENTIFIER\",\"children\":[\"task\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"COMMA\",\"children\":[\",\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"WHITESPACE\",\"children\":[\" \"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"IDENTIFIER\",\"children\":[\"data\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"RPAREN\",\"children\":[\")\"],\"type\":\"node\"}],\"type\":\"node\"}],\"type\":\"node\"}],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"p\",\"children\":[\"High-level training protocols like the \",{\"attributes\":{\"reftype\":\"document\",\"href\":\"..\u002Fnotebooks\u002Ffitonecycle.ipynb\",\"title\":\"\",\"document_id\":\"documents\u002Fnotebooks\u002Ffitonecycle.ipynb\"},\"tag\":\"reference\",\"children\":[\"one\",\"-\",\"cycle learning rate schedule\"],\"type\":\"node\"},\", \",{\"attributes\":{\"reftype\":\"document\",\"href\":\"..\u002Fnotebooks\u002Ffinetune.ipynb\",\"title\":\"\",\"document_id\":\"documents\u002Fnotebooks\u002Ffinetune.ipynb\"},\"tag\":\"reference\",\"children\":[\"fine\",\"-\",\"tuning\"],\"type\":\"node\"},\" and the \",{\"attributes\":{\"reftype\":\"document\",\"href\":\"..\u002Fnotebooks\u002Flrfind.ipynb\",\"title\":\"\",\"document_id\":\"documents\u002Fnotebooks\u002Flrfind.ipynb\"},\"tag\":\"reference\",\"children\":[\"learning rate finder\"],\"type\":\"node\"},\" are then available to us:\"],\"type\":\"node\"},{\"attributes\":{\"lang\":\"julia\"},\"tag\":\"codeblock\",\"children\":[{\"attributes\":{},\"tag\":\"julia\",\"children\":[{\"attributes\":{},\"tag\":\"CALL\",\"children\":[{\"attributes\":{\"reftype\":\"symbol\",\"document_id\":\"references\u002FFluxTraining.fit!\"},\"tag\":\"reference\",\"children\":[\"fit!\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"LPAREN\",\"children\":[\"(\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"IDENTIFIER\",\"children\":[\"learner\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"COMMA\",\"children\":[\",\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"WHITESPACE\",\"children\":[\" \"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"INTEGER\",\"children\":[\"10\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"RPAREN\",\"children\":[\")\"],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"WHITESPACE\",\"children\":[\"                  \"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"COMMENT\",\"children\":[\"# Basic training for 10 epochs\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"NEWLINE_WS\",\"children\":[\"\\n\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"CALL\",\"children\":[{\"attributes\":{\"reftype\":\"symbol\",\"document_id\":\"references\u002FFastAI.finetune!\"},\"tag\":\"reference\",\"children\":[\"finetune!\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"LPAREN\",\"children\":[\"(\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"IDENTIFIER\",\"children\":[\"learner\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"COMMA\",\"children\":[\",\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"WHITESPACE\",\"children\":[\" \"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"INTEGER\",\"children\":[\"5\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"COMMA\",\"children\":[\",\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"WHITESPACE\",\"children\":[\" \"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"FLOAT\",\"children\":[\"1e-3\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"RPAREN\",\"children\":[\")\"],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"WHITESPACE\",\"children\":[\"        \"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"COMMENT\",\"children\":[\"# Finetuning regimen for 1+5 epochs with lr=1e-3\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"NEWLINE_WS\",\"children\":[\"\\n\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"CALL\",\"children\":[{\"attributes\":{\"reftype\":\"symbol\",\"document_id\":\"references\u002FFastAI.fitonecycle!\"},\"tag\":\"reference\",\"children\":[\"fitonecycle!\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"LPAREN\",\"children\":[\"(\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"IDENTIFIER\",\"children\":[\"learner\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"COMMA\",\"children\":[\",\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"WHITESPACE\",\"children\":[\" \"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"INTEGER\",\"children\":[\"10\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"RPAREN\",\"children\":[\")\"],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"TOPLEVEL\",\"children\":[{\"attributes\":{},\"tag\":\"WHITESPACE\",\"children\":[\"          \"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"COMMENT\",\"children\":[\"# One-cycle learning rate regimen\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"NEWLINE_WS\",\"children\":[\"\\n\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"EQ\",\"children\":[{\"attributes\":{},\"tag\":\"IDENTIFIER\",\"children\":[\"res\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"WHITESPACE\",\"children\":[\" \"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"EQ\",\"children\":[\"=\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"WHITESPACE\",\"children\":[\" \"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"CALL\",\"children\":[{\"attributes\":{\"reftype\":\"symbol\",\"document_id\":\"references\u002FFastAI.lrfind\"},\"tag\":\"reference\",\"children\":[\"lrfind\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"LPAREN\",\"children\":[\"(\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"IDENTIFIER\",\"children\":[\"learner\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"RPAREN\",\"children\":[\")\"],\"type\":\"node\"}],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"SEMICOLON\",\"children\":[\";\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"WHITESPACE\",\"children\":[\" \"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"CALL\",\"children\":[{\"attributes\":{},\"tag\":\"IDENTIFIER\",\"children\":[\"plot\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"LPAREN\",\"children\":[\"(\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"IDENTIFIER\",\"children\":[\"res\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"RPAREN\",\"children\":[\")\"],\"type\":\"node\"}],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"WHITESPACE\",\"children\":[\"   \"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"COMMENT\",\"children\":[\"# Run learning rate finder and plot suggestions\"],\"type\":\"node\"}],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"h3\",\"children\":[\"Incrementally adapting PyTorch code\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"p\",\"children\":[\"Since it is a Julia package, FastAI.jl is not written on top of PyTorch, but a Julia library for deep learning: \",{\"attributes\":{\"href\":\"http:\u002F\u002Fwww.fluxml.ai\",\"title\":\"\"},\"tag\":\"a\",\"children\":[\"Flux\",\".\",\"jl\"],\"type\":\"node\"},\". In any case, the point of this section is to note that the abstractions in fastai are decoupled and existing projects can easily be reused. This is also the case for FastAI.jl as it is built on top of several decoupled libraries. Many of these were built specifically for FastAI.jl, but they are unaware of each other and useful in their own right:\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"ul\",\"children\":[{\"attributes\":{},\"tag\":\"li\",\"children\":[{\"attributes\":{},\"tag\":\"p\",\"children\":[{\"attributes\":{\"href\":\"https:\u002F\u002Fgithub.com\u002FFluxML\u002FFlux.jl\",\"title\":\"\"},\"tag\":\"a\",\"children\":[\"Flux\",\".\",\"jl\"],\"type\":\"node\"},\" provides models, optimizers, and loss functions, fulfilling a similar role to PyTorch\"],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"li\",\"children\":[{\"attributes\":{},\"tag\":\"p\",\"children\":[{\"attributes\":{\"href\":\"https:\u002F\u002Fgithub.com\u002FJuliaML\u002FMLDataPattern.jl\",\"title\":\"\"},\"tag\":\"a\",\"children\":[\"MLDataPattern\",\".\",\"jl\"],\"type\":\"node\"},\" gives you tools for building and transforming data containers\"],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"li\",\"children\":[{\"attributes\":{},\"tag\":\"p\",\"children\":[{\"attributes\":{\"href\":\"https:\u002F\u002Fgithub.com\u002Florenzoh\u002FDataLoaders.jl\",\"title\":\"\"},\"tag\":\"a\",\"children\":[\"DataLoaders\",\".\",\"jl\"],\"type\":\"node\"},\" takes care of efficient, parallelized iteration of data containers\"],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"li\",\"children\":[{\"attributes\":{},\"tag\":\"p\",\"children\":[{\"attributes\":{\"href\":\"https:\u002F\u002Fgithub.com\u002Florenzoh\u002FDataAugmentation.jl\",\"title\":\"\"},\"tag\":\"a\",\"children\":[\"DataAugmentation\",\".\",\"jl\"],\"type\":\"node\"},\" takes care of the lower levels of high-performance, composable data augmentations.\"],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"li\",\"children\":[{\"attributes\":{},\"tag\":\"p\",\"children\":[{\"attributes\":{\"href\":\"https:\u002F\u002Fgithub.com\u002Florenzoh\u002FFluxTraining.jl\",\"title\":\"\"},\"tag\":\"a\",\"children\":[\"FluxTraining\",\".\",\"jl\"],\"type\":\"node\"},\" contributes a highly extensible training loop with 2-way callbacks\"],\"type\":\"node\"}],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"p\",\"children\":[\"If that seems like a lot: don’t worry! If you’ve installed FastAI.jl, the functionality of most of these packages is reexported and you don’t have to install any of them explicitly.\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"h3\",\"children\":[\"Consistency across domains\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"p\",\"children\":[\"While computer vision is the only domain with mature support for now, the abstractions underlying FastAI.jl are carefully crafted to ensure that learning tasks for different domains can be created using the same set of interfaces. This shows in that there’s no need for application-specific functionality above the data block API.\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"h2\",\"children\":[\"Mid\",\"-\",\"level APIs\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"h3\",\"children\":[\"Learner\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"p\",\"children\":[\"The \",{\"attributes\":{\"reftype\":\"symbol\",\"document_id\":\"references\u002FFluxTraining.Learner\"},\"tag\":\"reference\",\"children\":[{\"attributes\":{},\"tag\":\"code\",\"children\":[\"Learner\"],\"type\":\"node\"}],\"type\":\"node\"},\" is very similar to fastai’s. It takes\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"ul\",\"children\":[{\"attributes\":{},\"tag\":\"li\",\"children\":[{\"attributes\":{},\"tag\":\"p\",\"children\":[\"a model: any parameterized, differentiable function like a neural network or even \",{\"attributes\":{\"href\":\"https:\u002F\u002Ffluxml.ai\u002Fblog\u002F2019\u002F03\u002F05\u002Fdp-vs-rl.html\",\"title\":\"\"},\"tag\":\"a\",\"children\":[\"a trebuchet simulator\"],\"type\":\"node\"}],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"li\",\"children\":[{\"attributes\":{},\"tag\":\"p\",\"children\":[\"training and validation data iterators: these can be \",{\"attributes\":{},\"tag\":\"code\",\"children\":[\"DataLoader\"],\"type\":\"node\"},\"s which paralellize data loading but any iterator over batches can be used\"],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"li\",\"children\":[{\"attributes\":{},\"tag\":\"p\",\"children\":[\"optimizer\"],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"li\",\"children\":[{\"attributes\":{},\"tag\":\"p\",\"children\":[\"loss function\"],\"type\":\"node\"}],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"h3\",\"children\":[\"Two\",\"-\",\"way callbacks\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"p\",\"children\":[\"The training loop also supports two-way callbacks. See the \",{\"attributes\":{\"href\":\"https:\u002F\u002Ffluxml.ai\u002FFluxTraining.jl\u002Fdev\u002Fdocs\u002Fcallbacks\u002Freference.md.html\",\"title\":\"\"},\"tag\":\"a\",\"children\":[\"FluxTraining\",\".\",\"jl docs\"],\"type\":\"node\"},\" for a list of all available callbacks. While supporting all the functionality of fastai’s callbacks and training loop, it also provides \",{\"attributes\":{\"href\":\"https:\u002F\u002Ffluxml.ai\u002FFluxTraining.jl\u002Fdev\u002Fdocs\u002Ftutorials\u002Ftraining.md.html\",\"title\":\"\"},\"tag\":\"a\",\"children\":[\"an extensible training loop API\"],\"type\":\"node\"},\" that makes it straightforward to integrate custom training steps with the available callbacks. As a result, different training steps for problems other than standard supervised training can make use of existing callbacks  without the need to handle control flow through callbacks. Additionally, callbacks have an additional level of safety by being required to declare what state they access and modify. With a little more effort up-front, this guarantees correct ordering of callback execution through \",{\"attributes\":{\"href\":\"https:\u002F\u002Ffluxml.ai\u002FFluxTraining.jl\u002Fdev\u002Fdocs\u002Fcallbacks\u002Ftipstricks.md.html#visualize-the-callback-dependency-graph\",\"title\":\"\"},\"tag\":\"a\",\"children\":[\"a dependency graph\"],\"type\":\"node\"},\". In the future, this will also make it possible to automatically run callbacks in parallel and asynchronously to reduce overhead by long-running callbacks like costly metric calculations and logging over the network.\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"h3\",\"children\":[\"Encodings and blocks\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"p\",\"children\":[\"In the paper, this subsection is in the low-level section (named Transforms and Pipelines), but I’m putting it here since it is the core of FastAI.jl’s data block API. FastAI.jl provides \",{\"attributes\":{},\"tag\":\"code\",\"children\":[\"Encoding\"],\"type\":\"node\"},\"s and \",{\"attributes\":{},\"tag\":\"code\",\"children\":[\"Block\"],\"type\":\"node\"},\"s which correspond to fastai’s \",{\"attributes\":{},\"tag\":\"code\",\"children\":[\"Transform\"],\"type\":\"node\"},\"s and \",{\"attributes\":{},\"tag\":\"code\",\"children\":[\"Block\"],\"type\":\"node\"},\"s. Encodings implement an \",{\"attributes\":{},\"tag\":\"code\",\"children\":[\"encode\"],\"type\":\"node\"},\" (and optionally \",{\"attributes\":{},\"tag\":\"code\",\"children\":[\"decode\"],\"type\":\"node\"},\") function that describes how data corresponding to some blocks is transformed and how that transformation can be inverted. There is also support for stateful encodings like \",{\"attributes\":{\"reftype\":\"symbol\",\"document_id\":\"references\u002FFastAI.Vision.ProjectiveTransforms\"},\"tag\":\"reference\",\"children\":[{\"attributes\":{},\"tag\":\"code\",\"children\":[\"ProjectiveTransforms\"],\"type\":\"node\"}],\"type\":\"node\"},\" which need to use the same random state to augment every data point. Additionally, encodings describe what kind of block data is returned from encoding, allowing inspection of the whole data pipeline. The \",{\"attributes\":{},\"tag\":\"code\",\"children\":[\"Block\"],\"type\":\"node\"},\"s are used to dispatch in the \",{\"attributes\":{},\"tag\":\"code\",\"children\":[\"encode\"],\"type\":\"node\"},\" function to implement block-specific transformations. If no \",{\"attributes\":{},\"tag\":\"code\",\"children\":[\"encode\"],\"type\":\"node\"},\" task is implemented for a pair of encoding and block, the default is to pass the data through unchanged like in fastai.\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"p\",\"children\":[\"The \",{\"attributes\":{},\"tag\":\"code\",\"children\":[\"Block\"],\"type\":\"node\"},\"s also allow implementing task-specific functionality:\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"ul\",\"children\":[{\"attributes\":{},\"tag\":\"li\",\"children\":[{\"attributes\":{},\"tag\":\"p\",\"children\":[{\"attributes\":{\"reftype\":\"symbol\",\"document_id\":\"references\u002FFastAI.blocklossfn\"},\"tag\":\"reference\",\"children\":[{\"attributes\":{},\"tag\":\"code\",\"children\":[\"blocklossfn\"],\"type\":\"node\"}],\"type\":\"node\"},\" takes a prediction and encoded target block to determine a good loss function to use. For example, for image classification we want to compare two one-hot encoded labels and hence define \",{\"attributes\":{},\"tag\":\"code\",\"children\":[\"blocklossfn(::OneHotTensor{0}, ::OneHotTensor{0}) = logitcrossentropy\"],\"type\":\"node\"},\".\"],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"li\",\"children\":[{\"attributes\":{},\"tag\":\"p\",\"children\":[{\"attributes\":{\"reftype\":\"symbol\",\"document_id\":\"references\u002FFastAI.blockmodel\"},\"tag\":\"reference\",\"children\":[{\"attributes\":{},\"tag\":\"code\",\"children\":[\"blockmodel\"],\"type\":\"node\"}],\"type\":\"node\"},\" constructs a model from a backbone that maps an input block to an output block. For example, for image segmentation we have \",{\"attributes\":{},\"tag\":\"code\",\"children\":[\"ImageTensor{N}()\"],\"type\":\"node\"},\" as the input block and \",{\"attributes\":{},\"tag\":\"code\",\"children\":[\"OneHotTensor{N}\"],\"type\":\"node\"},\" (one-hot encoded N-dimensional masks) as output, so \",{\"attributes\":{},\"tag\":\"code\",\"children\":[\"blockmodel\"],\"type\":\"node\"},\" turns the backbone into a U-Net.\"],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"li\",\"children\":[{\"attributes\":{},\"tag\":\"p\",\"children\":[{\"attributes\":{\"reftype\":\"symbol\",\"document_id\":\"references\u002FFastAI.showblock!\"},\"tag\":\"reference\",\"children\":[{\"attributes\":{},\"tag\":\"code\",\"children\":[\"showblock!\"],\"type\":\"node\"}],\"type\":\"node\"},\" defines how to visualize a block of data.\"],\"type\":\"node\"}],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"h3\",\"children\":[\"Generic optimizer\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"p\",\"children\":[\"FastAI.jl uses the optimizers from Flux.jl, which provides a similarly \",{\"attributes\":{\"href\":\"https:\u002F\u002Ffluxml.ai\u002FFlux.jl\u002Fstable\u002Ftraining\u002Foptimisers\u002F#Composing-Optimisers\",\"title\":\"\"},\"tag\":\"a\",\"children\":[\"composable API for optimzers\"],\"type\":\"node\"},\".\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"h3\",\"children\":[\"Generalized metric API\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"p\",\"children\":[\"Metrics are handled by the \",{\"attributes\":{\"reftype\":\"symbol\",\"document_id\":\"references\u002FFluxTraining.Metrics\"},\"tag\":\"reference\",\"children\":[{\"attributes\":{},\"tag\":\"code\",\"children\":[\"Metrics\"],\"type\":\"node\"}],\"type\":\"node\"},\" callback which takes in reducing metric functions or \",{\"attributes\":{\"reftype\":\"symbol\",\"document_id\":\"references\u002FFluxTraining.AbstractMetric\"},\"tag\":\"reference\",\"children\":[{\"attributes\":{},\"tag\":\"code\",\"children\":[\"FluxTraining.AbstractMetric\"],\"type\":\"node\"}],\"type\":\"node\"},\"s which have a similar API to fastai’s.\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"h3\",\"children\":[\"fastai\",\".\",\"data\",\".\",\"external\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"p\",\"children\":[\"FastAI.jl makes all the same datasets available in \",{\"attributes\":{},\"tag\":\"code\",\"children\":[\"fastai.data.external\"],\"type\":\"node\"},\" available. See \",{\"attributes\":{},\"tag\":\"code\",\"children\":[\"FastAI.Datasets.DATASETS\"],\"type\":\"node\"},\" for a list of all datasets and use \",{\"attributes\":{\"reftype\":\"symbol\",\"document_id\":\"references\u002FFastAI.Datasets.datasetpath\"},\"tag\":\"reference\",\"children\":[{\"attributes\":{},\"tag\":\"code\",\"children\":[\"datasetpath\"],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"code\",\"children\":[\"(name)\"],\"type\":\"node\"},\" to download and extract a dataset.\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"h3\",\"children\":[\"funcs\",\"_\",\"kwargs and DataLoader, fastai\",\".\",\"data\",\".\",\"core\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"p\",\"children\":[\"In FastAI.jl, you are not restricted to a specific type of data iterator and can pass any iterator over batches to \",{\"attributes\":{},\"tag\":\"code\",\"children\":[\"Learner\"],\"type\":\"node\"},\". In cases where performance is important \",{\"attributes\":{},\"tag\":\"code\",\"children\":[\"DataLoader\"],\"type\":\"node\"},\" can speed up data iteration by loading and batching samples in parallel on background threads. All transformations of data happen through the data container interface which requires a type to implement \",{\"attributes\":{},\"tag\":\"code\",\"children\":[\"LearnBase.getobs\"],\"type\":\"node\"},\" and \",{\"attributes\":{},\"tag\":\"code\",\"children\":[\"LearnBase.nobs\"],\"type\":\"node\"},\", similar to PyTorch’s \",{\"attributes\":{},\"tag\":\"code\",\"children\":[\"torch.utils.data.Dataset\"],\"type\":\"node\"},\". Data containers are then transformed into other data containers. Some examples:\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"ul\",\"children\":[{\"attributes\":{},\"tag\":\"li\",\"children\":[{\"attributes\":{},\"tag\":\"p\",\"children\":[{\"attributes\":{\"reftype\":\"symbol\",\"document_id\":\"references\u002FFastAI.Datasets.mapobs\"},\"tag\":\"reference\",\"children\":[{\"attributes\":{},\"tag\":\"code\",\"children\":[\"mapobs\"],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"code\",\"children\":[\"(f, data)\"],\"type\":\"node\"},\" lazily maps a function \",{\"attributes\":{},\"tag\":\"code\",\"children\":[\"f\"],\"type\":\"node\"},\" of over \",{\"attributes\":{},\"tag\":\"code\",\"children\":[\"data\"],\"type\":\"node\"},\" such that \",{\"attributes\":{},\"tag\":\"code\",\"children\":[\"getobs(mapobs(f, data), idx) == f(getobs(data, idx))\"],\"type\":\"node\"},\". For example \",{\"attributes\":{},\"tag\":\"code\",\"children\":[\"mapobs(loadfile, files)\"],\"type\":\"node\"},\" turns a vector of image files into a data container of images.\"],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"li\",\"children\":[{\"attributes\":{},\"tag\":\"p\",\"children\":[{\"attributes\":{},\"tag\":\"code\",\"children\":[\"DataLoader(data, batchsize)\"],\"type\":\"node\"},\" is a wrapper around \",{\"attributes\":{},\"tag\":\"code\",\"children\":[\"batchviewcollated\"],\"type\":\"node\"},\" which turns a data container of samples into one of collated batches and \",{\"attributes\":{},\"tag\":\"code\",\"children\":[\"eachobsparallel\"],\"type\":\"node\"},\" which creates a parallel, buffered iterator over the observations (here batches) in the resulting container.\"],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"li\",\"children\":[{\"attributes\":{},\"tag\":\"p\",\"children\":[{\"attributes\":{\"reftype\":\"symbol\",\"document_id\":\"references\u002FFastAI.Datasets.groupobs\"},\"tag\":\"reference\",\"children\":[{\"attributes\":{},\"tag\":\"code\",\"children\":[\"groupobs\"],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"code\",\"children\":[\"(f, data)\"],\"type\":\"node\"},\" splits a container into groups using a grouping function \",{\"attributes\":{},\"tag\":\"code\",\"children\":[\"f\"],\"type\":\"node\"},\". For example, \",{\"attributes\":{},\"tag\":\"code\",\"children\":[\"groupobs(grandparentname, files)\"],\"type\":\"node\"},\" creates training splits for files where the grandparent folder indicates the split.\"],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"li\",\"children\":[{\"attributes\":{},\"tag\":\"p\",\"children\":[{\"attributes\":{},\"tag\":\"code\",\"children\":[\"datasubset\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"code\",\"children\":[\"(data, idxs)\"],\"type\":\"node\"},\" lazily takes a subset of the observations in \",{\"attributes\":{},\"tag\":\"code\",\"children\":[\"data\"],\"type\":\"node\"},\".\"],\"type\":\"node\"}],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"p\",\"children\":[\"For more information, see the \",{\"attributes\":{\"reftype\":\"document\",\"href\":\"data_containers.md\",\"title\":\"\",\"document_id\":\"documents\u002Fdocs\u002Fdata_containers.md\"},\"tag\":\"reference\",\"children\":[\"data container tutorial\"],\"type\":\"node\"},\" and the \",{\"attributes\":{\"href\":\"https:\u002F\u002Fmldatapatternjl.readthedocs.io\u002Fen\u002Flatest\u002F\",\"title\":\"\"},\"tag\":\"a\",\"children\":[\"MLDataPattern\",\".\",\"jl docs\"],\"type\":\"node\"},\". At a higher level, there are also convenience functions like \",{\"attributes\":{\"reftype\":\"symbol\",\"document_id\":\"references\u002FFastAI.Datasets.FileDataset\"},\"tag\":\"reference\",\"children\":[{\"attributes\":{},\"tag\":\"code\",\"children\":[\"FileDataset\"],\"type\":\"node\"}],\"type\":\"node\"},\" to create data containers.\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"h3\",\"children\":[\"Layers and architectures\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"p\",\"children\":[\"Flux.jl already does a better job at functionally creating model architectures than PyTorch, so FastAI.jl makes use of its layers. For example \",{\"attributes\":{\"reftype\":\"symbol\",\"document_id\":\"references\u002FFlux.SkipConnection\"},\"tag\":\"reference\",\"children\":[{\"attributes\":{},\"tag\":\"code\",\"children\":[\"Flux.SkipConnection\"],\"type\":\"node\"}],\"type\":\"node\"},\"  corresponds to fastai’s \",{\"attributes\":{},\"tag\":\"code\",\"children\":[\"MergeLayer\"],\"type\":\"node\"},\". The \",{\"attributes\":{},\"tag\":\"code\",\"children\":[\"FastAI.Models\"],\"type\":\"node\"},\" submodule currently provides some high-level architectures like \",{\"attributes\":{\"reftype\":\"symbol\",\"document_id\":\"references\u002FFastAI.Vision.Models.xresnet18\"},\"tag\":\"reference\",\"children\":[{\"attributes\":{},\"tag\":\"code\",\"children\":[\"xresnet18\"],\"type\":\"node\"}],\"type\":\"node\"},\" and a U-Net builder \",{\"attributes\":{\"reftype\":\"symbol\",\"document_id\":\"references\u002FFastAI.Vision.Models.UNetDynamic\"},\"tag\":\"reference\",\"children\":[{\"attributes\":{},\"tag\":\"code\",\"children\":[\"UNetDynamic\"],\"type\":\"node\"}],\"type\":\"node\"},\" that can create U-Nets from \",{\"attributes\":{},\"tag\":\"em\",\"children\":[\"any\"],\"type\":\"node\"},\" convolutional feature extractor. The \",{\"attributes\":{\"reftype\":\"document\",\"href\":\"setup.md\",\"title\":\"\",\"document_id\":\"documents\u002Fdocs\u002Fsetup.md\"},\"tag\":\"reference\",\"children\":[\"optional dependency\"],\"type\":\"node\"},\" \",{\"attributes\":{\"href\":\"https:\u002F\u002Fgithub.com\u002FFluxML\u002FMetalhead.jl\",\"title\":\"\"},\"tag\":\"a\",\"children\":[\"Metalhead\",\".\",\"jl\"],\"type\":\"node\"},\" also provides common pretrained vision models.\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"h2\",\"children\":[\"Low\",\"-\",\"level APIs\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"p\",\"children\":[\"Due to the nature of the Julia language and its design around multiple dispatch, packages tend to compose really well, so it was not necessary to reimplement or provide a unified API for low-level operations. We’ll comment on the libraries that we were able to use.\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"h3\",\"children\":[\"PyTorch foundations\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"p\",\"children\":[\"Unlike Python, Julia has native support for N-dimensional regular arrays. As such, there is a standard interface for arrays and libraries don’t need to implement their own. Consider that every deep learning framework in Python implements their own CPU and GPU arrays, which is part of the reason they are \",{\"attributes\":{},\"tag\":\"em\",\"children\":[\"frameworks\"],\"type\":\"node\"},\", not \",{\"attributes\":{},\"tag\":\"em\",\"children\":[\"libraries\"],\"type\":\"node\"},\" (with the latter being vastly preferable). Julia’s standard libraries implements the standard CPU \",{\"attributes\":{},\"tag\":\"code\",\"children\":[\"Array\"],\"type\":\"node\"},\" type. GPU arrays are implemented through \",{\"attributes\":{\"href\":\"https:\u002F\u002Fgithub.com\u002FJuliaGPU\u002FCUDA.jl\",\"title\":\"\"},\"tag\":\"a\",\"children\":[\"CUDA\",\".\",\"jl\"],\"type\":\"node\"},\" \",{\"attributes\":{},\"tag\":\"code\",\"children\":[\"CuArray\"],\"type\":\"node\"},\" type (with unified support for GPU vendors other than nvidia in the works). As a result, Flux.jl, the deep learning library of choice for FastAI.jl, does not need to reimplement their own CPU and GPU array versions. This kind of composability in general largely benefits what can be accomplished in Julia.\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"p\",\"children\":[\"Some other libraries which are used under the hood: for image processing, the \",{\"attributes\":{\"href\":\"https:\u002F\u002Fjuliaimages.org\u002F\",\"title\":\"\"},\"tag\":\"a\",\"children\":[\"Images\",\".\",\"jl\"],\"type\":\"node\"},\" ecosystem of packages is used; for reading and processing tabular data \",{\"attributes\":{\"href\":\"https:\u002F\u002Fgithub.com\u002FJuliaData\u002FDataFrames.jl\",\"title\":\"\"},\"tag\":\"a\",\"children\":[\"DataFrames\",\".\",\"jl\"],\"type\":\"node\"},\" and \",{\"attributes\":{\"href\":\"https:\u002F\u002Fgithub.com\u002FJuliaData\u002FTables.jl\",\"title\":\"\"},\"tag\":\"a\",\"children\":[\"Tables\",\".\",\"jl\"],\"type\":\"node\"},\"; for plotting \",{\"attributes\":{\"href\":\"https:\u002F\u002Fgithub.com\u002FJuliaPlots\u002FMakie.jl\",\"title\":\"\"},\"tag\":\"a\",\"children\":[\"Makie\",\".\",\"jl\"],\"type\":\"node\"},\".\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"h3\",\"children\":[\"Type dispatch\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"p\",\"children\":[\"Multiple dispatch already is a core feature of the Julia language, hence the extensible interfaces in FastAI.jl are built around it and are natural fit for the language.\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"h3\",\"children\":[\"Object\",\"-\",\"oriented semantic tensors\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"p\",\"children\":[\"As mentioned above, Julia has great support for arrays with extra functionality available to packages that provide wrapper arrays like \",{\"attributes\":{\"href\":\"https:\u002F\u002Fgithub.com\u002Finvenia\u002FNamedDims.jl\",\"title\":\"\"},\"tag\":\"a\",\"children\":[\"NamedDims\",\".\",\"jl\"],\"type\":\"node\"},\" which should generally \",{\"attributes\":{},\"tag\":\"em\",\"children\":[\"just work\"],\"type\":\"node\"},\" with every part of the library. Hence there is no need for an addtional API that unifies separate packages, which in turn makes FastAI.jl more composable with other packages.\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"p\",\"children\":[\"In encodings, the array types are used for dispatch only where an especially performant implementation is possible, and the block information is used for dispatching the semantics of the encoding.\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"h3\",\"children\":[\"GPU\",\"-\",\"accelerated augmentation\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"p\",\"children\":[\"FastAI.jl does not support GPU-accelerated augmentation (yet). Please open an issue if you run into a situation where data processing \",{\"attributes\":{\"reftype\":\"document\",\"href\":\"background\u002Fdatapipelines.md\",\"title\":\"\",\"document_id\":\"documents\u002Fdocs\u002Fbackground\u002Fdatapipelines.md\"},\"tag\":\"reference\",\"children\":[\"becomes the bottleneck\"],\"type\":\"node\"},\" and we’ll prioritize this. The affine transformations implemented in DataAugmentation.jl and used in FastAI.jl are properly composed to ensure high quality results. They are also optimized for speed and memory usage (with complete support for inplace transformations).\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"h3\",\"children\":[\"Convenience functionality\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"p\",\"children\":[\"Much of the convenience provided by fastai is not required in Julia:\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"ul\",\"children\":[{\"attributes\":{},\"tag\":\"li\",\"children\":[{\"attributes\":{},\"tag\":\"p\",\"children\":[{\"attributes\":{},\"tag\":\"code\",\"children\":[\"@delegates\"],\"type\":\"node\"},\": Due to the absence of deep class hierarchies, keyword arguments are seldom passed around (the only instance where this happens in FastAI.jl is \",{\"attributes\":{\"reftype\":\"symbol\",\"document_id\":\"references\u002FFastAI.tasklearner\"},\"tag\":\"reference\",\"children\":[{\"attributes\":{},\"tag\":\"code\",\"children\":[\"tasklearner\"],\"type\":\"node\"}],\"type\":\"node\"},\").\"],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"li\",\"children\":[{\"attributes\":{},\"tag\":\"p\",\"children\":[{\"attributes\":{},\"tag\":\"code\",\"children\":[\"@patch\"],\"type\":\"node\"},\": since Julia is built around multiple dispatch, not classes, you just implement the task for a type, no patching needed\"],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"li\",\"children\":[{\"attributes\":{},\"tag\":\"p\",\"children\":[{\"attributes\":{},\"tag\":\"code\",\"children\":[\"L\"],\"type\":\"node\"},\": due to first-class array support such a wrapper list container isn’t needed\"],\"type\":\"node\"}],\"type\":\"node\"}],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"h2\",\"children\":[\"nbdev\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"p\",\"children\":[\"There is no \",{\"attributes\":{},\"tag\":\"code\",\"children\":[\"nbdev\"],\"type\":\"node\"},\"-equivalent in Julia at the moment. That said, this documentation is generated by a document creation package \",{\"attributes\":{\"href\":\"https:\u002F\u002Fgithub.com\u002Florenzoh\u002FPollen.jl\",\"title\":\"\"},\"tag\":\"a\",\"children\":[\"Pollen\",\".\",\"jl\"],\"type\":\"node\"},\" that could be extended to support such a workflow. It already has support for different source and output formats like Jupyter notebooks, code execution and is built for interactive work with incremental rebuilds.\"],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"hr\",\"children\":[],\"type\":\"node\"},{\"attributes\":{},\"tag\":\"p\",\"children\":[\"Hopefully this page has given you some context for how FastAI.jl relates to fastai and how to map concepts between the two. You are encouraged to go through the tutorials to see the design decisions made in practice.\"],\"type\":\"node\"}],\"type\":\"node\"}],\"type\":\"node\"}"}</script></div>
</body>

</html>